{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf148fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### IMPORTAR BIBLIOTECAS NECESSÁRIAS\n",
    "import csv\n",
    "from typing import Union, Any\n",
    "import tabula\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import PyPDF2\n",
    "from datetime import timedelta, time, datetime\n",
    "\n",
    "import pendulum\n",
    "from pendulum import now, yesterday, tomorrow, timezone, date\n",
    "import dateutil\n",
    "import os\n",
    "import warnings\n",
    "import requests\n",
    "import pprint\n",
    "import json\n",
    "from tkinter import filedialog\n",
    "from pandas import DataFrame\n",
    "from pandas.io.parsers import TextFileReader\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e040293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Ricardo/OneDrive/Área de Trabalho/SISTEMA AUDITORIA AERONAUTAS/AERONAUTAS/ARQUIVOS ORIGINAIS/MARCOS BELLINI/ESCALA IMPRESSÃO SITE.pdf\n",
      "Número de páginas: 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### LEITURA DO ARQUIVO DE SIGLAS SABRE\n",
    "path = filedialog.askopenfilename()\n",
    "\n",
    "print(path)\n",
    "\n",
    "imported_data = open(path, 'rb')\n",
    "pdf_reader = PyPDF2.PdfReader(imported_data)\n",
    "num_paginas = len(pdf_reader.pages)\n",
    "print(f\"Número de páginas: {num_paginas}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c97462c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Página 1 ---\n",
      "MARCOS RODOLFO CELENZA BELLINI Escala Summary, 01 May - 01 Jun 2025\n",
      "Generated 13 May 2025, 14:10 (VCP)\n",
      "Wed, 30  April 2025 (Local time)th\n",
      "Off (FR) 18:45 - 18:45 +1 VCP\n",
      "Fri, 2 May 2025 (Local time)nd\n",
      "Off (FR) 06:10 - 06:10 +1 VCP\n",
      "Sat, 3 May 2025 (Local time)rd\n",
      "Off (FR) 06:10 - 06:10 +1 VCP\n",
      "Sun, 4 May 2025 (Local time)th\n",
      "Apresentação 06:10 - 06:10 VCP\n",
      "Reserva (SEA) 06:10 - 11:30 VCP\n",
      "Release 11:30 - 11:30 VCP\n",
      "Apresentação 13:00 - 13:00 VCP\n",
      "Reserva (REX) 13:00 - 19:00 VCP\n",
      "Release 19:00 - 19:00 VCP\n",
      "Mon, 5 May 2025 (Local time)th\n",
      "Apresentação 20:50 - 20:50 VCP\n",
      "Reserva (R21) 20:50 - 23:50 VCP\n",
      "Release 23:50 - 23:50 VCP\n",
      "Tue, 6 May 2025 (Local time)th\n",
      "Apresentação 20:50 - 20:50 VCP\n",
      "Reserva (REA) 20:50 - 21:30 VCP\n",
      "AD4484 (Extra a serviço) 21:30 - 22:42 VCP - CNF CA Flight Time: 01:12\n",
      "Release 22:42 - 23:12 CNF\n",
      "Hotel 23:42 - 20:15 +1 CNF\n",
      "Wed, 7 May 2025 (Local time)th\n",
      "Reserva (SBATZ) 14:00 - 20:45 CNF\n",
      "Apresentação 20:45 - 21:34 CNF\n",
      "AD4438 21:34 - 00:29 +1 CNF - BEL CA Flight Time: 02:55\n",
      "Thu, 8 May 2025 (Local time)th\n",
      "Release 00:29 - 00:59 BEL\n",
      "Hotel 01:49 - 00:40 +1 BEL\n",
      "Fri, 9 May 2025 (Local time)th\n",
      "Apresentação 01:30 - 02:05 BEL\n",
      "AD4439 02:11 - 05:08 BEL - CNF CA Flight Time: 02:57\n",
      "AD4188 (Extra a serviço) 06:01 - 07:10 CNF - VCP CA Flight Time: 01:09\n",
      "Release 07:10 - 07:40 VCP\n",
      "Off (FR) 22:05 - 22:05 +1 VCP\n",
      "Sat, 10 May 2025 (Local time)th\n",
      "Off (FP) 22:05 - 22:05 +1 VCP\n",
      "Sun, 11  May 2025 (Local time)th\n",
      "Off (FP) 22:05 - 22:05 +1 VCP\n",
      "--- Página 2 ---\n",
      "Mon, 12  May 2025 (Local time)th\n",
      "Off (FR) 22:05 - 22:05 +1 VCP\n",
      "Tue, 13  May 2025 (Local time)th\n",
      "Off (FR) 22:05 - 22:05 +1 VCP\n",
      "Wed, 14  May 2025 (Local time)th\n",
      "Off (FR) 22:05 - 22:05 +1 VCP\n",
      "Thu, 15  May 2025 (Local time)th\n",
      "Off (FR) 22:05 - 22:05 +1 VCP\n",
      "Fri, 16 May 2025 (Local time)th\n",
      "Apresentação 22:05 - 22:55 VCP\n",
      "AD4451 22:55 - 01:40 +1 VCP - MAO CA Flight Time: 03:45\n",
      "Sat, 17 May 2025 (Local time)th\n",
      "Release 01:40 - 02:10 MAO\n",
      "Hotel 03:10 - 21:30 MAO\n",
      "Apresentação 22:30 - 23:05 MAO\n",
      "AD4624 23:05 - 02:10 +1 MAO - BEL CA Flight Time: 02:05\n",
      "Sun, 18  May 2025 (Local time)th\n",
      "Release 02:10 - 02:40 BEL\n",
      "Hotel 03:30 - 15:50 BEL\n",
      "Apresentação 16:40 - 17:15 BEL\n",
      "AD4545 17:15 - 18:20 BEL - MAO CA Flight Time: 02:05\n",
      "AD4861 19:00 - 22:05 MAO - BEL CA Flight Time: 02:05\n",
      "Release 22:05 - 22:35 BEL\n",
      "Hotel 23:25 - 11:40 +1 BEL\n",
      "Mon, 19  May 2025 (Local time)th\n",
      "Apresentação 12:30 - 13:05 BEL\n",
      "AD4840 13:05 - 14:00 BEL - MCP CA Flight Time: 00:55\n",
      "AD2705 14:40 - 15:35 MCP - BEL CA Flight Time: 00:55\n",
      "AD4433 17:05 - 19:35 BEL - REC CA Flight Time: 02:30\n",
      "AD4302 20:15 - 22:50 REC - BSB CA Flight Time: 02:35\n",
      "Release 22:50 - 23:20 BSB\n",
      "Tue, 20  May 2025 (Local time)th\n",
      "Hotel 00:00 - 11:45 BSB\n",
      "Apresentação 12:25 - 13:05 BSB\n",
      "AD4397 (Extra a serviço) 13:05 - 14:45 BSB - VCP CA Flight Time: 01:40\n",
      "AD4239 16:55 - 18:00 VCP - CGB CA Flight Time: 02:05\n",
      "AD2983 18:40 - 21:45 CGB - VCP CA Flight Time: 02:05\n",
      "Release 21:45 - 22:15 VCP\n",
      "Wed, 21  May 2025 (Local time)st\n",
      "Off (FR) 12:00 - 12:00 +1 VCP\n",
      "Thu, 22  May 2025 (Local time)nd\n",
      "Off (FR) 12:00 - 12:00 +1 VCP\n",
      "--- Página 3 ---\n",
      "Fri, 23 May 2025 (Local time)rd\n",
      "Apresentação 16:35 - 16:35 VCP\n",
      "Reserva (REX) 16:35 - 19:35 VCP\n",
      "Release 19:35 - 19:35 VCP\n",
      "Sat, 24 May 2025 (Local time)th\n",
      "Off (FR) 12:00 - 12:00 +1 VCP\n",
      "Sun, 25  May 2025 (Local time)th\n",
      "Apresentação 12:00 - 12:50 VCP\n",
      "AD4056 12:50 - 15:35 VCP - MAO CA Flight Time: 03:45\n",
      "Release 15:35 - 16:05 MAO\n",
      "Hotel 17:05 - 10:45 +1 MAO\n",
      "Mon, 26  May 2025 (Local time)th\n",
      "Apresentação 11:45 - 12:20 MAO\n",
      "AD2943 12:20 - 13:35 MAO - BVB CA Flight Time: 01:15\n",
      "AD4013 14:15 - 15:35 BVB - MAO CA Flight Time: 01:20\n",
      "AD4013 16:25 - 21:10 MAO - VCP CA Flight Time: 03:45\n",
      "AD4326 22:30 - 23:55 VCP - GYN CA Flight Time: 01:25\n",
      "Release 23:55 - 00:25 +1 GYN\n",
      "Tue, 27  May 2025 (Local time)th\n",
      "Hotel 01:15 - 04:30 +1 GYN\n",
      "Wed, 28  May 2025 (Local time)th\n",
      "Apresentação 05:20 - 05:55 GYN\n",
      "AD4327 05:55 - 07:25 GYN - VCP CA Flight Time: 01:30\n",
      "AD2943 08:55 - 11:40 VCP - MAO CA Flight Time: 03:45\n",
      "Release 11:40 - 12:10 MAO\n",
      "Hotel 13:10 - 10:45 +1 MAO\n",
      "Thu, 29  May 2025 (Local time)th\n",
      "Apresentação 11:45 - 12:20 MAO\n",
      "AD2943 12:20 - 13:35 MAO - BVB CA Flight Time: 01:15\n",
      "AD4013 14:15 - 15:35 BVB - MAO CA Flight Time: 01:20\n",
      "AD4013 16:25 - 21:10 MAO - VCP CA Flight Time: 03:45\n",
      "AD4326 22:30 - 23:55 VCP - GYN CA Flight Time: 01:25\n",
      "Release 23:55 - 00:25 +1 GYN\n",
      "Fri, 30 May 2025 (Local time)th\n",
      "Hotel 01:15 - 14:00 GYN\n",
      "Apresentação 14:50 - 15:25 GYN\n",
      "AD4867 15:25 - 16:50 GYN - VCP CA Flight Time: 01:25\n",
      "AD2960 17:50 - 19:20 VCP - GYN CA Flight Time: 01:30\n",
      "AD4567 20:00 - 21:30 GYN - VCP CA Flight Time: 01:30\n",
      "Release 21:30 - 22:00 VCP\n",
      "Sat, 31 May 2025 (Local time)st\n",
      "Off (FR) 10:30 - 10:30 +1 VCP\n",
      "Fri, 23 May 2025 (Local time)rd\n",
      "Apresentação 16:35 - 16:35 VCP\n",
      "Reserva (REX) 16:35 - 19:35 VCP\n",
      "Release 19:35 - 19:35 VCP\n",
      "Sat, 24 May 2025 (Local time)th\n",
      "Off (FR) 12:00 - 12:00 +1 VCP\n",
      "Sun, 25  May 2025 (Local time)th\n",
      "Apresentação 12:00 - 12:50 VCP\n",
      "AD4056 12:50 - 15:35 VCP - MAO CA Flight Time: 03:45\n",
      "Release 15:35 - 16:05 MAO\n",
      "Hotel 17:05 - 10:45 +1 MAO\n",
      "Mon, 26  May 2025 (Local time)th\n",
      "Apresentação 11:45 - 12:20 MAO\n",
      "AD2943 12:20 - 13:35 MAO - BVB CA Flight Time: 01:15\n",
      "AD4013 14:15 - 15:35 BVB - MAO CA Flight Time: 01:20\n",
      "AD4013 16:25 - 21:10 MAO - VCP CA Flight Time: 03:45\n",
      "AD4326 22:30 - 23:55 VCP - GYN CA Flight Time: 01:25\n",
      "Release 23:55 - 00:25 +1 GYN\n",
      "Tue, 27  May 2025 (Local time)th\n",
      "Hotel 01:15 - 04:30 +1 GYN\n",
      "Wed, 28  May 2025 (Local time)th\n",
      "Apresentação 05:20 - 05:55 GYN\n",
      "AD4327 05:55 - 07:25 GYN - VCP CA Flight Time: 01:30\n",
      "AD2943 08:55 - 11:40 VCP - MAO CA Flight Time: 03:45\n",
      "Release 11:40 - 12:10 MAO\n",
      "Hotel 13:10 - 10:45 +1 MAO\n",
      "Thu, 29  May 2025 (Local time)th\n",
      "Apresentação 11:45 - 12:20 MAO\n",
      "AD2943 12:20 - 13:35 MAO - BVB CA Flight Time: 01:15\n",
      "AD4013 14:15 - 15:35 BVB - MAO CA Flight Time: 01:20\n",
      "AD4013 16:25 - 21:10 MAO - VCP CA Flight Time: 03:45\n",
      "AD4326 22:30 - 23:55 VCP - GYN CA Flight Time: 01:25\n",
      "Release 23:55 - 00:25 +1 GYN\n",
      "Fri, 30 May 2025 (Local time)th\n",
      "Hotel 01:15 - 14:00 GYN\n",
      "Apresentação 14:50 - 15:25 GYN\n",
      "AD4867 15:25 - 16:50 GYN - VCP CA Flight Time: 01:25\n",
      "AD2960 17:50 - 19:20 VCP - GYN CA Flight Time: 01:30\n",
      "AD4567 20:00 - 21:30 GYN - VCP CA Flight Time: 01:30\n",
      "Release 21:30 - 22:00 VCP\n",
      "Sat, 31 May 2025 (Local time)st\n",
      "Off (FR) 10:30 - 10:30 +1 VCP\n",
      "Texto extraído salvo em: C:/Users/Ricardo/OneDrive/Área de Trabalho/SISTEMA AUDITORIA AERONAUTAS/AERONAUTAS/ARQUIVOS ORIGINAIS/MARCOS BELLINI/BELLINI MAIO 2025.csv\n",
      "Texto extraído salvo em: C:/Users/Ricardo/OneDrive/Área de Trabalho/SISTEMA AUDITORIA AERONAUTAS/AERONAUTAS/ARQUIVOS ORIGINAIS/MARCOS BELLINI/BELLINI MAIO 2025.csv\n"
     ]
    }
   ],
   "source": [
    "for i, pagina in enumerate(pdf_reader.pages):\n",
    "    print(f\"--- Página {i+1} ---\")\n",
    "    print(pagina.extract_text())\n",
    "    \n",
    "# SALVAR O TEXTO EXTRAÍDO EM UM ARQUIVO CSV\n",
    "output_csv = filedialog.asksaveasfilename(defaultextension=\".csv\", filetypes=[(\"CSV files\", \"*.csv\")])\n",
    "with open(output_csv, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    \n",
    "    for i, pagina in enumerate(pdf_reader.pages):\n",
    "        texto = pagina.extract_text()\n",
    "        linhas = texto.split('\\n')\n",
    "        \n",
    "        for linha in linhas:\n",
    "            csv_writer.writerow([linha])\n",
    "    print(f\"Texto extraído salvo em: {output_csv}\")\n",
    "    #print(f\"A atividade é : {output_csv.split('/')[-1]}\")  # Exibe apenas o nome do arquivo\n",
    "\n",
    "# Fechar o arquivo PDF\n",
    "imported_data.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c93365c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extração de texto concluída e salva em CSV.\n",
      "Arquivo CSV salvo em: C:/Users/Ricardo/OneDrive/Área de Trabalho/SISTEMA AUDITORIA AERONAUTAS/AERONAUTAS/ARQUIVOS ORIGINAIS/MARCOS BELLINI/BELLINI MAIO 2025.csv\n",
      "Conteúdo do CSV:\n",
      "                                                    0\n",
      "0   MARCOS RODOLFO CELENZA BELLINI Escala Summary,...\n",
      "1                  Generated 13 May 2025, 14:10 (VCP)\n",
      "2                  Wed, 30  April 2025 (Local time)th\n",
      "3                       Off (FR) 18:45 - 18:45 +1 VCP\n",
      "4                      Fri, 2 May 2025 (Local time)nd\n",
      "5                       Off (FR) 06:10 - 06:10 +1 VCP\n",
      "6                      Sat, 3 May 2025 (Local time)rd\n",
      "7                       Off (FR) 06:10 - 06:10 +1 VCP\n",
      "8                      Sun, 4 May 2025 (Local time)th\n",
      "9                      Apresentação 06:10 - 06:10 VCP\n",
      "10                    Reserva (SEA) 06:10 - 11:30 VCP\n",
      "11                          Release 11:30 - 11:30 VCP\n",
      "12                     Apresentação 13:00 - 13:00 VCP\n",
      "13                    Reserva (REX) 13:00 - 19:00 VCP\n",
      "14                          Release 19:00 - 19:00 VCP\n",
      "15                     Mon, 5 May 2025 (Local time)th\n",
      "16                     Apresentação 20:50 - 20:50 VCP\n",
      "17                    Reserva (R21) 20:50 - 23:50 VCP\n",
      "18                          Release 23:50 - 23:50 VCP\n",
      "19                     Tue, 6 May 2025 (Local time)th\n",
      "20                     Apresentação 20:50 - 20:50 VCP\n",
      "21                    Reserva (REA) 20:50 - 21:30 VCP\n",
      "22  AD4484 (Extra a serviço) 21:30 - 22:42 VCP - C...\n",
      "23                          Release 22:42 - 23:12 CNF\n",
      "24                         Hotel 23:42 - 20:15 +1 CNF\n",
      "25                     Wed, 7 May 2025 (Local time)th\n",
      "26                  Reserva (SBATZ) 14:00 - 20:45 CNF\n",
      "27                     Apresentação 20:45 - 21:34 CNF\n",
      "28  AD4438 21:34 - 00:29 +1 CNF - BEL CA Flight Ti...\n",
      "29                     Thu, 8 May 2025 (Local time)th\n",
      "30                          Release 00:29 - 00:59 BEL\n",
      "31                         Hotel 01:49 - 00:40 +1 BEL\n",
      "32                     Fri, 9 May 2025 (Local time)th\n",
      "33                     Apresentação 01:30 - 02:05 BEL\n",
      "34  AD4439 02:11 - 05:08 BEL - CNF CA Flight Time:...\n",
      "35  AD4188 (Extra a serviço) 06:01 - 07:10 CNF - V...\n",
      "36                          Release 07:10 - 07:40 VCP\n",
      "37                      Off (FR) 22:05 - 22:05 +1 VCP\n",
      "38                    Sat, 10 May 2025 (Local time)th\n",
      "39                      Off (FP) 22:05 - 22:05 +1 VCP\n",
      "40                   Sun, 11  May 2025 (Local time)th\n",
      "41                      Off (FP) 22:05 - 22:05 +1 VCP\n",
      "42                   Mon, 12  May 2025 (Local time)th\n",
      "43                      Off (FR) 22:05 - 22:05 +1 VCP\n",
      "44                   Tue, 13  May 2025 (Local time)th\n",
      "45                      Off (FR) 22:05 - 22:05 +1 VCP\n",
      "46                   Wed, 14  May 2025 (Local time)th\n",
      "47                      Off (FR) 22:05 - 22:05 +1 VCP\n",
      "48                   Thu, 15  May 2025 (Local time)th\n",
      "49                      Off (FR) 22:05 - 22:05 +1 VCP\n"
     ]
    }
   ],
   "source": [
    "# Exibir mensagem de conclusão\n",
    "\n",
    "print(\"Extração de texto concluída e salva em CSV.\")\n",
    "\n",
    "# Exibir o caminho do arquivo CSV salvo\n",
    "\n",
    "print(f\"Arquivo CSV salvo em: {output_csv}\")\n",
    "\n",
    "# Exibir o conteúdo do CSV\n",
    "df = pd.read_csv(output_csv, header=None, encoding='utf-8')\n",
    "print(\"Conteúdo do CSV:\")\n",
    "print(df[0:50])  # Exibe as primeiras linhas do DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40097aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 0 entries\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   Activity  0 non-null      category      \n",
      " 1   Checkin   0 non-null      datetime64[ns]\n",
      " 2   Start     0 non-null      datetime64[ns]\n",
      " 3   Dep       0 non-null      category      \n",
      " 4   Arr       0 non-null      category      \n",
      " 5   End       0 non-null      datetime64[ns]\n",
      " 6   Checkout  0 non-null      datetime64[ns]\n",
      " 7   CAT       0 non-null      category      \n",
      "dtypes: category(4), datetime64[ns](4)\n",
      "memory usage: 564.0 bytes\n"
     ]
    }
   ],
   "source": [
    "# a estrutura do CSV deve conter as colunas:\n",
    "df_escala_inicial = pd.DataFrame({\n",
    "    'Activity': pd.Series(dtype='category'),\n",
    "    'Checkin': pd.Series(dtype='datetime64[ns]'),\n",
    "    'Start': pd.Series(dtype='datetime64[ns]'),\n",
    "    'Dep': pd.Series(dtype='category'),\n",
    "    'Arr': pd.Series(dtype='category'),\n",
    "    'End': pd.Series(dtype='datetime64[ns]'),\n",
    "    'Checkout': pd.Series(dtype='datetime64[ns]'),\n",
    "    'CAT': pd.Series(dtype='category')\n",
    "})\n",
    "\n",
    "df_escala_inicial.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45faabfb",
   "metadata": {},
   "source": [
    "\n",
    "# INICIAR A LEITURA DO ARQUIVO CSV E PROCESSAMENTO DOS DADOS\n",
    "# LOOP NO ARQUIVO CSV PARA PROCESSAR AS LINHAS E ADICIONAR AO DataFrame\n",
    "for index, row in df_escala_inicial.iterrows():\n",
    "    linha = row[0]  # Acessa a coluna que contém o texto extraído\n",
    "    if linha.strip():  # Verifica se a linha não está vazia\n",
    "\n",
    "        # Dividir a linha em colunas usando regex para capturar os campos\n",
    "        #colunas = re.split(r'\\s{2,}', linha.strip())\n",
    "        \n",
    "        # SE A LINHA CONTIVER ','\n",
    "        if ',' in linha:\n",
    "            # colocar os valores apos a virgula até encontrar '(' na variavel var_data\n",
    "            # Extrair os valores após a vírgula até encontrar o caractere '\n",
    "            after_comma = linha.split(',', 1)[1]  # pega tudo após a primeira vírgula\n",
    "            var_data = after_comma.split(\"(\")[0].strip()\n",
    "            \n",
    "            print(f\"VAR DATA: {var_data}\")\n",
    "            \n",
    "            # imprimir 80 caracteres '-'\n",
    "            print('-' * 80)\n",
    "            \n",
    "            # ir para a proxima linha\n",
    "            continue\n",
    "        # caso a linha possua Off\n",
    "        if 'Off' in linha:\n",
    "            # Extrair os valores após ( até encontrar o caractere )\n",
    "            after_parenthesis = linha.split('(', 1)[1]  # pega tudo após o primeiro '('\n",
    "            var_activity = after_parenthesis.split(\")\")[0].strip()  # pega tudo até o primeiro ')'\n",
    "            \n",
    "            print(f\"VAR ACTIVITY: {var_activity}\")\n",
    "            \n",
    "            # na proxima coluna temos o horário de checkin\n",
    "            var_checkin = after_parenthesis.split(\")\")[1].strip()  # pega tudo após o primeiro ')'      \n",
    "            \n",
    "            # Extrair o horário de checkin e start\n",
    "            var_checkin_time = var_checkin.split()[0]  # pega o primeiro horário\n",
    "            var_start_time = var_checkin_time \n",
    "            \n",
    "            print(f\"VAR CHECKIN TIME: {var_checkin_time}\")  \n",
    "            print(f\"VAR START TIME: {var_start_time}\")  \n",
    "\n",
    "            \n",
    "            print('-' * 80)\n",
    "            # ir para a proxima linha\n",
    "            continue  \n",
    "                        \n",
    "        if 'Apresentacao' not in linha:\n",
    "            # caso a proxima linha inicie com Reserva\n",
    "            if index + 1 < len(df):  # Verifica se há uma próxima linha\n",
    "                proxima_linha = df.iloc[index + 1, 0]  # Acessa a próxima linha\n",
    "                if proxima_linha.startswith('Reserva'):\n",
    "                    # Extrair a activity da próxima linha\n",
    "                    proxima_colunas = proxima_linha.split()  # Divide a linha em colunas usando espaços como delimitador\n",
    "                    var_activity = proxima_colunas[0]  # A primeira coluna é a atividade\n",
    "                    var_start_time = proxima_colunas[1]  # A segunda coluna é o horário de início  \n",
    "                    # Extrair o horário de checkin da próxima linha\n",
    "                    var_checkin_time = proxima_colunas[1]  # A segunda coluna é o horário de checkin\n",
    "                    # retroceder uma linha\n",
    "                    #colunas = df.iloc[index - 1, 0].split()  # Divide a linha anterior em colunas usando espaços como delimitador\n",
    "            \n",
    "            \n",
    "            ##### PAREI AQUI FALTA COMPLETAR O DIA 4 QUE TEM RESERVA INTERRUPÇÃO E OUTRA RESERVA \n",
    "                                \n",
    "            var_checkin_time = var_checkin.split()[0]  # pega o primeiro horário\n",
    "            # tudo da primeira coluna na linha atual\n",
    "            colunas = linha.split()  # Divide a linha em colunas usando espaços como delimitador\n",
    "            var_activity = colunas[0]  # A primeira coluna é a atividade \n",
    "\n",
    "            print(f\"VAR ACTIVITY: {var_activity}\")\n",
    "            print(f\"VAR CHECKIN TIME: {var_checkin_time}\")                  \n",
    "            print(f\"VAR START TIME: {var_start_time}\")            \n",
    "            #print('-' * 80)\n",
    "            # ir para a proxima linha\n",
    "            continue  \n",
    "            # caso a activity seja Reserva, pegar o horário de checkin\n",
    "            \n",
    "            # retroceder uma linha\n",
    "            colunas = df.iloc[index - 1, 0].split()  # Divide a linha anterior em colunas usando espaços como delimitador\n",
    "        \"\"\"        \n",
    "        # Verificar se a linha tem o número correto de colunas\n",
    "        if len(colunas) >= 1: #7:\n",
    "            # Criar um dicionário com os dados da linha\n",
    "            dados = {\n",
    "                'Activity': colunas[0],\n",
    "                'Checkin': pd.to_datetime(colunas[1], errors='coerce'),\n",
    "                'Start': pd.to_datetime(colunas[2], errors='coerce'),\n",
    "                'Dep': colunas[3],\n",
    "                'Arr': colunas[4],\n",
    "                'End': pd.to_datetime(colunas[5], errors='coerce'),\n",
    "                'Checkout': pd.to_datetime(colunas[6], errors='coerce'),\n",
    "                'CAT': colunas[7] if len(colunas) > 7 else None\n",
    "            }\n",
    "            # Adicionar os dados ao DataFrame\n",
    "            df_escala_inicial = df_escala_inicial.append(dados, ignore_index=True)\n",
    "        \"\"\"\n",
    "        # gravando os dados no DataFrame\n",
    "        df_escala_inicial = df_escala_inicial.append({\n",
    "            'Activity': var_activity,\n",
    "            'Checkin': pd.to_datetime(var_checkin_time, errors='coerce'),\n",
    "            'Start': pd.to_datetime(var_start_time, errors='coerce'),\n",
    "            'Dep': None,  # Coluna Dep não está sendo preenchida\n",
    "            'Arr': None,  # Coluna Arr não está sendo preenchida\n",
    "            'End': None,  # Coluna End não está sendo preenchida\n",
    "            'Checkout': None,  # Coluna Checkout não está sendo preenchida\n",
    "            'CAT': None  # Coluna CAT não está sendo preenchida\n",
    "        }, ignore_index=True)\n",
    "        \n",
    "print(f\"DATAFRAME CRIADO: {(df_escala_inicial)}\")\n",
    "\n",
    "print(df_escala_inicial.head(50))  # Exibe as primeiras 50 linhas do DataFrame resultante\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7900b9e",
   "metadata": {},
   "source": [
    "m# Exibir o DataFrame resultante completo\n",
    "\n",
    "print(\"DataFrame completo:\")\n",
    "print(df_escala_inicial.to_string(index=False))  # Exibe o DataFrame completo sem o índice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74ffae4",
   "metadata": {},
   "source": [
    "# Exibir o número de linhas e colunas do DataFrame resultante\n",
    "print(f\"Número de linhas: {df_escala_inicial.shape[0]}, Número de colunas: {df_escala_inicial.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0ac2f5",
   "metadata": {},
   "source": [
    "# Exibir informações do DataFrame resultante\n",
    "print(\"Informações do DataFrame resultante:\")\n",
    "print(df_escala_inicial.info())  # Exibe informações sobre o DataFrame, como tipos de dados e número de entradas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1926515",
   "metadata": {},
   "source": [
    "# Exibir estatísticas descritivas do DataFrame resultante\n",
    "print(\"Estatísticas descritivas do DataFrame resultante:\")\n",
    "print(df_escala_inicial.describe(include='all'))  # Exibe estatísticas descritivas, incluindo colunas não numéricas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ed08a6",
   "metadata": {},
   "source": [
    "# Exibir o DataFrame como uma tabela formatada\n",
    "\n",
    "#Exibir o DataFrame completo\n",
    "#print(\"DataFrame completo:\")  \n",
    "#print(df.to_string(index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c18a61",
   "metadata": {},
   "source": [
    "# Exibir o número de linhas e colunas do DataFrame\n",
    "print(f\"Número de linhas: {df_escala_inicial.shape[0]}, Número de colunas: {df_escala_inicial.shape[1]}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562db648",
   "metadata": {},
   "source": [
    "# Exibir informações do DataFrame\n",
    "print(\"Informações do DataFrame:\")\n",
    "print(df.info())  # Exibe informações sobre o DataFrame, como tipos de dados e número de entradas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004cd5ba",
   "metadata": {},
   "source": [
    "# Exibir estatísticas descritivas do DataFrame\n",
    "print(\"Estatísticas descritivas do DataFrame:\") \n",
    "print(df.describe(include='all'))  # Exibe estatísticas descritivas, incluindo colunas não numéricas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aff2d54",
   "metadata": {},
   "source": [
    "# Exibir o DataFrame como uma tabela formatada\n",
    "print(\"DataFrame formatado:\")\n",
    "print(df.to_markdown(index=False))  # Exibe o DataFrame formatado como uma tabela Markdown\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fc9570",
   "metadata": {},
   "source": [
    "# Exibir o DataFrame como uma tabela HTML\n",
    "print(\"DataFrame como tabela HTML:\")Markdown\n",
    "print(df.to_html(index=False))  # Exibe o DataFrame formatado como uma tabela HTML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd11f100",
   "metadata": {},
   "source": [
    "# Exibir o DataFrame como uma tabela LaTeX  \n",
    "print(\"DataFrame como tabela LaTeX:\")\n",
    "print(df.to_latex(index=False))  # Exibe o DataFrame formatado como uma tabela LaTeX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0305205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### limpar o terminal\n",
    "import os\n",
    "os.system('cls' if os.name == 'nt' else 'clear')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8e157a",
   "metadata": {},
   "source": [
    "# Exibir o DataFrame como uma tabela JSON\n",
    "print(\"DataFrame como tabela JSON:\")\n",
    "print(df_escala_inicial.to_json(orient='records', lines=True))  # Exibe o DataFrame formatado como uma tabela JSON\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8cc58f",
   "metadata": {},
   "source": [
    "# Exibir o DataFrame como uma tabela Excel\n",
    "#print(\"DataFrame como tabela Excel:\")\n",
    "#excel_output = filedialog.asksaveasfilename(defaultextension=\".xlsx\", filetypes=[(\"Excel files\", \"*.xlsx\")])\n",
    "#df.to_excel(excel_output, index=False)  # Salva o DataFrame como um arquivo Excel \n",
    "#print(f\"DataFrame salvo como Excel em: {excel_output}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d41a2eb",
   "metadata": {},
   "source": [
    "# Exibir o DataFrame como uma tabela Parquet  \n",
    "print(\"DataFrame como tabela Parquet:\")\n",
    "parquet_output = filedialog.asksaveasfilename(defaultextension=\".parquet\", filetypes=[(\"Parquet files\", \"*.parquet\")])  \n",
    "#df.to_parquet(parquet_output, index=False)  # Salva o DataFrame como um arquivo Parquet\n",
    "print(f\"DataFrame salvo como Parquet em: {parquet_output}\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8704f15d",
   "metadata": {},
   "source": [
    "# Exibir o DataFrame como uma tabela Feather\n",
    "print(\"DataFrame como tabela Feather:\")\n",
    "feather_output = filedialog.asksaveasfilename(defaultextension=\".feather\", filetypes=[(\"Feather files\", \"*.feather\")])\n",
    "df.to_feather(feather_output)  # Salva o DataFrame como um arquivo Feather  \n",
    "print(f\"DataFrame salvo como Feather em: {feather_output}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfaac99",
   "metadata": {},
   "source": [
    "# Exibir o DataFrame como uma tabela HDF5\n",
    "print(\"DataFrame como tabela HDF5:\")\n",
    "hdf5_output = filedialog.asksaveasfilename(defaultextension=\".h5\", filetypes=[(\"HDF5 files\", \"*.h5\")])\n",
    "df.to_hdf(hdf5_output, key='data', mode='w')  # Salva o DataFrame como um arquivo HDF5  \n",
    "print(f\"DataFrame salvo como HDF5 em: {hdf5_output}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1e7a8b",
   "metadata": {},
   "source": [
    "# Exibir o DataFrame como uma tabela SQL\n",
    "print(\"DataFrame como tabela SQL:\")\n",
    "import sqlite3\n",
    "sql_output = filedialog.asksaveasfilename(defaultextension=\".db\", filetypes=[(\"SQLite files\", \"*.db\")])\n",
    "conn = sqlite3.connect(sql_output)  # Conecta ou cria um banco de dados SQLite\n",
    "df.to_sql('tabela', conn, if_exists='replace', index=False)  # Salva o DataFrame como uma tabela SQL\n",
    "print(f\"DataFrame salvo como SQL em: {sql_output}\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c00e2b",
   "metadata": {},
   "source": [
    "# Fechar a conexão com o banco de dados SQLite\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f86f9d",
   "metadata": {},
   "source": [
    "# Exibir o DataFrame como uma tabela JSON Lines\n",
    "print(\"DataFrame como tabela JSON Lines:\")\n",
    "print(df.to_json(orient='records', lines=True))  # Exibe o DataFrame formatado como uma tabela JSON Lines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85751532",
   "metadata": {},
   "source": [
    "# Exibir o DataFrame como uma tabela CSV\n",
    "print(\"DataFrame como tabela CSV:\") \n",
    "print(df.to_csv(index=False))  # Exibe o DataFrame formatado como uma tabela CSV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c99e57",
   "metadata": {},
   "source": [
    "# Exibir o DataFrame como uma tabela TSV  \n",
    "print(\"DataFrame como tabela TSV:\")\n",
    "print(df.to_csv(sep='\\t', index=False))  # Exibe o DataFrame formatado como uma tabela TSV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52bee1e",
   "metadata": {},
   "source": [
    "# Exibir o DataFrame como uma tabela XML\n",
    "print(\"DataFrame como tabela XML:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d6fe09",
   "metadata": {},
   "source": [
    "# Carregar o DataFrame a partir do arquivo CSV\n",
    "df_xml = pd.read_csv(output_csv, header=None, encoding='utf-8')\n",
    "#print(df_xml.to_xml(index=False))  # Exibe o DataFrame formatado como uma tabela XML\n",
    "# Exibir o DataFrame como uma tabela Markdown\n",
    "print(\"DataFrame como tabela Markdown:\")\n",
    "print(df.to_markdown(index=False))  # Exibe o DataFrame formatado como uma tabela Markdown\n",
    "display(df_xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d17d9572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo selecionado: C:/Users/Ricardo/OneDrive/Área de Trabalho/SISTEMA AUDITORIA AERONAUTAS/AERONAUTAS/ARQUIVOS ORIGINAIS/MARCOS BELLINI/BELLINI MAIO 2025.csv\n",
      "DataFrame carregado com sucesso.\n",
      "Nome do arquivo: MARCOS RODOLFO CELENZA BELLINI Escala Summary, 01 May - 01 Jun 2025\n",
      "Linha encontrada: Wed, 30  April 2025 (Local time)th\n",
      "Data encontrada HOJE: 30/April/2025\n",
      "Próxima linha HOJE: Off (FR) 18:45 - 18:45 +1 VCP\n",
      "Linha iniciada com 'Off'\n",
      "Atividade encontrada: FR\n",
      "Horário de checkin encontrado: 18:45\n",
      "Horário de início encontrado: 18:45\n",
      "Horário de fim encontrado: 18:45\n",
      "Horário de checkout encontrado: 18:45\n",
      "Data e hora de checkin: 30/April/2025 18:45\n",
      "Data e hora de início: 30/April/2025 18:45\n",
      "Data e hora de fim: 01/May/2025 18:45\n",
      "Data e hora de checkout: 01/May/2025 18:45\n",
      "Dep: VCP\n",
      "Arr: VCP\n",
      "--------------------------------------------------------------------------------\n",
      "Ativity: FR, Checkin: 30/April/2025 18:45, Start: 30/April/2025 18:45, Dep: VCP, Arr: VCP, End: 01/May/2025 18:45, Checkout: 01/May/2025 18:45\n",
      "--------------------------------------------------------------------------------\n",
      "Linha encontrada: Fri, 2 May 2025 (Local time)nd\n",
      "Data encontrada HOJE: 2/May/2025\n",
      "Próxima linha HOJE: Off (FR) 06:10 - 06:10 +1 VCP\n",
      "Linha iniciada com 'Off'\n",
      "Atividade encontrada: FR\n",
      "Horário de checkin encontrado: 06:10\n",
      "Horário de início encontrado: 06:10\n",
      "Horário de fim encontrado: 06:10\n",
      "Horário de checkout encontrado: 06:10\n",
      "Data e hora de checkin: 2/May/2025 06:10\n",
      "Data e hora de início: 2/May/2025 06:10\n",
      "Data e hora de fim: 03/May/2025 06:10\n",
      "Data e hora de checkout: 03/May/2025 06:10\n",
      "Dep: VCP\n",
      "Arr: VCP\n",
      "--------------------------------------------------------------------------------\n",
      "Ativity: FR, Checkin: 2/May/2025 06:10, Start: 2/May/2025 06:10, Dep: VCP, Arr: VCP, End: 03/May/2025 06:10, Checkout: 03/May/2025 06:10\n",
      "--------------------------------------------------------------------------------\n",
      "Linha encontrada: Sat, 3 May 2025 (Local time)rd\n",
      "Data encontrada HOJE: 3/May/2025\n",
      "Próxima linha HOJE: Off (FR) 06:10 - 06:10 +1 VCP\n",
      "Linha iniciada com 'Off'\n",
      "Atividade encontrada: FR\n",
      "Horário de checkin encontrado: 06:10\n",
      "Horário de início encontrado: 06:10\n",
      "Horário de fim encontrado: 06:10\n",
      "Horário de checkout encontrado: 06:10\n",
      "Data e hora de checkin: 3/May/2025 06:10\n",
      "Data e hora de início: 3/May/2025 06:10\n",
      "Data e hora de fim: 04/May/2025 06:10\n",
      "Data e hora de checkout: 04/May/2025 06:10\n",
      "Dep: VCP\n",
      "Arr: VCP\n",
      "--------------------------------------------------------------------------------\n",
      "Ativity: FR, Checkin: 3/May/2025 06:10, Start: 3/May/2025 06:10, Dep: VCP, Arr: VCP, End: 04/May/2025 06:10, Checkout: 04/May/2025 06:10\n",
      "--------------------------------------------------------------------------------\n",
      "Linha encontrada: Sun, 4 May 2025 (Local time)th\n",
      "Data encontrada HOJE: 4/May/2025\n",
      "Próxima linha HOJE: Apresentação 06:10 - 06:10 VCP\n",
      "Linha iniciada com 'Apresentação', continuando o loop...\n",
      "Linha não iniciada com um dia da semana: Reserva (SEA) 06:10 - 11:30 VCP\n",
      "Atividade encontrada: Reserva\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'var_checkin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 142\u001b[0m\n\u001b[0;32m    140\u001b[0m var_hora_end \u001b[38;5;241m=\u001b[39m linha\u001b[38;5;241m.\u001b[39msplit()[\u001b[38;5;241m4\u001b[39m]\n\u001b[0;32m    141\u001b[0m var_hora_checkout \u001b[38;5;241m=\u001b[39m linha\u001b[38;5;241m.\u001b[39msplit()[\u001b[38;5;241m4\u001b[39m]\n\u001b[1;32m--> 142\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHorário de checkin encontrado: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar_checkin\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m var_start \u001b[38;5;241m=\u001b[39m linha\u001b[38;5;241m.\u001b[39msplit()[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHorário de início encontrado: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar_start\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'var_checkin' is not defined"
     ]
    }
   ],
   "source": [
    "# iniciar a leitura de cada linha do CSV e processar os dados\n",
    "# encontrar a primeira linha que contém a palavra correspondente as 3 primeiras letras do dia da semana em ingles no inicio da linha\n",
    "\n",
    "path = filedialog.askopenfilename(title=\"Selecione o arquivo CSV\", filetypes=[(\"CSV files\", \"*.csv\")])\n",
    "\n",
    "print(f\"Arquivo selecionado: {path}\")\n",
    "\n",
    "# Verificar se o caminho do arquivo foi selecionado\n",
    "if not path:\n",
    "    print(\"Nenhum arquivo selecionado.\")\n",
    "    exit()\n",
    "\n",
    "df_escala_inicial = pd.read_csv(path, header=None)\n",
    "print(\"DataFrame carregado com sucesso.\")\n",
    "#print(f\"DataFrame inicial: {df_escala_inicial.head(10)}\")  # Exibe as primeiras 10 linhas do DataFrame\n",
    "\n",
    "# nome do arquivo CSV\n",
    "var_nome_arquivo = linha = df_escala_inicial.iloc[0, 0]  # Extrai o nome do arquivo do caminho completo\n",
    "print(f\"Nome do arquivo: {var_nome_arquivo}\")\n",
    "\n",
    "# Loop para ler o arquivo CSV até encontrar uma linha que comece com um dia da semana\n",
    "linha = df_escala_inicial.iloc[2, 0]  # Acessa a primeira linha do DataFrame\n",
    "n = 2\n",
    "\n",
    "while True:\n",
    "    # verificar se chegou ao final do DataFrame\n",
    "    if n >= len(df_escala_inicial):\n",
    "        print(\"Chegou ao final do DataFrame, encerrando o loop.\")\n",
    "        break\n",
    "\n",
    "    linha = df_escala_inicial.iloc[n, 0]\n",
    "    \n",
    "    if linha.startswith('Mon') or linha.startswith('Tue') or linha.startswith('Wed') or linha.startswith('Thu') or linha.startswith('Fri') or linha.startswith('Sat') or linha.startswith('Sun'):\n",
    "        print(f\"Linha encontrada: {linha}\")\n",
    "        # variavel que contem a data\n",
    "        var_data = linha.split()[1] + \"/\" + linha.split()[2] + \"/\" + linha.split()[3] # Pega a data e hora da linha  \n",
    "        print(f\"Data encontrada HOJE: {var_data}\")\n",
    "        # avançar para a próxima linha do CSV\n",
    "        n += 1\n",
    "        linha = df_escala_inicial.iloc[n, 0]\n",
    "        print(f\"Próxima linha HOJE: {linha}\")    \n",
    "        \n",
    "        # se a linha iniciar com a palavra 'Apresentação', continuar o loop\n",
    "        if linha.startswith('Apresentação'):\n",
    "            print(\"Linha iniciada com 'Apresentação', continuando o loop...\")\n",
    "            n += 1\n",
    "            continue\n",
    "\n",
    "        # se a linha iniciar com a palavra 'Off', parar o loop\n",
    "        if linha.startswith('Off'):\n",
    "            print(\"Linha iniciada com 'Off'\")\n",
    "            \n",
    "            # variavel que contem a atividade sem os parênteses\n",
    "            var_activity = linha.split()[1]\n",
    "            # retirar os parênteses da atividade\n",
    "            var_activity = var_activity.replace('(', '').replace(')', '')\n",
    "            print(f\"Atividade encontrada: {var_activity}\")\n",
    "            \n",
    "            var_hora_checkin = linha.split()[2]  # Pega o horário de checkin da linha\n",
    "            print(f\"Horário de checkin encontrado: {var_hora_checkin}\")\n",
    "            \n",
    "            var_hora_start = var_hora_checkin  # Pega o horário de início da linha\n",
    "            print(f\"Horário de início encontrado: {var_hora_start}\")\n",
    "            \n",
    "            var_hora_end = linha.split()[2]  # Pega o horário de fim da linha\n",
    "            print(f\"Horário de fim encontrado: {var_hora_end}\")\n",
    "            \n",
    "            var_hora_checkout = linha.split()[2]  # Pega o horário de checkout da linha\n",
    "            print(f\"Horário de checkout encontrado: {var_hora_end}\")                  \n",
    "        \n",
    "            # montar as variaveis de data e hora\n",
    "            var_data_hora_checkin = f\"{var_data} {var_hora_checkin}\"\n",
    "            var_data_hora_start = f\"{var_data} {var_hora_start}\"\n",
    "            # as variaveis de data e hora de fim e checkout deverão ser no dia seguinte\n",
    "            var_data_hora_end = (datetime.strptime(var_data, \"%d/%B/%Y\") + timedelta(days=1)).strftime(\"%d/%B/%Y\") + f\" {var_hora_end}\" \n",
    "            var_data_hora_checkout = (datetime.strptime(var_data, \"%d/%B/%Y\") + timedelta(days=1)).strftime(\"%d/%B/%Y\") + f\" {var_hora_checkout}\"\n",
    "            \n",
    "            print(f\"Data e hora de checkin: {var_data_hora_checkin}\")\n",
    "            print(f\"Data e hora de início: {var_data_hora_start}\")\n",
    "            print(f\"Data e hora de fim: {var_data_hora_end}\")\n",
    "            print(f\"Data e hora de checkout: {var_data_hora_checkout}\")\n",
    "            \n",
    "            # variaveis para Dep e Arr\n",
    "            var_dep = linha.split()[6] #if len(linha.split()) > 3 else None\n",
    "            var_arr = linha.split()[6] #if len(linha.split()) > 4 else None  \n",
    "            print(f\"Dep: {var_dep}\")\n",
    "            print(f\"Arr: {var_arr}\")    \n",
    "            \n",
    "            # imprimir 80 caracteres '-'\n",
    "            print('-' * 80)\n",
    "            \n",
    "            # mostrar todas as variaveis numa mesma string\n",
    "            print(f\"Ativity: {var_activity}, Checkin: {var_data_hora_checkin}, Start: {var_data_hora_start}, Dep: {var_dep}, Arr: {var_arr}, End: {var_data_hora_end}, Checkout: {var_data_hora_checkout}\")\n",
    "\n",
    "        # abrir um arquivo CSV para salvar os dados\n",
    "        # nome do arquivo CSV\n",
    "        if not var_nome_arquivo.lower().endswith('.csv'):\n",
    "            var_nome_arquivo = var_nome_arquivo + '.csv'\n",
    "        with open(var_nome_arquivo, 'a', newline='', encoding='utf-8') as csvfile:\n",
    "            csv_writer = csv.writer(csvfile)\n",
    "            # escrever o cabeçalho se o arquivo estiver vazio\n",
    "            if csvfile.tell() == 0:\n",
    "                csv_writer.writerow(['Activity', 'Checkin', 'Start', 'Dep', 'Arr', 'End', 'Checkout'])\n",
    "            # escrever os dados no arquivo CSV\n",
    "            csv_writer.writerow([var_activity, var_data_hora_checkin, var_data_hora_start, var_dep, var_arr, var_data_hora_end, var_data_hora_checkout])\n",
    "\n",
    "            n = n + 1\n",
    "            # atualizar a linha para a próxima iteração\n",
    "            # imprimir 80 caracteres '-'\n",
    "            print('-' * 80)\n",
    "    else:\n",
    "        print(f\"Linha não iniciada com um dia da semana: {linha}\")\n",
    "        n += 1\n",
    "        \n",
    "        var_activity = linha.split()[0]\n",
    "        print(f\"Atividade encontrada: {var_activity}\")\n",
    "        # verificar se a atividade é 'Apresentação' ou 'Release'\n",
    "        \n",
    "        \n",
    "        \n",
    "        #if var_activity.startswith('Apresentação') or var_activity.startswith('Release'):\n",
    "        #    print(f\"Atividade iniciada com 'Apresentação' ou 'Release', continuando o loop...\")\n",
    "        #    n += 1\n",
    "        #    continue\n",
    "        \n",
    "        \n",
    "        # se var_activity for 'Apresentação', 'Release' continuar o loop\n",
    "        \n",
    "        # verificar se a atividade inicia com \"AD\"\n",
    "        #if var_activity.startswith('AD'):\n",
    "            # pegar o horario de apresentação da linha anterior\n",
    "            #n -= 1\n",
    "            #linha_anterior = df_escala_inicial.iloc[n, 0]\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        var_hora_checkin = linha.split()[4]\n",
    "        var_hora_start = linha.split()[4]\n",
    "        var_hora_end = linha.split()[4]\n",
    "        var_hora_checkout = linha.split()[4]\n",
    "        print(f\"Horário de checkin encontrado: {var_checkin}\")\n",
    "        \n",
    "        var_start = linha.split()[2]\n",
    "        print(f\"Horário de início encontrado: {var_start}\")\n",
    "        \n",
    "        var_end = linha.split()[4]\n",
    "        print(f\"Horário de fim encontrado: {var_end}\")\n",
    "        \n",
    "        var_checkout = linha.split()[4]\n",
    "        print(f\"Horário de checkout encontrado: {var_checkout}\")\n",
    "        \n",
    "        # montar as variaveis de data e hora\n",
    "        # se var_activity iniciar com 'AD'\n",
    "        #if var_activity.startswith('AD'):\n",
    "            # Apenas concatena a data e hora como string\n",
    "        #    var_data_hora_end = f\"{var_data} {var_end}\"\n",
    "        #    var_data_hora_checkout = f\"{var_data} {var_checkout}\"\n",
    "        #else: \n",
    "        var_data_hora_checkin = f\"{var_data} {var_checkin}\"\n",
    "        var_data_hora_start = f\"{var_data} {var_start}\"\n",
    "        var_data_hora_end = f\"{var_data} {var_end}\"\n",
    "        var_data_hora_checkout = f\"{var_data} {var_checkout}\"\n",
    "        \n",
    "        print(f\"Data e hora de checkin: {var_data_hora_checkin}\")\n",
    "        print(f\"Data e hora de início: {var_data_hora_start}\")\n",
    "        print(f\"Data e hora de fim: {var_data_hora_end}\")\n",
    "        print(f\"Data e hora de checkout: {var_data_hora_checkout}\")\n",
    "        \n",
    "        # variaveis para Dep e Arr\n",
    "        #if var_activity.startswith('AD'):\n",
    "        #    var_dep = linha.split()[5] if len(linha.split()) > 5 else None\n",
    "        #    var_arr = linha.split()[7] if len(linha.split()) > 6 else None\n",
    "        #else:\n",
    "        var_dep = linha.split()[2] #if len(linha.split()) > 5 else None\n",
    "        var_arr = linha.split()[4] #if len(linha.split()) > 6 else None\n",
    "        \n",
    "        print(f\"Dep: {var_dep}\")\n",
    "        print(f\"Arr: {var_arr}\")\n",
    "        \n",
    "        # imprimir 80 caracteres '-'\n",
    "        print('-' * 80)\n",
    "        \n",
    "        # mostrar todas as variaveis numa mesma string\n",
    "        print(f\"Ativity: {var_activity}, Checkin: {var_data_hora_checkin}, Start: {var_data_hora_start}, Dep: {var_dep}, Arr: {var_arr}, End: {var_data_hora_end}, Checkout: {var_data_hora_checkout}\")\n",
    "          \n",
    "        # abrir um arquivo CSV para salvar os dados\n",
    "        # nome do arquivo CSV\n",
    "        if not var_nome_arquivo.lower().endswith('.csv'):\n",
    "            var_nome_arquivo = var_nome_arquivo + '.csv'\n",
    "        with open(var_nome_arquivo, 'a', newline='', encoding='utf-8') as csvfile:\n",
    "            csv_writer = csv.writer(csvfile)\n",
    "            # escrever o cabeçalho se o arquivo estiver vazio\n",
    "            if csvfile.tell() == 0:\n",
    "                csv_writer.writerow(['Activity', 'Checkin', 'Start', 'Dep', 'Arr', 'End', 'Checkout'])\n",
    "            # escrever os dados no arquivo CSV\n",
    "            csv_writer.writerow([var_activity, var_data_hora_checkin, var_data_hora_start, var_dep, var_arr, var_data_hora_end, var_data_hora_checkout])\n",
    "        print(f\"Dados salvos no arquivo: {var_nome_arquivo}\")\n",
    "\n",
    "\n",
    "     \n",
    "        \n",
    "        # Exibir mensagem de conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1011249",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
