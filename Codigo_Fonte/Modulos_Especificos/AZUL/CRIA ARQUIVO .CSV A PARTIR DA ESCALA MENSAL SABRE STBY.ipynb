{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf148fc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pendulum'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPyPDF2\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m timedelta, time, datetime\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpendulum\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpendulum\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m now, yesterday, tomorrow, timezone, date\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdateutil\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pendulum'"
     ]
    }
   ],
   "source": [
    "#### IMPORTAR BIBLIOTECAS NECESSÁRIAS\n",
    "import csv\n",
    "from typing import Union, Any\n",
    "#import tabula\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import PyPDF2\n",
    "from datetime import timedelta, time, datetime\n",
    "\n",
    "import pendulum\n",
    "from pendulum import now, yesterday, tomorrow, timezone, date\n",
    "import dateutil\n",
    "import os\n",
    "import warnings\n",
    "import requests\n",
    "import pprint\n",
    "import json\n",
    "from tkinter import filedialog\n",
    "from pandas import DataFrame\n",
    "from pandas.io.parsers import TextFileReader\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e040293",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### LEITURA DO ARQUIVO DE SIGLAS SABRE\n",
    "path = filedialog.askopenfilename()\n",
    "\n",
    "print(path)\n",
    "\n",
    "imported_data = open(path, 'rb')\n",
    "pdf_reader = PyPDF2.PdfReader(imported_data)\n",
    "num_paginas = len(pdf_reader.pages)\n",
    "print(f\"Número de páginas: {num_paginas}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c97462c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, pagina in enumerate(pdf_reader.pages):\n",
    "    print(f\"--- Página {i+1} ---\")\n",
    "    print(pagina.extract_text())\n",
    "    \n",
    "# SALVAR O TEXTO EXTRAÍDO EM UM ARQUIVO CSV\n",
    "output_csv = filedialog.asksaveasfilename(defaultextension=\".csv\", filetypes=[(\"CSV files\", \"*.csv\")])\n",
    "with open(output_csv, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    \n",
    "    for i, pagina in enumerate(pdf_reader.pages):\n",
    "        texto = pagina.extract_text()\n",
    "        linhas = texto.split('\\n')\n",
    "        \n",
    "        for linha in linhas:\n",
    "            csv_writer.writerow([linha])\n",
    "    print(f\"Texto extraído salvo em: {output_csv}\")\n",
    "    #print(f\"A atividade é : {output_csv.split('/')[-1]}\")  # Exibe apenas o nome do arquivo\n",
    "\n",
    "# Fechar o arquivo PDF\n",
    "imported_data.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c93365c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir mensagem de conclusão\n",
    "\n",
    "print(\"Extração de texto concluída e salva em CSV.\")\n",
    "\n",
    "# Exibir o caminho do arquivo CSV salvo\n",
    "\n",
    "print(f\"Arquivo CSV salvo em: {output_csv}\")\n",
    "\n",
    "# Exibir o conteúdo do CSV\n",
    "df = pd.read_csv(output_csv, header=None, encoding='utf-8')\n",
    "print(\"Conteúdo do CSV:\")\n",
    "print(df[0:50])  # Exibe as primeiras linhas do DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40097aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a estrutura do CSV deve conter as colunas:\n",
    "df_escala_inicial = pd.DataFrame({\n",
    "    'Activity': pd.Series(dtype='category'),\n",
    "    'Checkin': pd.Series(dtype='datetime64[ns]'),\n",
    "    'Start': pd.Series(dtype='datetime64[ns]'),\n",
    "    'Dep': pd.Series(dtype='category'),\n",
    "    'Arr': pd.Series(dtype='category'),\n",
    "    'End': pd.Series(dtype='datetime64[ns]'),\n",
    "    'Checkout': pd.Series(dtype='datetime64[ns]'),\n",
    "    'CAT': pd.Series(dtype='category')\n",
    "})\n",
    "\n",
    "df_escala_inicial.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45faabfb",
   "metadata": {},
   "source": [
    "\n",
    "# INICIAR A LEITURA DO ARQUIVO CSV E PROCESSAMENTO DOS DADOS\n",
    "# LOOP NO ARQUIVO CSV PARA PROCESSAR AS LINHAS E ADICIONAR AO DataFrame\n",
    "for index, row in df_escala_inicial.iterrows():\n",
    "    linha = row[0]  # Acessa a coluna que contém o texto extraído\n",
    "    if linha.strip():  # Verifica se a linha não está vazia\n",
    "\n",
    "        # Dividir a linha em colunas usando regex para capturar os campos\n",
    "        #colunas = re.split(r'\\s{2,}', linha.strip())\n",
    "        \n",
    "        # SE A LINHA CONTIVER ','\n",
    "        if ',' in linha:\n",
    "            # colocar os valores apos a virgula até encontrar '(' na variavel var_data\n",
    "            # Extrair os valores após a vírgula até encontrar o caractere '\n",
    "            after_comma = linha.split(',', 1)[1]  # pega tudo após a primeira vírgula\n",
    "            var_data = after_comma.split(\"(\")[0].strip()\n",
    "            \n",
    "            print(f\"VAR DATA: {var_data}\")\n",
    "            \n",
    "            # imprimir 80 caracteres '-'\n",
    "            print('-' * 80)\n",
    "            \n",
    "            # ir para a proxima linha\n",
    "            continue\n",
    "        # caso a linha possua Off\n",
    "        if 'Off' in linha:\n",
    "            # Extrair os valores após ( até encontrar o caractere )\n",
    "            after_parenthesis = linha.split('(', 1)[1]  # pega tudo após o primeiro '('\n",
    "            var_activity = after_parenthesis.split(\")\")[0].strip()  # pega tudo até o primeiro ')'\n",
    "            \n",
    "            print(f\"VAR ACTIVITY: {var_activity}\")\n",
    "            \n",
    "            # na proxima coluna temos o horário de checkin\n",
    "            var_checkin = after_parenthesis.split(\")\")[1].strip()  # pega tudo após o primeiro ')'      \n",
    "            \n",
    "            # Extrair o horário de checkin e start\n",
    "            var_checkin_time = var_checkin.split()[0]  # pega o primeiro horário\n",
    "            var_start_time = var_checkin_time \n",
    "            \n",
    "            print(f\"VAR CHECKIN TIME: {var_checkin_time}\")  \n",
    "            print(f\"VAR START TIME: {var_start_time}\")  \n",
    "\n",
    "            \n",
    "            print('-' * 80)\n",
    "            # ir para a proxima linha\n",
    "            continue  \n",
    "                        \n",
    "        if 'Apresentacao' not in linha:\n",
    "            # caso a proxima linha inicie com Reserva\n",
    "            if index + 1 < len(df):  # Verifica se há uma próxima linha\n",
    "                proxima_linha = df.iloc[index + 1, 0]  # Acessa a próxima linha\n",
    "                if proxima_linha.startswith('Reserva'):\n",
    "                    # Extrair a activity da próxima linha\n",
    "                    proxima_colunas = proxima_linha.split()  # Divide a linha em colunas usando espaços como delimitador\n",
    "                    var_activity = proxima_colunas[0]  # A primeira coluna é a atividade\n",
    "                    var_start_time = proxima_colunas[1]  # A segunda coluna é o horário de início  \n",
    "                    # Extrair o horário de checkin da próxima linha\n",
    "                    var_checkin_time = proxima_colunas[1]  # A segunda coluna é o horário de checkin\n",
    "                    # retroceder uma linha\n",
    "                    #colunas = df.iloc[index - 1, 0].split()  # Divide a linha anterior em colunas usando espaços como delimitador\n",
    "            \n",
    "            \n",
    "            ##### PAREI AQUI FALTA COMPLETAR O DIA 4 QUE TEM RESERVA INTERRUPÇÃO E OUTRA RESERVA \n",
    "                                \n",
    "            var_checkin_time = var_checkin.split()[0]  # pega o primeiro horário\n",
    "            # tudo da primeira coluna na linha atual\n",
    "            colunas = linha.split()  # Divide a linha em colunas usando espaços como delimitador\n",
    "            var_activity = colunas[0]  # A primeira coluna é a atividade \n",
    "\n",
    "            print(f\"VAR ACTIVITY: {var_activity}\")\n",
    "            print(f\"VAR CHECKIN TIME: {var_checkin_time}\")                  \n",
    "            print(f\"VAR START TIME: {var_start_time}\")            \n",
    "            #print('-' * 80)\n",
    "            # ir para a proxima linha\n",
    "            continue  \n",
    "            # caso a activity seja Reserva, pegar o horário de checkin\n",
    "            \n",
    "            # retroceder uma linha\n",
    "            colunas = df.iloc[index - 1, 0].split()  # Divide a linha anterior em colunas usando espaços como delimitador\n",
    "        \"\"\"        \n",
    "        # Verificar se a linha tem o número correto de colunas\n",
    "        if len(colunas) >= 1: #7:\n",
    "            # Criar um dicionário com os dados da linha\n",
    "            dados = {\n",
    "                'Activity': colunas[0],\n",
    "                'Checkin': pd.to_datetime(colunas[1], errors='coerce'),\n",
    "                'Start': pd.to_datetime(colunas[2], errors='coerce'),\n",
    "                'Dep': colunas[3],\n",
    "                'Arr': colunas[4],\n",
    "                'End': pd.to_datetime(colunas[5], errors='coerce'),\n",
    "                'Checkout': pd.to_datetime(colunas[6], errors='coerce'),\n",
    "                'CAT': colunas[7] if len(colunas) > 7 else None\n",
    "            }\n",
    "            # Adicionar os dados ao DataFrame\n",
    "            df_escala_inicial = df_escala_inicial.append(dados, ignore_index=True)\n",
    "        \"\"\"\n",
    "        # gravando os dados no DataFrame\n",
    "        df_escala_inicial = df_escala_inicial.append({\n",
    "            'Activity': var_activity,\n",
    "            'Checkin': pd.to_datetime(var_checkin_time, errors='coerce'),\n",
    "            'Start': pd.to_datetime(var_start_time, errors='coerce'),\n",
    "            'Dep': None,  # Coluna Dep não está sendo preenchida\n",
    "            'Arr': None,  # Coluna Arr não está sendo preenchida\n",
    "            'End': None,  # Coluna End não está sendo preenchida\n",
    "            'Checkout': None,  # Coluna Checkout não está sendo preenchida\n",
    "            'CAT': None  # Coluna CAT não está sendo preenchida\n",
    "        }, ignore_index=True)\n",
    "        \n",
    "print(f\"DATAFRAME CRIADO: {(df_escala_inicial)}\")\n",
    "\n",
    "print(df_escala_inicial.head(50))  # Exibe as primeiras 50 linhas do DataFrame resultante\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7900b9e",
   "metadata": {},
   "source": [
    "m# Exibir o DataFrame resultante completo\n",
    "\n",
    "print(\"DataFrame completo:\")\n",
    "print(df_escala_inicial.to_string(index=False))  # Exibe o DataFrame completo sem o índice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74ffae4",
   "metadata": {},
   "source": [
    "# Exibir o número de linhas e colunas do DataFrame resultante\n",
    "print(f\"Número de linhas: {df_escala_inicial.shape[0]}, Número de colunas: {df_escala_inicial.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0ac2f5",
   "metadata": {},
   "source": [
    "# Exibir informações do DataFrame resultante\n",
    "print(\"Informações do DataFrame resultante:\")\n",
    "print(df_escala_inicial.info())  # Exibe informações sobre o DataFrame, como tipos de dados e número de entradas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1926515",
   "metadata": {},
   "source": [
    "# Exibir estatísticas descritivas do DataFrame resultante\n",
    "print(\"Estatísticas descritivas do DataFrame resultante:\")\n",
    "print(df_escala_inicial.describe(include='all'))  # Exibe estatísticas descritivas, incluindo colunas não numéricas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ed08a6",
   "metadata": {},
   "source": [
    "# Exibir o DataFrame como uma tabela formatada\n",
    "\n",
    "#Exibir o DataFrame completo\n",
    "#print(\"DataFrame completo:\")  \n",
    "#print(df.to_string(index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c18a61",
   "metadata": {},
   "source": [
    "# Exibir o número de linhas e colunas do DataFrame\n",
    "print(f\"Número de linhas: {df_escala_inicial.shape[0]}, Número de colunas: {df_escala_inicial.shape[1]}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562db648",
   "metadata": {},
   "source": [
    "# Exibir informações do DataFrame\n",
    "print(\"Informações do DataFrame:\")\n",
    "print(df.info())  # Exibe informações sobre o DataFrame, como tipos de dados e número de entradas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004cd5ba",
   "metadata": {},
   "source": [
    "# Exibir estatísticas descritivas do DataFrame\n",
    "print(\"Estatísticas descritivas do DataFrame:\") \n",
    "print(df.describe(include='all'))  # Exibe estatísticas descritivas, incluindo colunas não numéricas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aff2d54",
   "metadata": {},
   "source": [
    "# Exibir o DataFrame como uma tabela formatada\n",
    "print(\"DataFrame formatado:\")\n",
    "print(df.to_markdown(index=False))  # Exibe o DataFrame formatado como uma tabela Markdown\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fc9570",
   "metadata": {},
   "source": [
    "# Exibir o DataFrame como uma tabela HTML\n",
    "print(\"DataFrame como tabela HTML:\")Markdown\n",
    "print(df.to_html(index=False))  # Exibe o DataFrame formatado como uma tabela HTML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd11f100",
   "metadata": {},
   "source": [
    "# Exibir o DataFrame como uma tabela LaTeX  \n",
    "print(\"DataFrame como tabela LaTeX:\")\n",
    "print(df.to_latex(index=False))  # Exibe o DataFrame formatado como uma tabela LaTeX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0305205",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### limpar o terminal\n",
    "import os\n",
    "os.system('cls' if os.name == 'nt' else 'clear')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8e157a",
   "metadata": {},
   "source": [
    "# Exibir o DataFrame como uma tabela JSON\n",
    "print(\"DataFrame como tabela JSON:\")\n",
    "print(df_escala_inicial.to_json(orient='records', lines=True))  # Exibe o DataFrame formatado como uma tabela JSON\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8cc58f",
   "metadata": {},
   "source": [
    "# Exibir o DataFrame como uma tabela Excel\n",
    "#print(\"DataFrame como tabela Excel:\")\n",
    "#excel_output = filedialog.asksaveasfilename(defaultextension=\".xlsx\", filetypes=[(\"Excel files\", \"*.xlsx\")])\n",
    "#df.to_excel(excel_output, index=False)  # Salva o DataFrame como um arquivo Excel \n",
    "#print(f\"DataFrame salvo como Excel em: {excel_output}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d41a2eb",
   "metadata": {},
   "source": [
    "# Exibir o DataFrame como uma tabela Parquet  \n",
    "print(\"DataFrame como tabela Parquet:\")\n",
    "parquet_output = filedialog.asksaveasfilename(defaultextension=\".parquet\", filetypes=[(\"Parquet files\", \"*.parquet\")])  \n",
    "#df.to_parquet(parquet_output, index=False)  # Salva o DataFrame como um arquivo Parquet\n",
    "print(f\"DataFrame salvo como Parquet em: {parquet_output}\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8704f15d",
   "metadata": {},
   "source": [
    "# Exibir o DataFrame como uma tabela Feather\n",
    "print(\"DataFrame como tabela Feather:\")\n",
    "feather_output = filedialog.asksaveasfilename(defaultextension=\".feather\", filetypes=[(\"Feather files\", \"*.feather\")])\n",
    "df.to_feather(feather_output)  # Salva o DataFrame como um arquivo Feather  \n",
    "print(f\"DataFrame salvo como Feather em: {feather_output}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfaac99",
   "metadata": {},
   "source": [
    "# Exibir o DataFrame como uma tabela HDF5\n",
    "print(\"DataFrame como tabela HDF5:\")\n",
    "hdf5_output = filedialog.asksaveasfilename(defaultextension=\".h5\", filetypes=[(\"HDF5 files\", \"*.h5\")])\n",
    "df.to_hdf(hdf5_output, key='data', mode='w')  # Salva o DataFrame como um arquivo HDF5  \n",
    "print(f\"DataFrame salvo como HDF5 em: {hdf5_output}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1e7a8b",
   "metadata": {},
   "source": [
    "# Exibir o DataFrame como uma tabela SQL\n",
    "print(\"DataFrame como tabela SQL:\")\n",
    "import sqlite3\n",
    "sql_output = filedialog.asksaveasfilename(defaultextension=\".db\", filetypes=[(\"SQLite files\", \"*.db\")])\n",
    "conn = sqlite3.connect(sql_output)  # Conecta ou cria um banco de dados SQLite\n",
    "df.to_sql('tabela', conn, if_exists='replace', index=False)  # Salva o DataFrame como uma tabela SQL\n",
    "print(f\"DataFrame salvo como SQL em: {sql_output}\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c00e2b",
   "metadata": {},
   "source": [
    "# Fechar a conexão com o banco de dados SQLite\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f86f9d",
   "metadata": {},
   "source": [
    "# Exibir o DataFrame como uma tabela JSON Lines\n",
    "print(\"DataFrame como tabela JSON Lines:\")\n",
    "print(df.to_json(orient='records', lines=True))  # Exibe o DataFrame formatado como uma tabela JSON Lines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85751532",
   "metadata": {},
   "source": [
    "# Exibir o DataFrame como uma tabela CSV\n",
    "print(\"DataFrame como tabela CSV:\") \n",
    "print(df.to_csv(index=False))  # Exibe o DataFrame formatado como uma tabela CSV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c99e57",
   "metadata": {},
   "source": [
    "# Exibir o DataFrame como uma tabela TSV  \n",
    "print(\"DataFrame como tabela TSV:\")\n",
    "print(df.to_csv(sep='\\t', index=False))  # Exibe o DataFrame formatado como uma tabela TSV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52bee1e",
   "metadata": {},
   "source": [
    "# Exibir o DataFrame como uma tabela XML\n",
    "print(\"DataFrame como tabela XML:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d6fe09",
   "metadata": {},
   "source": [
    "# Carregar o DataFrame a partir do arquivo CSV\n",
    "df_xml = pd.read_csv(output_csv, header=None, encoding='utf-8')\n",
    "#print(df_xml.to_xml(index=False))  # Exibe o DataFrame formatado como uma tabela XML\n",
    "# Exibir o DataFrame como uma tabela Markdown\n",
    "print(\"DataFrame como tabela Markdown:\")\n",
    "print(df.to_markdown(index=False))  # Exibe o DataFrame formatado como uma tabela Markdown\n",
    "display(df_xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17d9572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iniciar a leitura de cada linha do CSV e processar os dados\n",
    "# encontrar a primeira linha que contém a palavra correspondente as 3 primeiras letras do dia da semana em ingles no inicio da linha\n",
    "\n",
    "path = filedialog.askopenfilename(title=\"Selecione o arquivo CSV\", filetypes=[(\"CSV files\", \"*.csv\")])\n",
    "\n",
    "print(f\"Arquivo selecionado: {path}\")\n",
    "\n",
    "# Verificar se o caminho do arquivo foi selecionado\n",
    "if not path:\n",
    "    print(\"Nenhum arquivo selecionado.\")\n",
    "    exit()\n",
    "\n",
    "df_escala_inicial = pd.read_csv(path, header=None)\n",
    "print(\"DataFrame carregado com sucesso.\")\n",
    "#print(f\"DataFrame inicial: {df_escala_inicial.head(10)}\")  # Exibe as primeiras 10 linhas do DataFrame\n",
    "\n",
    "# nome do arquivo CSV\n",
    "var_nome_arquivo = linha = df_escala_inicial.iloc[0, 0]  # Extrai o nome do arquivo do caminho completo\n",
    "print(f\"Nome do arquivo: {var_nome_arquivo}\")\n",
    "\n",
    "# Loop para ler o arquivo CSV até encontrar uma linha que comece com um dia da semana\n",
    "linha = df_escala_inicial.iloc[2, 0]  # Acessa a primeira linha do DataFrame\n",
    "n = 2\n",
    "\n",
    "while True:\n",
    "    # verificar se chegou ao final do DataFrame\n",
    "    if n >= len(df_escala_inicial):\n",
    "        print(\"Chegou ao final do DataFrame, encerrando o loop.\")\n",
    "        break\n",
    "\n",
    "    linha = df_escala_inicial.iloc[n, 0]\n",
    "    \n",
    "    if linha.startswith('Mon') or linha.startswith('Tue') or linha.startswith('Wed') or linha.startswith('Thu') or linha.startswith('Fri') or linha.startswith('Sat') or linha.startswith('Sun'):\n",
    "        print(f\"Linha encontrada: {linha}\")\n",
    "        # variavel que contem a data\n",
    "        var_data = linha.split()[1] + \"/\" + linha.split()[2] + \"/\" + linha.split()[3] # Pega a data e hora da linha  \n",
    "        print(f\"Data encontrada HOJE: {var_data}\")\n",
    "        # avançar para a próxima linha do CSV\n",
    "        n += 1\n",
    "        linha = df_escala_inicial.iloc[n, 0]\n",
    "        print(f\"Próxima linha HOJE: {linha}\")    \n",
    "        \n",
    "        # se a linha iniciar com a palavra 'Apresentação', continuar o loop\n",
    "        if linha.startswith('Apresentação'):\n",
    "            print(\"Linha iniciada com 'Apresentação', continuando o loop...\")\n",
    "            n += 1\n",
    "            continue\n",
    "\n",
    "        # se a linha iniciar com a palavra 'Off', parar o loop\n",
    "        if linha.startswith('Off'):\n",
    "            print(\"Linha iniciada com 'Off'\")\n",
    "            \n",
    "            # variavel que contem a atividade sem os parênteses\n",
    "            var_activity = linha.split()[1]\n",
    "            # retirar os parênteses da atividade\n",
    "            var_activity = var_activity.replace('(', '').replace(')', '')\n",
    "            print(f\"Atividade encontrada: {var_activity}\")\n",
    "            \n",
    "            var_hora_checkin = linha.split()[2]  # Pega o horário de checkin da linha\n",
    "            print(f\"Horário de checkin encontrado: {var_hora_checkin}\")\n",
    "            \n",
    "            var_hora_start = var_hora_checkin  # Pega o horário de início da linha\n",
    "            print(f\"Horário de início encontrado: {var_hora_start}\")\n",
    "            \n",
    "            var_hora_end = linha.split()[2]  # Pega o horário de fim da linha\n",
    "            print(f\"Horário de fim encontrado: {var_hora_end}\")\n",
    "            \n",
    "            var_hora_checkout = linha.split()[2]  # Pega o horário de checkout da linha\n",
    "            print(f\"Horário de checkout encontrado: {var_hora_end}\")                  \n",
    "        \n",
    "            # montar as variaveis de data e hora\n",
    "            var_data_hora_checkin = f\"{var_data} {var_hora_checkin}\"\n",
    "            var_data_hora_start = f\"{var_data} {var_hora_start}\"\n",
    "            # as variaveis de data e hora de fim e checkout deverão ser no dia seguinte\n",
    "            var_data_hora_end = (datetime.strptime(var_data, \"%d/%B/%Y\") + timedelta(days=1)).strftime(\"%d/%B/%Y\") + f\" {var_hora_end}\" \n",
    "            var_data_hora_checkout = (datetime.strptime(var_data, \"%d/%B/%Y\") + timedelta(days=1)).strftime(\"%d/%B/%Y\") + f\" {var_hora_checkout}\"\n",
    "            \n",
    "            print(f\"Data e hora de checkin: {var_data_hora_checkin}\")\n",
    "            print(f\"Data e hora de início: {var_data_hora_start}\")\n",
    "            print(f\"Data e hora de fim: {var_data_hora_end}\")\n",
    "            print(f\"Data e hora de checkout: {var_data_hora_checkout}\")\n",
    "            \n",
    "            # variaveis para Dep e Arr\n",
    "            var_dep = linha.split()[6] #if len(linha.split()) > 3 else None\n",
    "            var_arr = linha.split()[6] #if len(linha.split()) > 4 else None  \n",
    "            print(f\"Dep: {var_dep}\")\n",
    "            print(f\"Arr: {var_arr}\")    \n",
    "            \n",
    "            # imprimir 80 caracteres '-'\n",
    "            print('-' * 80)\n",
    "            \n",
    "            # mostrar todas as variaveis numa mesma string\n",
    "            print(f\"Ativity: {var_activity}, Checkin: {var_data_hora_checkin}, Start: {var_data_hora_start}, Dep: {var_dep}, Arr: {var_arr}, End: {var_data_hora_end}, Checkout: {var_data_hora_checkout}\")\n",
    "\n",
    "        # abrir um arquivo CSV para salvar os dados\n",
    "        # nome do arquivo CSV\n",
    "        if not var_nome_arquivo.lower().endswith('.csv'):\n",
    "            var_nome_arquivo = var_nome_arquivo + '.csv'\n",
    "        with open(var_nome_arquivo, 'a', newline='', encoding='utf-8') as csvfile:\n",
    "            csv_writer = csv.writer(csvfile)\n",
    "            # escrever o cabeçalho se o arquivo estiver vazio\n",
    "            if csvfile.tell() == 0:\n",
    "                csv_writer.writerow(['Activity', 'Checkin', 'Start', 'Dep', 'Arr', 'End', 'Checkout'])\n",
    "            # escrever os dados no arquivo CSV\n",
    "            csv_writer.writerow([var_activity, var_data_hora_checkin, var_data_hora_start, var_dep, var_arr, var_data_hora_end, var_data_hora_checkout])\n",
    "\n",
    "            n = n + 1\n",
    "            # atualizar a linha para a próxima iteração\n",
    "            # imprimir 80 caracteres '-'\n",
    "            print('-' * 80)\n",
    "    else:\n",
    "        print(f\"Linha não iniciada com um dia da semana: {linha}\")\n",
    "        n += 1\n",
    "        \n",
    "        var_activity = linha.split()[0]\n",
    "        print(f\"Atividade encontrada: {var_activity}\")\n",
    "        # verificar se a atividade é 'Apresentação' ou 'Release'\n",
    "        \n",
    "        \n",
    "        \n",
    "        #if var_activity.startswith('Apresentação') or var_activity.startswith('Release'):\n",
    "        #    print(f\"Atividade iniciada com 'Apresentação' ou 'Release', continuando o loop...\")\n",
    "        #    n += 1\n",
    "        #    continue\n",
    "        \n",
    "        \n",
    "        # se var_activity for 'Apresentação', 'Release' continuar o loop\n",
    "        \n",
    "        # verificar se a atividade inicia com \"AD\"\n",
    "        #if var_activity.startswith('AD'):\n",
    "            # pegar o horario de apresentação da linha anterior\n",
    "            #n -= 1\n",
    "            #linha_anterior = df_escala_inicial.iloc[n, 0]\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        var_hora_checkin = linha.split()[4]\n",
    "        var_hora_start = linha.split()[4]\n",
    "        var_hora_end = linha.split()[4]\n",
    "        var_hora_checkout = linha.split()[4]\n",
    "        print(f\"Horário de checkin encontrado: {var_checkin}\")\n",
    "        \n",
    "        var_start = linha.split()[2]\n",
    "        print(f\"Horário de início encontrado: {var_start}\")\n",
    "        \n",
    "        var_end = linha.split()[4]\n",
    "        print(f\"Horário de fim encontrado: {var_end}\")\n",
    "        \n",
    "        var_checkout = linha.split()[4]\n",
    "        print(f\"Horário de checkout encontrado: {var_checkout}\")\n",
    "        \n",
    "        # montar as variaveis de data e hora\n",
    "        # se var_activity iniciar com 'AD'\n",
    "        #if var_activity.startswith('AD'):\n",
    "            # Apenas concatena a data e hora como string\n",
    "        #    var_data_hora_end = f\"{var_data} {var_end}\"\n",
    "        #    var_data_hora_checkout = f\"{var_data} {var_checkout}\"\n",
    "        #else: \n",
    "        var_data_hora_checkin = f\"{var_data} {var_checkin}\"\n",
    "        var_data_hora_start = f\"{var_data} {var_start}\"\n",
    "        var_data_hora_end = f\"{var_data} {var_end}\"\n",
    "        var_data_hora_checkout = f\"{var_data} {var_checkout}\"\n",
    "        \n",
    "        print(f\"Data e hora de checkin: {var_data_hora_checkin}\")\n",
    "        print(f\"Data e hora de início: {var_data_hora_start}\")\n",
    "        print(f\"Data e hora de fim: {var_data_hora_end}\")\n",
    "        print(f\"Data e hora de checkout: {var_data_hora_checkout}\")\n",
    "        \n",
    "        # variaveis para Dep e Arr\n",
    "        #if var_activity.startswith('AD'):\n",
    "        #    var_dep = linha.split()[5] if len(linha.split()) > 5 else None\n",
    "        #    var_arr = linha.split()[7] if len(linha.split()) > 6 else None\n",
    "        #else:\n",
    "        var_dep = linha.split()[2] #if len(linha.split()) > 5 else None\n",
    "        var_arr = linha.split()[4] #if len(linha.split()) > 6 else None\n",
    "        \n",
    "        print(f\"Dep: {var_dep}\")\n",
    "        print(f\"Arr: {var_arr}\")\n",
    "        \n",
    "        # imprimir 80 caracteres '-'\n",
    "        print('-' * 80)\n",
    "        \n",
    "        # mostrar todas as variaveis numa mesma string\n",
    "        print(f\"Ativity: {var_activity}, Checkin: {var_data_hora_checkin}, Start: {var_data_hora_start}, Dep: {var_dep}, Arr: {var_arr}, End: {var_data_hora_end}, Checkout: {var_data_hora_checkout}\")\n",
    "          \n",
    "        # abrir um arquivo CSV para salvar os dados\n",
    "        # nome do arquivo CSV\n",
    "        if not var_nome_arquivo.lower().endswith('.csv'):\n",
    "            var_nome_arquivo = var_nome_arquivo + '.csv'\n",
    "        with open(var_nome_arquivo, 'a', newline='', encoding='utf-8') as csvfile:\n",
    "            csv_writer = csv.writer(csvfile)\n",
    "            # escrever o cabeçalho se o arquivo estiver vazio\n",
    "            if csvfile.tell() == 0:\n",
    "                csv_writer.writerow(['Activity', 'Checkin', 'Start', 'Dep', 'Arr', 'End', 'Checkout'])\n",
    "            # escrever os dados no arquivo CSV\n",
    "            csv_writer.writerow([var_activity, var_data_hora_checkin, var_data_hora_start, var_dep, var_arr, var_data_hora_end, var_data_hora_checkout])\n",
    "        print(f\"Dados salvos no arquivo: {var_nome_arquivo}\")\n",
    "\n",
    "\n",
    "     \n",
    "        \n",
    "        # Exibir mensagem de conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1011249",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
