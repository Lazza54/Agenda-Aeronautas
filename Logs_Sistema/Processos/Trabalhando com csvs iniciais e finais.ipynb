{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fad1b12",
   "metadata": {},
   "source": [
    "IMPORTAR OS ARQUIVOS CSV COM DADOS COMPLETAMENTE CALCULADOS E O COM DADOS INICIAIS PARA COMPARA√á√ÉO E VERIFICA√á√ÉO DOS C√ÅLCULOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f7812d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar bibliotecas para realizar as fun√ß√µes\n",
    "from datetime import datetime, time\n",
    "import pandas as pandas\n",
    "import numpy as nu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6913821d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèóÔ∏è CRIANDO ESTRUTURA DE PASTAS...\n",
      "‚úÖ Criada: g:\\PROJETOS PYTHON\\aeronautas_azul\\CODIGOS GERADOS\n",
      "‚úÖ Criada: g:\\PROJETOS PYTHON\\aeronautas_azul\\CODIGOS GERADOS\\analises\n",
      "‚úÖ Criada: g:\\PROJETOS PYTHON\\aeronautas_azul\\CODIGOS GERADOS\\utilities\n",
      "‚úÖ Criada: g:\\PROJETOS PYTHON\\aeronautas_azul\\CODIGOS GERADOS\\reports\n",
      "‚úÖ Criada: g:\\PROJETOS PYTHON\\aeronautas_azul\\RESULTADOS\n",
      "‚úÖ Criada: g:\\PROJETOS PYTHON\\aeronautas_azul\\RESULTADOS\\logs\n",
      "‚úÖ Criada: g:\\PROJETOS PYTHON\\aeronautas_azul\\RESULTADOS\\relatorios\n",
      "‚úÖ Criada: g:\\PROJETOS PYTHON\\aeronautas_azul\\RESULTADOS\\arquivos_padronizados\n",
      "\n",
      "üìÇ Estrutura criada em: g:\\PROJETOS PYTHON\\aeronautas_azul\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def criar_estrutura_pastas():\n",
    "    \"\"\"Cria a estrutura de pastas para organizar c√≥digos gerados\"\"\"\n",
    "    \n",
    "    # Diret√≥rio base (ajustar conforme necess√°rio)\n",
    "    base_dir = Path(\"g:/PROJETOS PYTHON/aeronautas_azul\")\n",
    "    \n",
    "    # Estrutura de pastas\n",
    "    pastas = [\n",
    "        \"CODIGOS GERADOS\",\n",
    "        \"CODIGOS GERADOS/analises\",\n",
    "        \"CODIGOS GERADOS/utilities\", \n",
    "        \"CODIGOS GERADOS/reports\",\n",
    "        \"RESULTADOS\",\n",
    "        \"RESULTADOS/logs\",\n",
    "        \"RESULTADOS/relatorios\",\n",
    "        \"RESULTADOS/arquivos_padronizados\"\n",
    "    ]\n",
    "    \n",
    "    print(\"üèóÔ∏è CRIANDO ESTRUTURA DE PASTAS...\")\n",
    "    \n",
    "    for pasta in pastas:\n",
    "        caminho_pasta = base_dir / pasta\n",
    "        try:\n",
    "            caminho_pasta.mkdir(parents=True, exist_ok=True)\n",
    "            print(f\"‚úÖ Criada: {caminho_pasta}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erro ao criar {pasta}: {e}\")\n",
    "    \n",
    "    print(f\"\\nüìÇ Estrutura criada em: {base_dir}\")\n",
    "    return base_dir\n",
    "\n",
    "# Executar cria√ß√£o da estrutura\n",
    "base_directory = criar_estrutura_pastas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eb917312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar uma fun√ß√£o para escolher os diretorios via dialogo\n",
    "def escolher_diretorio():\n",
    "    from tkinter import Tk\n",
    "    from tkinter.filedialog import askdirectory\n",
    "\n",
    "    # criar uma janela oculta\n",
    "    Tk().withdraw()\n",
    "    # abrir o dialogo para escolher o diretorio\n",
    "    diretorio = askdirectory(title=\"Escolha o diret√≥rio\")\n",
    "    return diretorio\n",
    "\n",
    "# criar uma fun√ß√£o para escolher os arquivos csv\n",
    "def escolher_arquivos():\n",
    "    from tkinter import Tk\n",
    "    from tkinter.filedialog import askopenfilenames\n",
    "\n",
    "    # criar uma janela oculta\n",
    "    Tk().withdraw()\n",
    "    # abrir o dialogo para escolher os arquivos\n",
    "    arquivos = askopenfilenames(title=\"Escolha os arquivos CSV\", filetypes=[(\"CSV files\", \"*.csv\")])\n",
    "    return arquivos if arquivos else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "87045161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Diret√≥rio selecionado: G:/PROJETOS PYTHON/aeronautas_azul/AERONAUTAS/ARQUIVOS TRABALHADOS/RICARDO LAZZARINI\n",
      "‚úÖ Exatos 2 arquivos selecionados!\n",
      "1. G:/PROJETOS PYTHON/aeronautas_azul/AERONAUTAS/ARQUIVOS TRABALHADOS/RICARDO LAZZARINI/escala_e_ricardo_lazzarini_vcp_3394_112017_022023_COM_SUFIXO.csv\n",
      "2. G:/PROJETOS PYTHON/aeronautas_azul/AERONAUTAS/ARQUIVOS TRABALHADOS/RICARDO LAZZARINI/escala_e_ricardo_lazzarini_vcp_3394_112017_022023_COM_SUFIXO.csv) - CALCULOS_EM_TIMEDELTA.csv\n",
      "\n",
      "üìÇ Carregando os arquivos...\n",
      "‚úÖ Arquivo 1 carregado: G:/PROJETOS PYTHON/aeronautas_azul/AERONAUTAS/ARQUIVOS TRABALHADOS/RICARDO LAZZARINI/escala_e_ricardo_lazzarini_vcp_3394_112017_022023_COM_SUFIXO.csv - Shape: (2541, 12)\n",
      "‚úÖ Arquivo 2 carregado: G:/PROJETOS PYTHON/aeronautas_azul/AERONAUTAS/ARQUIVOS TRABALHADOS/RICARDO LAZZARINI/escala_e_ricardo_lazzarini_vcp_3394_112017_022023_COM_SUFIXO.csv) - CALCULOS_EM_TIMEDELTA.csv - Shape: (2541, 25)\n",
      "\n",
      "==================================================\n",
      "üìä DISPLAY DO PRIMEIRO ARQUIVO: G:/PROJETOS PYTHON/aeronautas_azul/AERONAUTAS/ARQUIVOS TRABALHADOS/RICARDO LAZZARINI/escala_e_ricardo_lazzarini_vcp_3394_112017_022023_COM_SUFIXO.csv\n",
      "==================================================\n",
      "üîπ Colunas: ['Activity', 'Id_Leg', 'Checkin', 'Start', 'Dep', 'Arr', 'End', 'Checkout', 'AcVer', 'DD', 'CAT', 'Crew']\n",
      "üîπ Primeiras 5 linhas:\n",
      "  Activity Id_Leg              Checkin                Start  Dep  Arr  \\\n",
      "0   AD5046     -I  2017-11-01 18:55:00  2017-11-01 19:48:00  VCP  POA   \n",
      "1   AD2852     -M  2017-11-01 18:55:00  2017-11-01 22:23:00  POA  CWB   \n",
      "2   AD2852     -M  2017-11-01 18:55:00  2017-11-02 00:02:00  CWB  CGR   \n",
      "3   AD2852     -F  2017-11-01 18:55:00  2017-11-02 02:13:00  CGR  CGB   \n",
      "4   AD2898    -IF  2017-11-03 00:20:00  2017-11-03 00:55:00  CGB  SMT   \n",
      "\n",
      "                   End             Checkout AcVer DD CAT  \\\n",
      "0  2017-11-01 21:37:00  2017-11-02 04:01:00   E95  -  CA   \n",
      "1  2017-11-01 23:31:00  2017-11-02 04:01:00   E95  -  CA   \n",
      "2  2017-11-02 01:43:00  2017-11-02 04:01:00   E95  -  CA   \n",
      "3  2017-11-02 03:31:00  2017-11-02 04:01:00   E95  -  CA   \n",
      "4  2017-11-03 01:51:00  2017-11-03 02:21:00   E95  -  CA   \n",
      "\n",
      "                                                Crew  \n",
      "0  ALESSANDRO DIAS DA SILVA - FO HALAN FRANCISCO ...  \n",
      "1  ALESSANDRO DIAS DA SILVA - FO HALAN FRANCISCO ...  \n",
      "2  ALESSANDRO DIAS DA SILVA - FO HALAN FRANCISCO ...  \n",
      "3  ALESSANDRO DIAS DA SILVA - FO HALAN FRANCISCO ...  \n",
      "4  ALESSANDRO DIAS DA SILVA - FO HALAN FRANCISCO ...  \n",
      "\n",
      "==================================================\n",
      "üìä DISPLAY DO SEGUNDO ARQUIVO: G:/PROJETOS PYTHON/aeronautas_azul/AERONAUTAS/ARQUIVOS TRABALHADOS/RICARDO LAZZARINI/escala_e_ricardo_lazzarini_vcp_3394_112017_022023_COM_SUFIXO.csv) - CALCULOS_EM_TIMEDELTA.csv\n",
      "==================================================\n",
      "üîπ Colunas: ['Activity', 'Id_Leg', 'Checkin', 'Start', 'Dep', 'Arr', 'End', 'Checkout', 'AcVer', 'DD', 'CAT', 'Crew', 'Tempo Apresentacao', 'Operacao', 'Tempo Solo', 'Jornada', 'Repouso', 'Repouso Extra', 'Diurno', 'Noturno', 'Especial', 'Especial Noturno', 'Start_date', 'End_date', 'Internacional']\n",
      "üîπ Primeiras 5 linhas:\n",
      "  Activity Id_Leg              Checkin                Start  Dep  Arr  \\\n",
      "0   AD5046     -I  2017-11-01 18:55:00  2017-11-01 19:48:00  VCP  POA   \n",
      "1   AD2852     -M  2017-11-01 18:55:00  2017-11-01 22:23:00  POA  CWB   \n",
      "2   AD2852     -M  2017-11-01 18:55:00  2017-11-02 00:02:00  CWB  CGR   \n",
      "3   AD2852     -F  2017-11-01 18:55:00  2017-11-02 02:13:00  CGR  CGB   \n",
      "4   AD2898    -IF  2017-11-03 00:20:00  2017-11-03 00:55:00  CGB  SMT   \n",
      "\n",
      "                   End             Checkout AcVer DD  ...          Jornada  \\\n",
      "0  2017-11-01 21:37:00  2017-11-02 04:01:00   E95  -  ...  0 days 00:00:00   \n",
      "1  2017-11-01 23:31:00  2017-11-02 04:01:00   E95  -  ...  0 days 00:00:00   \n",
      "2  2017-11-02 01:43:00  2017-11-02 04:01:00   E95  -  ...  0 days 00:00:00   \n",
      "3  2017-11-02 03:31:00  2017-11-02 04:01:00   E95  -  ...  0 days 09:36:00   \n",
      "4  2017-11-03 01:51:00  2017-11-03 02:21:00   E95  -  ...  0 days 02:31:00   \n",
      "\n",
      "           Repouso    Repouso Extra           Diurno          Noturno  \\\n",
      "0  0 days 00:00:00  0 days 00:00:00  0 days 00:00:00  0 days 01:49:00   \n",
      "1  0 days 00:00:00  0 days 00:00:00  0 days 00:00:00  0 days 01:08:00   \n",
      "2  0 days 00:00:00  0 days 00:00:00  0 days 00:00:00  0 days 01:41:00   \n",
      "3  0 days 20:19:00  0 days 08:19:00  0 days 00:00:00  0 days 01:18:00   \n",
      "4  1 days 07:49:00  0 days 19:49:00  0 days 00:00:00  0 days 00:56:00   \n",
      "\n",
      "          Especial Especial Noturno  Start_date    End_date Internacional  \n",
      "0  0 days 00:00:00  0 days 00:00:00  2017-11-01  2017-11-01             N  \n",
      "1  0 days 00:00:00  0 days 00:00:00  2017-11-01  2017-11-01             N  \n",
      "2  0 days 00:00:00  0 days 01:41:00  2017-11-02  2017-11-02             N  \n",
      "3  0 days 00:00:00  0 days 01:18:00  2017-11-02  2017-11-02             N  \n",
      "4  0 days 00:00:00  0 days 00:00:00  2017-11-03  2017-11-03             N  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "üìä INFORMA√á√ïES DETALHADAS DO ARQUIVO 1:\n",
      "üîπ G:/PROJETOS PYTHON/aeronautas_azul/AERONAUTAS/ARQUIVOS TRABALHADOS/RICARDO LAZZARINI/escala_e_ricardo_lazzarini_vcp_3394_112017_022023_COM_SUFIXO.csv\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2541 entries, 0 to 2540\n",
      "Data columns (total 12 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Activity  2541 non-null   object\n",
      " 1   Id_Leg    2541 non-null   object\n",
      " 2   Checkin   2541 non-null   object\n",
      " 3   Start     2541 non-null   object\n",
      " 4   Dep       2541 non-null   object\n",
      " 5   Arr       2541 non-null   object\n",
      " 6   End       2541 non-null   object\n",
      " 7   Checkout  2541 non-null   object\n",
      " 8   AcVer     2541 non-null   object\n",
      " 9   DD        2541 non-null   object\n",
      " 10  CAT       2541 non-null   object\n",
      " 11  Crew      2541 non-null   object\n",
      "dtypes: object(12)\n",
      "memory usage: 238.3+ KB\n",
      "\n",
      "üìä INFORMA√á√ïES DETALHADAS DO ARQUIVO 2:\n",
      "üîπ G:/PROJETOS PYTHON/aeronautas_azul/AERONAUTAS/ARQUIVOS TRABALHADOS/RICARDO LAZZARINI/escala_e_ricardo_lazzarini_vcp_3394_112017_022023_COM_SUFIXO.csv) - CALCULOS_EM_TIMEDELTA.csv\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2541 entries, 0 to 2540\n",
      "Data columns (total 25 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Activity            2541 non-null   object\n",
      " 1   Id_Leg              2541 non-null   object\n",
      " 2   Checkin             2541 non-null   object\n",
      " 3   Start               2541 non-null   object\n",
      " 4   Dep                 2541 non-null   object\n",
      " 5   Arr                 2541 non-null   object\n",
      " 6   End                 2541 non-null   object\n",
      " 7   Checkout            2541 non-null   object\n",
      " 8   AcVer               2541 non-null   object\n",
      " 9   DD                  2541 non-null   object\n",
      " 10  CAT                 2541 non-null   object\n",
      " 11  Crew                2541 non-null   object\n",
      " 12  Tempo Apresentacao  2541 non-null   object\n",
      " 13  Operacao            2541 non-null   object\n",
      " 14  Tempo Solo          2541 non-null   object\n",
      " 15  Jornada             2541 non-null   object\n",
      " 16  Repouso             2540 non-null   object\n",
      " 17  Repouso Extra       2541 non-null   object\n",
      " 18  Diurno              2541 non-null   object\n",
      " 19  Noturno             2541 non-null   object\n",
      " 20  Especial            2541 non-null   object\n",
      " 21  Especial Noturno    2541 non-null   object\n",
      " 22  Start_date          2541 non-null   object\n",
      " 23  End_date            2541 non-null   object\n",
      " 24  Internacional       2541 non-null   object\n",
      "dtypes: object(25)\n",
      "memory usage: 496.4+ KB\n",
      "\n",
      "üîÑ RESUMO COMPARATIVO:\n",
      "üìã Arquivo 1: 2,541 linhas x 12 colunas\n",
      "üìã Arquivo 2: 2,541 linhas x 25 colunas\n",
      "üìä Diferen√ßa: 0 linhas, 13 colunas\n",
      "\n",
      "‚úÖ PROCESSAMENTO CONCLU√çDO!\n"
     ]
    }
   ],
   "source": [
    "# chamar a fun√ß√£o para escolher o diretorio\n",
    "diretorio = escolher_diretorio()\n",
    "if diretorio:\n",
    "    print(f\"‚úÖ Diret√≥rio selecionado: {diretorio}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Nenhum diret√≥rio foi selecionado\")\n",
    "\n",
    "# chamar a fun√ß√£o para escolher os arquivos csv\n",
    "arquivos = escolher_arquivos()\n",
    "\n",
    "# verificar se os arquivos foram escolhidos\n",
    "if arquivos is None or len(arquivos) == 0:\n",
    "    print(\"‚ùå Nenhum arquivo foi selecionado.\")\n",
    "    print(\"üí° Dica: Execute a c√©lula novamente e selecione exatamente 2 arquivos CSV\")\n",
    "elif len(arquivos) != 2:\n",
    "    print(f\"‚ö†Ô∏è Foram selecionados {len(arquivos)} arquivos. Por favor, selecione exatamente 2 arquivos CSV.\")\n",
    "    print(\"üí° Execute a c√©lula novamente e selecione apenas 2 arquivos\")\n",
    "else:\n",
    "    print(f\"‚úÖ Exatos 2 arquivos selecionados!\")\n",
    "    \n",
    "    # mostrar os arquivos selecionados\n",
    "    arquivo1 = arquivos[0]\n",
    "    arquivo2 = arquivos[1]\n",
    "    print(f\"1. {arquivo1.split('\\\\')[-1]}\")\n",
    "    print(f\"2. {arquivo2.split('\\\\')[-1]}\")\n",
    "    \n",
    "    print(\"\\nüìÇ Carregando os arquivos...\")\n",
    "    \n",
    "    try:\n",
    "        # carregar o primeiro arquivo\n",
    "        df1 = pandas.read_csv(arquivo1, sep=',', encoding='utf-8')\n",
    "        nome_arquivo1 = arquivo1.split('\\\\')[-1]\n",
    "        print(f\"‚úÖ Arquivo 1 carregado: {nome_arquivo1} - Shape: {df1.shape}\")\n",
    "        \n",
    "        # carregar o segundo arquivo\n",
    "        df2 = pandas.read_csv(arquivo2, sep=',', encoding='utf-8')\n",
    "        nome_arquivo2 = arquivo2.split('\\\\')[-1]\n",
    "        print(f\"‚úÖ Arquivo 2 carregado: {nome_arquivo2} - Shape: {df2.shape}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"üìä DISPLAY DO PRIMEIRO ARQUIVO: {nome_arquivo1}\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"üîπ Colunas: {list(df1.columns)}\")\n",
    "        print(f\"üîπ Primeiras 5 linhas:\")\n",
    "        print(df1.head())\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"üìä DISPLAY DO SEGUNDO ARQUIVO: {nome_arquivo2}\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"üîπ Colunas: {list(df2.columns)}\")\n",
    "        print(f\"üîπ Primeiras 5 linhas:\")\n",
    "        print(df2.head())\n",
    "        \n",
    "        # informa√ß√µes detalhadas usando info()\n",
    "        print(\"\\nüìä INFORMA√á√ïES DETALHADAS DO ARQUIVO 1:\")\n",
    "        print(f\"üîπ {nome_arquivo1}\")\n",
    "        df1.info()\n",
    "        \n",
    "        print(\"\\nüìä INFORMA√á√ïES DETALHADAS DO ARQUIVO 2:\")\n",
    "        print(f\"üîπ {nome_arquivo2}\")\n",
    "        df2.info()\n",
    "        \n",
    "        # resumo r√°pido da compara√ß√£o\n",
    "        print(f\"\\nüîÑ RESUMO COMPARATIVO:\")\n",
    "        print(f\"üìã Arquivo 1: {df1.shape[0]:,} linhas x {df1.shape[1]} colunas\")\n",
    "        print(f\"üìã Arquivo 2: {df2.shape[0]:,} linhas x {df2.shape[1]} colunas\")\n",
    "        print(f\"üìä Diferen√ßa: {abs(df1.shape[0] - df2.shape[0]):,} linhas, {abs(df1.shape[1] - df2.shape[1])} colunas\")\n",
    "        \n",
    "        print(\"\\n‚úÖ PROCESSAMENTO CONCLU√çDO!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao carregar os arquivos: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9ad74a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç COMPARA√á√ÉO DETALHADA DOS DATAFRAMES\n",
      "============================================================\n",
      "‚úÖ Dataframes encontrados. Iniciando compara√ß√£o...\n",
      "\n",
      "üîç DIAGN√ìSTICO DOS DATAFRAMES:\n",
      "   üìä DF1 shape: (2541, 12)\n",
      "   üìä DF2 shape: (2541, 25)\n",
      "üîç Procurando coluna 'Internacional'...\n",
      "   DF1 colunas: ['Activity', 'Id_Leg', 'Checkin', 'Start', 'Dep', 'Arr', 'End', 'Checkout', 'AcVer', 'DD', 'CAT', 'Crew']\n",
      "   DF2 colunas: ['Activity', 'Id_Leg', 'Checkin', 'Start', 'Dep', 'Arr', 'End', 'Checkout', 'AcVer', 'DD', 'CAT', 'Crew', 'Tempo Apresentacao', 'Operacao', 'Tempo Solo', 'Jornada', 'Repouso', 'Repouso Extra', 'Diurno', 'Noturno', 'Especial', 'Especial Noturno', 'Start_date', 'End_date', 'Internacional']\n",
      "‚ö†Ô∏è Coluna 'Internacional' n√£o encontrada em um ou ambos os dataframes\n",
      "üí° Usando todas as 12 colunas comuns dispon√≠veis\n",
      "‚úÖ Sele√ß√£o conclu√≠da:\n",
      "   üìã DF1_comparacao shape: (2541, 12)\n",
      "   üìã DF2_comparacao shape: (2541, 12)\n",
      "üîç Verificando compatibilidade das colunas:\n",
      "   üìã DF1 colunas: ['Activity', 'Id_Leg', 'Checkin', 'Start', 'Dep', 'Arr', 'End', 'Checkout', 'AcVer', 'DD', 'CAT', 'Crew']\n",
      "   üìã DF2 colunas: ['Activity', 'Id_Leg', 'Checkin', 'Start', 'Dep', 'Arr', 'End', 'Checkout', 'AcVer', 'DD', 'CAT', 'Crew']\n",
      "‚úÖ Colunas s√£o id√™nticas nos dois dataframes\n",
      "   üìã Colunas finais para compara√ß√£o: ['Activity', 'Id_Leg', 'Checkin', 'Start', 'Dep', 'Arr', 'End', 'Checkout', 'AcVer', 'DD', 'CAT', 'Crew']\n",
      "\n",
      "üìä ESCOPO DA COMPARA√á√ÉO:\n",
      "   üìã Colunas originais DF1: 12\n",
      "   üìã Colunas originais DF2: 25\n",
      "   üìã Colunas selecionadas para compara√ß√£o: 12\n",
      "   üìè Linhas DF1: 2,541\n",
      "   üìè Linhas DF2: 2,541\n",
      "   üìã Colunas: ['Activity', 'Id_Leg', 'Checkin', 'Start', 'Dep', 'Arr', 'End', 'Checkout', 'AcVer', 'DD', 'CAT', 'Crew']\n",
      "\n",
      "üîç INICIANDO COMPARA√á√ÉO DETALHADA...\n",
      "   üìä Comparando 2,541 linhas x 12 colunas\n",
      "   üîÑ Processando coluna 1/12: 'Activity'\n",
      "   üîÑ Processando coluna 2/12: 'Id_Leg'\n",
      "   üîÑ Processando coluna 3/12: 'Checkin'\n",
      "   üîÑ Processando coluna 4/12: 'Start'\n",
      "   üîÑ Processando coluna 5/12: 'Dep'\n",
      "   üîÑ Processando coluna 6/12: 'Arr'\n",
      "   üîÑ Processando coluna 7/12: 'End'\n",
      "   üîÑ Processando coluna 8/12: 'Checkout'\n",
      "   üîÑ Processando coluna 9/12: 'AcVer'\n",
      "   üîÑ Processando coluna 10/12: 'DD'\n",
      "   üîÑ Processando coluna 11/12: 'CAT'\n",
      "   üîÑ Processando coluna 12/12: 'Crew'\n",
      "\n",
      "üìà RESULTADOS DA COMPARA√á√ÉO:\n",
      "   üî¢ Total de compara√ß√µes realizadas: 30,492\n",
      "   ‚ùå Diferen√ßas encontradas: 4,879\n",
      "   ‚úÖ Valores iguais: 25,613\n",
      "   üìä Taxa de igualdade: 84.00%\n",
      "\n",
      "‚ö†Ô∏è DIFEREN√áAS ENCONTRADAS:\n",
      "Mostrando as primeiras 10 diferen√ßas:\n",
      "\n",
      "   1. Linha 40, Coluna 'Checkin':\n",
      "      DF1: 01DEZ17 02:00\n",
      "      DF2: 2017-12-01 02:00:00\n",
      "      Tipo: Valores diferentes\n",
      "\n",
      "   2. Linha 41, Coluna 'Checkin':\n",
      "      DF1: 02DEZ17 02:00\n",
      "      DF2: 2017-12-02 02:00:00\n",
      "      Tipo: Valores diferentes\n",
      "\n",
      "   3. Linha 42, Coluna 'Checkin':\n",
      "      DF1: 03DEZ17 02:00\n",
      "      DF2: 2017-12-03 02:00:00\n",
      "      Tipo: Valores diferentes\n",
      "\n",
      "   4. Linha 43, Coluna 'Checkin':\n",
      "      DF1: 04DEZ17 02:00\n",
      "      DF2: 2017-12-04 02:00:00\n",
      "      Tipo: Valores diferentes\n",
      "\n",
      "   5. Linha 44, Coluna 'Checkin':\n",
      "      DF1: 05DEZ17 02:00\n",
      "      DF2: 2017-12-05 02:00:00\n",
      "      Tipo: Valores diferentes\n",
      "\n",
      "   6. Linha 45, Coluna 'Checkin':\n",
      "      DF1: 06DEZ17 02:00\n",
      "      DF2: 2017-12-06 02:00:00\n",
      "      Tipo: Valores diferentes\n",
      "\n",
      "   7. Linha 46, Coluna 'Checkin':\n",
      "      DF1: 07DEZ17 02:00\n",
      "      DF2: 2017-12-07 02:00:00\n",
      "      Tipo: Valores diferentes\n",
      "\n",
      "   8. Linha 47, Coluna 'Checkin':\n",
      "      DF1: 08DEZ17 02:00\n",
      "      DF2: 2017-12-08 02:00:00\n",
      "      Tipo: Valores diferentes\n",
      "\n",
      "   9. Linha 48, Coluna 'Checkin':\n",
      "      DF1: 09DEZ17 02:00\n",
      "      DF2: 2017-12-09 02:00:00\n",
      "      Tipo: Valores diferentes\n",
      "\n",
      "   10. Linha 49, Coluna 'Checkin':\n",
      "      DF1: 10DEZ17 02:00\n",
      "      DF2: 2017-12-10 02:00:00\n",
      "      Tipo: Valores diferentes\n",
      "\n",
      "   ... e mais 4869 diferen√ßas\n",
      "\n",
      "üìä DIFEREN√áAS POR COLUNA:\n",
      "   Checkin: 1218 diferen√ßas\n",
      "   Checkout: 1218 diferen√ßas\n",
      "   Crew: 5 diferen√ßas\n",
      "   End: 1219 diferen√ßas\n",
      "   Start: 1219 diferen√ßas\n",
      "\n",
      "‚úÖ COMPARA√á√ÉO CONCLU√çDA!\n"
     ]
    }
   ],
   "source": [
    "# compara√ß√£o detalhada entre os dataframes at√© a coluna \"Internacional\"\n",
    "print(\"üîç COMPARA√á√ÉO DETALHADA DOS DATAFRAMES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# verificar se os dataframes existem\n",
    "try:\n",
    "    df1\n",
    "    df2\n",
    "    print(\"‚úÖ Dataframes encontrados. Iniciando compara√ß√£o...\")\n",
    "    \n",
    "    # diagn√≥stico de problemas de parsing\n",
    "    print(f\"\\nüîç DIAGN√ìSTICO DOS DATAFRAMES:\")\n",
    "    print(f\"   üìä DF1 shape: {df1.shape}\")\n",
    "    print(f\"   üìä DF2 shape: {df2.shape}\")\n",
    "    \n",
    "    # verificar se h√° colunas problem√°ticas (com v√≠rgulas)\n",
    "    problemas_df1 = [col for col in df1.columns if ',' in str(col)]\n",
    "    problemas_df2 = [col for col in df2.columns if ',' in str(col)]\n",
    "    \n",
    "    if problemas_df1:\n",
    "        print(f\"   ‚ö†Ô∏è PROBLEMAS DETECTADOS no DF1:\")\n",
    "        for col in problemas_df1:\n",
    "            print(f\"      - Coluna problem√°tica: '{col[:100]}...' (truncada)\")\n",
    "        print(f\"   üí° Isso indica que o CSV pode ter sido lido incorretamente\")\n",
    "        print(f\"   üí° Poss√≠vel solu√ß√£o: verificar o separador ou formato do arquivo\")\n",
    "        \n",
    "    if problemas_df2:\n",
    "        print(f\"   ‚ö†Ô∏è PROBLEMAS DETECTADOS no DF2:\")\n",
    "        for col in problemas_df2:\n",
    "            print(f\"      - Coluna problem√°tica: '{col[:100]}...' (truncada)\")\n",
    "        print(f\"   üí° Isso indica que o CSV pode ter sido lido incorretamente\")\n",
    "        \n",
    "except NameError:\n",
    "    print(\"‚ùå Dataframes n√£o encontrados. Execute primeiro a c√©lula de carregamento.\")\n",
    "    raise SystemExit(\"Dataframes n√£o encontrados\")\n",
    "\n",
    "# encontrar a posi√ß√£o da coluna \"Internacional\" em ambos os dataframes\n",
    "print(f\"üîç Procurando coluna 'Internacional'...\")\n",
    "print(f\"   DF1 colunas: {list(df1.columns)}\")\n",
    "print(f\"   DF2 colunas: {list(df2.columns)}\")\n",
    "\n",
    "try:\n",
    "    # verificar se a coluna existe em ambos os dataframes\n",
    "    if 'Internacional' in df1.columns and 'Internacional' in df2.columns:\n",
    "        pos_internacional_df1 = df1.columns.get_loc('Internacional')\n",
    "        pos_internacional_df2 = df2.columns.get_loc('Internacional')\n",
    "        print(f\"üìç Coluna 'Internacional' encontrada na posi√ß√£o {pos_internacional_df1} no DF1 e posi√ß√£o {pos_internacional_df2} no DF2\")\n",
    "        \n",
    "        # usar a menor posi√ß√£o para garantir que ambos tenham as colunas\n",
    "        pos_limite = min(pos_internacional_df1, pos_internacional_df2) + 1\n",
    "        print(f\"üéØ Limite definido: {pos_limite} colunas (at√© 'Internacional' inclusive)\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Coluna 'Internacional' n√£o encontrada em um ou ambos os dataframes\")\n",
    "        # usar todas as colunas dispon√≠veis\n",
    "        pos_limite = min(len(df1.columns), len(df2.columns))\n",
    "        print(f\"üí° Usando todas as {pos_limite} colunas comuns dispon√≠veis\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro ao localizar coluna 'Internacional': {e}\")\n",
    "    pos_limite = min(len(df1.columns), len(df2.columns))\n",
    "    print(f\"üí° Fallback: usando as primeiras {pos_limite} colunas\")\n",
    "\n",
    "# selecionar as colunas para compara√ß√£o - SEMPRE haver√° colunas se chegamos at√© aqui\n",
    "df1_comparacao = df1.iloc[:, :pos_limite]\n",
    "df2_comparacao = df2.iloc[:, :pos_limite]\n",
    "\n",
    "print(f\"‚úÖ Sele√ß√£o conclu√≠da:\")\n",
    "print(f\"   üìã DF1_comparacao shape: {df1_comparacao.shape}\")\n",
    "print(f\"   üìã DF2_comparacao shape: {df2_comparacao.shape}\")\n",
    "\n",
    "# verificar se as colunas s√£o realmente compat√≠veis\n",
    "colunas_df1 = list(df1_comparacao.columns)\n",
    "colunas_df2 = list(df2_comparacao.columns)\n",
    "\n",
    "print(f\"üîç Verificando compatibilidade das colunas:\")\n",
    "print(f\"   üìã DF1 colunas: {colunas_df1}\")\n",
    "print(f\"   üìã DF2 colunas: {colunas_df2}\")\n",
    "\n",
    "# verificar se alguma coluna cont√©m v√≠rgulas (indicando problema de parsing)\n",
    "for i, col in enumerate(colunas_df1):\n",
    "    if ',' in str(col):\n",
    "        print(f\"‚ö†Ô∏è PROBLEMA DETECTADO na coluna {i} do DF1: '{col}'\")\n",
    "        print(\"   üí° Esta coluna parece conter m√∫ltiplos nomes separados por v√≠rgula\")\n",
    "        print(\"   üí° Isso indica um problema na leitura do CSV\")\n",
    "\n",
    "for i, col in enumerate(colunas_df2):\n",
    "    if ',' in str(col):\n",
    "        print(f\"‚ö†Ô∏è PROBLEMA DETECTADO na coluna {i} do DF2: '{col}'\")\n",
    "        print(\"   üí° Esta coluna parece conter m√∫ltiplos nomes separados por v√≠rgula\")\n",
    "        print(\"   üí° Isso indica um problema na leitura do CSV\")\n",
    "\n",
    "# garantir que as colunas sejam exatamente as mesmas\n",
    "if colunas_df1 == colunas_df2:\n",
    "    print(f\"‚úÖ Colunas s√£o id√™nticas nos dois dataframes\")\n",
    "    colunas_finais = colunas_df1\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Colunas diferentes detectadas!\")\n",
    "    # usar apenas as colunas que existem em ambos\n",
    "    colunas_finais = []\n",
    "    for i in range(min(len(colunas_df1), len(colunas_df2))):\n",
    "        if i < len(colunas_df1) and i < len(colunas_df2):\n",
    "            col1 = colunas_df1[i]\n",
    "            col2 = colunas_df2[i]\n",
    "            if col1 == col2:\n",
    "                colunas_finais.append(col1)\n",
    "            else:\n",
    "                print(f\"   Diverg√™ncia na posi√ß√£o {i}: '{col1}' vs '{col2}'\")\n",
    "                break\n",
    "    \n",
    "    if len(colunas_finais) > 0:\n",
    "        # reselecionar apenas as colunas comuns\n",
    "        df1_comparacao = df1_comparacao.iloc[:, :len(colunas_finais)]\n",
    "        df2_comparacao = df2_comparacao.iloc[:, :len(colunas_finais)]\n",
    "        print(f\"üîß Usando apenas {len(colunas_finais)} colunas comuns\")\n",
    "    else:\n",
    "        print(\"‚ùå Nenhuma coluna comum encontrada!\")\n",
    "\n",
    "print(f\"   üìã Colunas finais para compara√ß√£o: {list(df1_comparacao.columns)}\")\n",
    "\n",
    "print(f\"\\nüìä ESCOPO DA COMPARA√á√ÉO:\")\n",
    "print(f\"   üìã Colunas originais DF1: {len(df1.columns)}\")\n",
    "print(f\"   üìã Colunas originais DF2: {len(df2.columns)}\")\n",
    "print(f\"   üìã Colunas selecionadas para compara√ß√£o: {len(df1_comparacao.columns)}\")\n",
    "print(f\"   üìè Linhas DF1: {len(df1_comparacao):,}\")\n",
    "print(f\"   üìè Linhas DF2: {len(df2_comparacao):,}\")\n",
    "print(f\"   üìã Colunas: {list(df1_comparacao.columns)}\")\n",
    "\n",
    "# verificar se os dataframes t√™m o mesmo n√∫mero de linhas\n",
    "if len(df1_comparacao) != len(df2_comparacao):\n",
    "    print(f\"\\n‚ö†Ô∏è ATEN√á√ÉO: Dataframes t√™m tamanhos diferentes!\")\n",
    "    print(f\"   DF1: {len(df1_comparacao):,} linhas\")\n",
    "    print(f\"   DF2: {len(df2_comparacao):,} linhas\")\n",
    "    # usar o menor tamanho para compara√ß√£o\n",
    "    min_linhas = min(len(df1_comparacao), len(df2_comparacao))\n",
    "    df1_comparacao = df1_comparacao.iloc[:min_linhas]\n",
    "    df2_comparacao = df2_comparacao.iloc[:min_linhas]\n",
    "    print(f\"   üîß Comparando apenas as primeiras {min_linhas:,} linhas\")\n",
    "\n",
    "# fazer a compara√ß√£o elemento por elemento\n",
    "if len(df1_comparacao.columns) > 0 and len(df2_comparacao.columns) > 0:\n",
    "    print(f\"\\nüîç INICIANDO COMPARA√á√ÉO DETALHADA...\")\n",
    "    print(f\"   üìä Comparando {len(df1_comparacao):,} linhas x {len(df1_comparacao.columns)} colunas\")\n",
    "\n",
    "    # comparar valores elemento por elemento\n",
    "    diferencas_encontradas = []\n",
    "    total_comparacoes = 0\n",
    "\n",
    "    try:\n",
    "        for col_idx, col in enumerate(df1_comparacao.columns):\n",
    "            print(f\"   üîÑ Processando coluna {col_idx + 1}/{len(df1_comparacao.columns)}: '{col}'\")\n",
    "            \n",
    "            # verificar se a coluna existe no segundo dataframe\n",
    "            if col in df2_comparacao.columns:\n",
    "                # comparar coluna por coluna\n",
    "                for idx in df1_comparacao.index:\n",
    "                    total_comparacoes += 1\n",
    "                    \n",
    "                    try:\n",
    "                        val1 = df1_comparacao.loc[idx, col]\n",
    "                        val2 = df2_comparacao.loc[idx, col]\n",
    "                        \n",
    "                        # tratar valores NaN\n",
    "                        if pandas.isna(val1) and pandas.isna(val2):\n",
    "                            continue  # ambos s√£o NaN, consideramos iguais\n",
    "                        elif pandas.isna(val1) or pandas.isna(val2):\n",
    "                            # um √© NaN e outro n√£o\n",
    "                            diferencas_encontradas.append({\n",
    "                                'linha': idx,\n",
    "                                'coluna': col,\n",
    "                                'valor_df1': val1,\n",
    "                                'valor_df2': val2,\n",
    "                                'tipo_diferenca': 'NaN vs Valor'\n",
    "                            })\n",
    "                        elif val1 != val2:\n",
    "                            # valores diferentes\n",
    "                            diferencas_encontradas.append({\n",
    "                                'linha': idx,\n",
    "                                'coluna': col,\n",
    "                                'valor_df1': val1,\n",
    "                                'valor_df2': val2,\n",
    "                                'tipo_diferenca': 'Valores diferentes'\n",
    "                            })\n",
    "                    except Exception as e:\n",
    "                        print(f\"      ‚ùå Erro ao comparar linha {idx}, coluna '{col}': {e}\")\n",
    "                        break\n",
    "            else:\n",
    "                print(f\"      ‚ö†Ô∏è Coluna '{col}' n√£o encontrada no DF2\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro durante a compara√ß√£o: {e}\")\n",
    "        print(\"üí° Isso pode indicar problemas na estrutura dos dados\")\n",
    "        \n",
    "else:\n",
    "    print(f\"\\n‚ùå IMPOSS√çVEL REALIZAR COMPARA√á√ÉO!\")\n",
    "    print(f\"   üìã DF1 colunas: {len(df1_comparacao.columns)}\")\n",
    "    print(f\"   üìã DF2 colunas: {len(df2_comparacao.columns)}\")\n",
    "    diferencas_encontradas = []\n",
    "    total_comparacoes = 0\n",
    "\n",
    "# relat√≥rio dos resultados\n",
    "print(f\"\\nüìà RESULTADOS DA COMPARA√á√ÉO:\")\n",
    "print(f\"   üî¢ Total de compara√ß√µes realizadas: {total_comparacoes:,}\")\n",
    "print(f\"   ‚ùå Diferen√ßas encontradas: {len(diferencas_encontradas):,}\")\n",
    "print(f\"   ‚úÖ Valores iguais: {total_comparacoes - len(diferencas_encontradas):,}\")\n",
    "\n",
    "if total_comparacoes > 0:\n",
    "    taxa_igualdade = ((total_comparacoes - len(diferencas_encontradas)) / total_comparacoes * 100)\n",
    "    print(f\"   üìä Taxa de igualdade: {taxa_igualdade:.2f}%\")\n",
    "\n",
    "if len(diferencas_encontradas) == 0:\n",
    "    print(f\"\\nüéâ PERFEITO! Os dataframes s√£o ID√äNTICOS at√© a coluna especificada!\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è DIFEREN√áAS ENCONTRADAS:\")\n",
    "    print(f\"Mostrando as primeiras 10 diferen√ßas:\")\n",
    "    \n",
    "    for i, diff in enumerate(diferencas_encontradas[:10]):\n",
    "        print(f\"\\n   {i+1}. Linha {diff['linha']}, Coluna '{diff['coluna']}':\")\n",
    "        print(f\"      DF1: {diff['valor_df1']}\")\n",
    "        print(f\"      DF2: {diff['valor_df2']}\")\n",
    "        print(f\"      Tipo: {diff['tipo_diferenca']}\")\n",
    "    \n",
    "    if len(diferencas_encontradas) > 10:\n",
    "        print(f\"\\n   ... e mais {len(diferencas_encontradas) - 10} diferen√ßas\")\n",
    "    \n",
    "    # resumo por coluna\n",
    "    diferencas_por_coluna = {}\n",
    "    for diff in diferencas_encontradas:\n",
    "        col = diff['coluna']\n",
    "        if col not in diferencas_por_coluna:\n",
    "            diferencas_por_coluna[col] = 0\n",
    "        diferencas_por_coluna[col] += 1\n",
    "    \n",
    "    print(f\"\\nüìä DIFEREN√áAS POR COLUNA:\")\n",
    "    for col, count in sorted(diferencas_por_coluna.items()):\n",
    "        print(f\"   {col}: {count} diferen√ßas\")\n",
    "\n",
    "print(f\"\\n‚úÖ COMPARA√á√ÉO CONCLU√çDA!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4bec99aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ AN√ÅLISE DETALHADA DO CONTE√öDO DAS COLUNAS\n",
      "======================================================================\n",
      "‚úÖ Dataframes encontrados. Iniciando an√°lise detalhada...\n",
      "‚ö†Ô∏è Coluna 'Internacional' n√£o encontrada. Analisando todas as 12 colunas comuns\n",
      "üéØ Escopo da an√°lise: 12 colunas\n",
      "   üìä DF1: 2,541 linhas\n",
      "   üìä DF2: 2,541 linhas\n",
      "\n",
      "==================================================\n",
      "üìã COLUNA 1: 'Activity'\n",
      "==================================================\n",
      "üîç INFORMA√á√ïES B√ÅSICAS:\n",
      "   üìä DF1 - Tipo: object | Valores √∫nicos: 733 | Nulos: 0\n",
      "   üìä DF2 - Tipo: object | Valores √∫nicos: 733 | Nulos: 0\n",
      "‚úÖ Tipos compat√≠veis: object\n",
      "\n",
      "üìù ESTAT√çSTICAS DE TEXTO:\n",
      "   DF1 - Comprimento m√©dio: 4.1 caracteres\n",
      "   DF2 - Comprimento m√©dio: 4.1 caracteres\n",
      "\n",
      "üîç AN√ÅLISE DE VALORES √öNICOS:\n",
      "   ü§ù Valores comuns: 733\n",
      "   üìã S√≥ no DF1: 0\n",
      "   üìã S√≥ no DF2: 0\n",
      "\n",
      "üìä COMPARA√á√ÉO DIRETA (amostra de 1,000 linhas):\n",
      "   ‚úÖ Valores iguais: 1,000 (100.0%)\n",
      "   ‚ùå Valores diferentes: 0 (0.0%)\n",
      "\n",
      "‚úÖ COLUNA OK: Sem problemas detectados\n",
      "\n",
      "==================================================\n",
      "üìã COLUNA 2: 'Id_Leg'\n",
      "==================================================\n",
      "üîç INFORMA√á√ïES B√ÅSICAS:\n",
      "   üìä DF1 - Tipo: object | Valores √∫nicos: 4 | Nulos: 0\n",
      "   üìä DF2 - Tipo: object | Valores √∫nicos: 4 | Nulos: 0\n",
      "‚úÖ Tipos compat√≠veis: object\n",
      "\n",
      "üìù ESTAT√çSTICAS DE TEXTO:\n",
      "   DF1 - Comprimento m√©dio: 2.6 caracteres\n",
      "   DF2 - Comprimento m√©dio: 2.6 caracteres\n",
      "\n",
      "üîç AN√ÅLISE DE VALORES √öNICOS:\n",
      "   ü§ù Valores comuns: 4\n",
      "   üìã S√≥ no DF1: 0\n",
      "   üìã S√≥ no DF2: 0\n",
      "\n",
      "üìä COMPARA√á√ÉO DIRETA (amostra de 1,000 linhas):\n",
      "   ‚úÖ Valores iguais: 1,000 (100.0%)\n",
      "   ‚ùå Valores diferentes: 0 (0.0%)\n",
      "\n",
      "‚úÖ COLUNA OK: Sem problemas detectados\n",
      "\n",
      "==================================================\n",
      "üìã COLUNA 3: 'Checkin'\n",
      "==================================================\n",
      "üîç INFORMA√á√ïES B√ÅSICAS:\n",
      "   üìä DF1 - Tipo: object | Valores √∫nicos: 1,857 | Nulos: 0\n",
      "   üìä DF2 - Tipo: object | Valores √∫nicos: 1,857 | Nulos: 0\n",
      "‚úÖ Tipos compat√≠veis: object\n",
      "\n",
      "üìù ESTAT√çSTICAS DE TEXTO:\n",
      "   DF1 - Comprimento m√©dio: 16.1 caracteres\n",
      "   DF2 - Comprimento m√©dio: 19.0 caracteres\n",
      "\n",
      "üîç AN√ÅLISE DE VALORES √öNICOS:\n",
      "   ü§ù Valores comuns: 971\n",
      "   üìã S√≥ no DF1: 886\n",
      "   üìã S√≥ no DF2: 886\n",
      "   üîç Exemplos s√≥ no DF1: ['27DEZ20 06:01', '16AGO22 08:00', '07AGO20 00:00', '13DEZ22 04:45', '06OUT22 12:05']\n",
      "   üîç Exemplos s√≥ no DF2: ['2022-08-10 06:50:00', '2019-10-11 10:30:00', '2022-10-15 07:15:00', '2021-12-21 12:15:00', '2019-10-05 13:20:00']\n",
      "\n",
      "üìä COMPARA√á√ÉO DIRETA (amostra de 1,000 linhas):\n",
      "   ‚úÖ Valores iguais: 706 (70.6%)\n",
      "   ‚ùå Valores diferentes: 294 (29.4%)\n",
      "\n",
      "‚ö†Ô∏è PROBLEMAS DETECTADOS:\n",
      "   ‚ùå 886 valores √∫nicos s√≥ no DF1\n",
      "   ‚ùå 886 valores √∫nicos s√≥ no DF2\n",
      "   ‚ùå Taxa de igualdade baixa: 70.6%\n",
      "\n",
      "==================================================\n",
      "üìã COLUNA 4: 'Start'\n",
      "==================================================\n",
      "üîç INFORMA√á√ïES B√ÅSICAS:\n",
      "   üìä DF1 - Tipo: object | Valores √∫nicos: 2,541 | Nulos: 0\n",
      "   üìä DF2 - Tipo: object | Valores √∫nicos: 2,541 | Nulos: 0\n",
      "‚úÖ Tipos compat√≠veis: object\n",
      "\n",
      "üìù ESTAT√çSTICAS DE TEXTO:\n",
      "   DF1 - Comprimento m√©dio: 16.1 caracteres\n",
      "   DF2 - Comprimento m√©dio: 19.0 caracteres\n",
      "\n",
      "üîç AN√ÅLISE DE VALORES √öNICOS:\n",
      "   ü§ù Valores comuns: 1,322\n",
      "   üìã S√≥ no DF1: 1,219\n",
      "   üìã S√≥ no DF2: 1,219\n",
      "   üîç Exemplos s√≥ no DF1: ['24SET21 10:54', '01SET22 19:36', '20DEZ20 02:21', '27DEZ20 06:01', '06FEV20 04:11']\n",
      "   üîç Exemplos s√≥ no DF2: ['2022-08-10 06:50:00', '2022-12-11 03:45:00', '2019-10-11 10:30:00', '2021-12-26 23:04:00', '2022-10-06 19:40:00']\n",
      "\n",
      "üìä COMPARA√á√ÉO DIRETA (amostra de 1,000 linhas):\n",
      "   ‚úÖ Valores iguais: 706 (70.6%)\n",
      "   ‚ùå Valores diferentes: 294 (29.4%)\n",
      "\n",
      "‚ö†Ô∏è PROBLEMAS DETECTADOS:\n",
      "   ‚ùå 1219 valores √∫nicos s√≥ no DF1\n",
      "   ‚ùå 1219 valores √∫nicos s√≥ no DF2\n",
      "   ‚ùå Taxa de igualdade baixa: 70.6%\n",
      "\n",
      "==================================================\n",
      "üìã COLUNA 5: 'Dep'\n",
      "==================================================\n",
      "üîç INFORMA√á√ïES B√ÅSICAS:\n",
      "   üìä DF1 - Tipo: object | Valores √∫nicos: 59 | Nulos: 0\n",
      "   üìä DF2 - Tipo: object | Valores √∫nicos: 59 | Nulos: 0\n",
      "‚úÖ Tipos compat√≠veis: object\n",
      "\n",
      "üìù ESTAT√çSTICAS DE TEXTO:\n",
      "   DF1 - Comprimento m√©dio: 3.0 caracteres\n",
      "   DF2 - Comprimento m√©dio: 3.0 caracteres\n",
      "\n",
      "üîç AN√ÅLISE DE VALORES √öNICOS:\n",
      "   ü§ù Valores comuns: 59\n",
      "   üìã S√≥ no DF1: 0\n",
      "   üìã S√≥ no DF2: 0\n",
      "\n",
      "üìä COMPARA√á√ÉO DIRETA (amostra de 1,000 linhas):\n",
      "   ‚úÖ Valores iguais: 1,000 (100.0%)\n",
      "   ‚ùå Valores diferentes: 0 (0.0%)\n",
      "\n",
      "‚úÖ COLUNA OK: Sem problemas detectados\n",
      "\n",
      "==================================================\n",
      "üìã COLUNA 6: 'Arr'\n",
      "==================================================\n",
      "üîç INFORMA√á√ïES B√ÅSICAS:\n",
      "   üìä DF1 - Tipo: object | Valores √∫nicos: 59 | Nulos: 0\n",
      "   üìä DF2 - Tipo: object | Valores √∫nicos: 59 | Nulos: 0\n",
      "‚úÖ Tipos compat√≠veis: object\n",
      "\n",
      "üìù ESTAT√çSTICAS DE TEXTO:\n",
      "   DF1 - Comprimento m√©dio: 3.0 caracteres\n",
      "   DF2 - Comprimento m√©dio: 3.0 caracteres\n",
      "\n",
      "üîç AN√ÅLISE DE VALORES √öNICOS:\n",
      "   ü§ù Valores comuns: 59\n",
      "   üìã S√≥ no DF1: 0\n",
      "   üìã S√≥ no DF2: 0\n",
      "\n",
      "üìä COMPARA√á√ÉO DIRETA (amostra de 1,000 linhas):\n",
      "   ‚úÖ Valores iguais: 1,000 (100.0%)\n",
      "   ‚ùå Valores diferentes: 0 (0.0%)\n",
      "\n",
      "‚úÖ COLUNA OK: Sem problemas detectados\n",
      "\n",
      "==================================================\n",
      "üìã COLUNA 7: 'End'\n",
      "==================================================\n",
      "üîç INFORMA√á√ïES B√ÅSICAS:\n",
      "   üìä DF1 - Tipo: object | Valores √∫nicos: 2,541 | Nulos: 0\n",
      "   üìä DF2 - Tipo: object | Valores √∫nicos: 2,541 | Nulos: 0\n",
      "‚úÖ Tipos compat√≠veis: object\n",
      "\n",
      "üìù ESTAT√çSTICAS DE TEXTO:\n",
      "   DF1 - Comprimento m√©dio: 16.1 caracteres\n",
      "   DF2 - Comprimento m√©dio: 19.0 caracteres\n",
      "\n",
      "üîç AN√ÅLISE DE VALORES √öNICOS:\n",
      "   ü§ù Valores comuns: 1,322\n",
      "   üìã S√≥ no DF1: 1,219\n",
      "   üìã S√≥ no DF2: 1,219\n",
      "   üîç Exemplos s√≥ no DF1: ['13ABR20 23:59', '21MAI22 12:35', '22DEZ22 00:11', '26AGO21 18:40', '20SET19 14:07']\n",
      "   üîç Exemplos s√≥ no DF2: ['2017-12-26 03:57:00', '2022-08-10 06:50:00', '2021-12-14 20:29:00', '2019-12-18 13:15:00', '2022-10-31 19:55:00']\n",
      "\n",
      "üìä COMPARA√á√ÉO DIRETA (amostra de 1,000 linhas):\n",
      "   ‚úÖ Valores iguais: 707 (70.7%)\n",
      "   ‚ùå Valores diferentes: 293 (29.3%)\n",
      "\n",
      "‚ö†Ô∏è PROBLEMAS DETECTADOS:\n",
      "   ‚ùå 1219 valores √∫nicos s√≥ no DF1\n",
      "   ‚ùå 1219 valores √∫nicos s√≥ no DF2\n",
      "   ‚ùå Taxa de igualdade baixa: 70.7%\n",
      "\n",
      "==================================================\n",
      "üìã COLUNA 8: 'Checkout'\n",
      "==================================================\n",
      "üîç INFORMA√á√ïES B√ÅSICAS:\n",
      "   üìä DF1 - Tipo: object | Valores √∫nicos: 1,869 | Nulos: 0\n",
      "   üìä DF2 - Tipo: object | Valores √∫nicos: 1,869 | Nulos: 0\n",
      "‚úÖ Tipos compat√≠veis: object\n",
      "\n",
      "üìù ESTAT√çSTICAS DE TEXTO:\n",
      "   DF1 - Comprimento m√©dio: 16.1 caracteres\n",
      "   DF2 - Comprimento m√©dio: 19.0 caracteres\n",
      "\n",
      "üîç AN√ÅLISE DE VALORES √öNICOS:\n",
      "   ü§ù Valores comuns: 979\n",
      "   üìã S√≥ no DF1: 890\n",
      "   üìã S√≥ no DF2: 890\n",
      "   üîç Exemplos s√≥ no DF1: ['13ABR20 23:59', '07AGO20 00:00', '26OUT19 23:25', '18OUT20 00:00', '23DEZ19 13:00']\n",
      "   üîç Exemplos s√≥ no DF2: ['2022-08-10 06:50:00', '2021-08-21 21:32:00', '2019-12-18 13:15:00', '2019-02-26 03:30:00', '2022-10-21 01:30:00']\n",
      "\n",
      "üìä COMPARA√á√ÉO DIRETA (amostra de 1,000 linhas):\n",
      "   ‚úÖ Valores iguais: 707 (70.7%)\n",
      "   ‚ùå Valores diferentes: 293 (29.3%)\n",
      "\n",
      "‚ö†Ô∏è PROBLEMAS DETECTADOS:\n",
      "   ‚ùå 890 valores √∫nicos s√≥ no DF1\n",
      "   ‚ùå 890 valores √∫nicos s√≥ no DF2\n",
      "   ‚ùå Taxa de igualdade baixa: 70.7%\n",
      "\n",
      "==================================================\n",
      "üìã COLUNA 9: 'AcVer'\n",
      "==================================================\n",
      "üîç INFORMA√á√ïES B√ÅSICAS:\n",
      "   üìä DF1 - Tipo: object | Valores √∫nicos: 13 | Nulos: 0\n",
      "   üìä DF2 - Tipo: object | Valores √∫nicos: 13 | Nulos: 0\n",
      "‚úÖ Tipos compat√≠veis: object\n",
      "\n",
      "üìù ESTAT√çSTICAS DE TEXTO:\n",
      "   DF1 - Comprimento m√©dio: 1.9 caracteres\n",
      "   DF2 - Comprimento m√©dio: 1.9 caracteres\n",
      "\n",
      "üîç AN√ÅLISE DE VALORES √öNICOS:\n",
      "   ü§ù Valores comuns: 13\n",
      "   üìã S√≥ no DF1: 0\n",
      "   üìã S√≥ no DF2: 0\n",
      "\n",
      "üìä COMPARA√á√ÉO DIRETA (amostra de 1,000 linhas):\n",
      "   ‚úÖ Valores iguais: 1,000 (100.0%)\n",
      "   ‚ùå Valores diferentes: 0 (0.0%)\n",
      "\n",
      "‚úÖ COLUNA OK: Sem problemas detectados\n",
      "\n",
      "==================================================\n",
      "üìã COLUNA 10: 'DD'\n",
      "==================================================\n",
      "üîç INFORMA√á√ïES B√ÅSICAS:\n",
      "   üìä DF1 - Tipo: object | Valores √∫nicos: 9 | Nulos: 0\n",
      "   üìä DF2 - Tipo: object | Valores √∫nicos: 9 | Nulos: 0\n",
      "‚úÖ Tipos compat√≠veis: object\n",
      "\n",
      "üìù ESTAT√çSTICAS DE TEXTO:\n",
      "   DF1 - Comprimento m√©dio: 1.0 caracteres\n",
      "   DF2 - Comprimento m√©dio: 1.0 caracteres\n",
      "\n",
      "üîç AN√ÅLISE DE VALORES √öNICOS:\n",
      "   ü§ù Valores comuns: 9\n",
      "   üìã S√≥ no DF1: 0\n",
      "   üìã S√≥ no DF2: 0\n",
      "\n",
      "üìä COMPARA√á√ÉO DIRETA (amostra de 1,000 linhas):\n",
      "   ‚úÖ Valores iguais: 1,000 (100.0%)\n",
      "   ‚ùå Valores diferentes: 0 (0.0%)\n",
      "\n",
      "‚úÖ COLUNA OK: Sem problemas detectados\n",
      "\n",
      "==================================================\n",
      "üìã COLUNA 11: 'CAT'\n",
      "==================================================\n",
      "üîç INFORMA√á√ïES B√ÅSICAS:\n",
      "   üìä DF1 - Tipo: object | Valores √∫nicos: 3 | Nulos: 0\n",
      "   üìä DF2 - Tipo: object | Valores √∫nicos: 3 | Nulos: 0\n",
      "‚úÖ Tipos compat√≠veis: object\n",
      "\n",
      "üìù ESTAT√çSTICAS DE TEXTO:\n",
      "   DF1 - Comprimento m√©dio: 2.0 caracteres\n",
      "   DF2 - Comprimento m√©dio: 2.0 caracteres\n",
      "\n",
      "üîç AN√ÅLISE DE VALORES √öNICOS:\n",
      "   ü§ù Valores comuns: 3\n",
      "   üìã S√≥ no DF1: 0\n",
      "   üìã S√≥ no DF2: 0\n",
      "\n",
      "üìä COMPARA√á√ÉO DIRETA (amostra de 1,000 linhas):\n",
      "   ‚úÖ Valores iguais: 1,000 (100.0%)\n",
      "   ‚ùå Valores diferentes: 0 (0.0%)\n",
      "\n",
      "‚úÖ COLUNA OK: Sem problemas detectados\n",
      "\n",
      "==================================================\n",
      "üìã COLUNA 12: 'Crew'\n",
      "==================================================\n",
      "üîç INFORMA√á√ïES B√ÅSICAS:\n",
      "   üìä DF1 - Tipo: object | Valores √∫nicos: 647 | Nulos: 0\n",
      "   üìä DF2 - Tipo: object | Valores √∫nicos: 647 | Nulos: 0\n",
      "‚úÖ Tipos compat√≠veis: object\n",
      "\n",
      "üìù ESTAT√çSTICAS DE TEXTO:\n",
      "   DF1 - Comprimento m√©dio: 77.4 caracteres\n",
      "   DF2 - Comprimento m√©dio: 77.4 caracteres\n",
      "\n",
      "üîç AN√ÅLISE DE VALORES √öNICOS:\n",
      "   ü§ù Valores comuns: 643\n",
      "   üìã S√≥ no DF1: 4\n",
      "   üìã S√≥ no DF2: 4\n",
      "   üîç Exemplos s√≥ no DF1: ['ALAN DE SOUZA BARBOSA - FO PATRICIA SAYURI HORST KATO - FA RAFAEL TEIXEIRA BELTR√ÉO - CL THOMAS SOARES MOREIRA - FA', 'ALINE DE DEUS PEDRON BISTAFFA - CL ANDRE DA SILVA BARBOSA - FO ANDR√â COSTA DE OLIVEIRA NEVES - DHD BEATRIZ FARIA DE ALMEIDA MAGNABOSCO - FA EVELLYN LAGARES MOREIRA - FA NADILENE APARECIDA THOME - FA', 'ANA PAULA RAMALHO RAMOS - FA ANDRE LUIZ SETARO - DHD CARLOS AIRTON DE LACERDA GIUDICI - DHD DANIEL HENRIQUE OLIVEIRA VERAS - DHD FABIOLA PEDRO DOS SANTOS FERREIRA - DHD GABRIELA SOUSA RAMOS - FA GUILHERME PICOLOTTO - FO LEANDRO DE OLIVEIRA PARATELLA - DHD MARCIA FERREIRA DA SILVA - DHD PERICLES DE TARSO PENHA - CL SILVIA PICCOLI - FA S√âRGIO AUGUSTO ANACLETO - DHD WALDISZELE GOMES DOMINGOS - DHD', 'ERIKA CAMARGO PEREIRA - FA FELIPE ISHIHIRA - FA FRANCIELI RIGUI - CL LUCAS OLIVEIRA FARIA - FA OCTAVIANO FALCAO REIS - DHD P√âRICLES DO VALE FERNANDES - DHD TERCIO LUIZ CIARLARIELLO CUNHA RODRIGUES - DHD WILLIAM AUGUSTO ROCHA KRAPP - FO']\n",
      "   üîç Exemplos s√≥ no DF2: ['ERIKA CAMARGO PEREIRA - FA FELIPE ISHIHIRA - FA FRANCIELI RIGUI - CL LUCAS OLIVEIRA FARIA - FA OCTAVIANO FALCAO REIS - DHD P√É\\x89RICLES DO VALE FERNANDES - DHD TERCIO LUIZ CIARLARIELLO CUNHA RODRIGUES - DHD WILLIAM AUGUSTO ROCHA KRAPP - FO', 'ALINE DE DEUS PEDRON BISTAFFA - CL ANDRE DA SILVA BARBOSA - FO ANDR√É\\x89 COSTA DE OLIVEIRA NEVES - DHD BEATRIZ FARIA DE ALMEIDA MAGNABOSCO - FA EVELLYN LAGARES MOREIRA - FA NADILENE APARECIDA THOME - FA', 'ALAN DE SOUZA BARBOSA - FO PATRICIA SAYURI HORST KATO - FA RAFAEL TEIXEIRA BELTR√É\\x83O - CL THOMAS SOARES MOREIRA - FA', 'ANA PAULA RAMALHO RAMOS - FA ANDRE LUIZ SETARO - DHD CARLOS AIRTON DE LACERDA GIUDICI - DHD DANIEL HENRIQUE OLIVEIRA VERAS - DHD FABIOLA PEDRO DOS SANTOS FERREIRA - DHD GABRIELA SOUSA RAMOS - FA GUILHERME PICOLOTTO - FO LEANDRO DE OLIVEIRA PARATELLA - DHD MARCIA FERREIRA DA SILVA - DHD PERICLES DE TARSO PENHA - CL SILVIA PICCOLI - FA S√É\\x89RGIO AUGUSTO ANACLETO - DHD WALDISZELE GOMES DOMINGOS - DHD']\n",
      "\n",
      "üìä COMPARA√á√ÉO DIRETA (amostra de 1,000 linhas):\n",
      "   ‚úÖ Valores iguais: 998 (99.8%)\n",
      "   ‚ùå Valores diferentes: 2 (0.2%)\n",
      "\n",
      "‚ö†Ô∏è PROBLEMAS DETECTADOS:\n",
      "   ‚ùå 4 valores √∫nicos s√≥ no DF1\n",
      "   ‚ùå 4 valores √∫nicos s√≥ no DF2\n",
      "\n",
      "======================================================================\n",
      "üìä RESUMO GERAL DA AN√ÅLISE\n",
      "======================================================================\n",
      "üéØ Total de colunas analisadas: 12\n",
      "‚úÖ Colunas sem problemas: 7 (58.3%)\n",
      "‚ö†Ô∏è Colunas com problemas: 5 (41.7%)\n",
      "\n",
      "‚ùå COLUNAS COM PROBLEMAS:\n",
      "   1. 'Checkin' - 3 problema(s)\n",
      "      ‚Ä¢ 886 valores √∫nicos s√≥ no DF1\n",
      "      ‚Ä¢ 886 valores √∫nicos s√≥ no DF2\n",
      "      ‚Ä¢ Taxa de igualdade baixa: 70.6%\n",
      "   2. 'Start' - 3 problema(s)\n",
      "      ‚Ä¢ 1219 valores √∫nicos s√≥ no DF1\n",
      "      ‚Ä¢ 1219 valores √∫nicos s√≥ no DF2\n",
      "      ‚Ä¢ Taxa de igualdade baixa: 70.6%\n",
      "   3. 'End' - 3 problema(s)\n",
      "      ‚Ä¢ 1219 valores √∫nicos s√≥ no DF1\n",
      "      ‚Ä¢ 1219 valores √∫nicos s√≥ no DF2\n",
      "      ‚Ä¢ Taxa de igualdade baixa: 70.7%\n",
      "   4. 'Checkout' - 3 problema(s)\n",
      "      ‚Ä¢ 890 valores √∫nicos s√≥ no DF1\n",
      "      ‚Ä¢ 890 valores √∫nicos s√≥ no DF2\n",
      "      ‚Ä¢ Taxa de igualdade baixa: 70.7%\n",
      "   5. 'Crew' - 2 problema(s)\n",
      "      ‚Ä¢ 4 valores √∫nicos s√≥ no DF1\n",
      "      ‚Ä¢ 4 valores √∫nicos s√≥ no DF2\n",
      "\n",
      "üìã DISTRIBUI√á√ÉO POR TIPO DE COLUNA:\n",
      "   Texto: 12 colunas\n",
      "\n",
      "‚úÖ AN√ÅLISE DETALHADA CONCLU√çDA!\n",
      "üíæ Relat√≥rio salvo na vari√°vel 'relatorio_colunas'\n"
     ]
    }
   ],
   "source": [
    "# AN√ÅLISE DETALHADA DO CONTE√öDO DE CADA COLUNA AT√â \"INTERNACIONAL\"\n",
    "print(\"üî¨ AN√ÅLISE DETALHADA DO CONTE√öDO DAS COLUNAS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# verificar se os dataframes existem\n",
    "try:\n",
    "    df1\n",
    "    df2\n",
    "    print(\"‚úÖ Dataframes encontrados. Iniciando an√°lise detalhada...\")\n",
    "    \n",
    "    # encontrar a posi√ß√£o da coluna \"Internacional\"\n",
    "    if 'Internacional' in df1.columns and 'Internacional' in df2.columns:\n",
    "        pos_internacional_df1 = df1.columns.get_loc('Internacional')\n",
    "        pos_internacional_df2 = df2.columns.get_loc('Internacional')\n",
    "        pos_limite = min(pos_internacional_df1, pos_internacional_df2) + 1\n",
    "        print(f\"üìç Analisando at√© a coluna 'Internacional' (posi√ß√£o {pos_limite-1})\")\n",
    "    else:\n",
    "        pos_limite = min(len(df1.columns), len(df2.columns))\n",
    "        print(f\"‚ö†Ô∏è Coluna 'Internacional' n√£o encontrada. Analisando todas as {pos_limite} colunas comuns\")\n",
    "    \n",
    "    # selecionar colunas para an√°lise\n",
    "    df1_analise = df1.iloc[:, :pos_limite]\n",
    "    df2_analise = df2.iloc[:, :pos_limite]\n",
    "    \n",
    "    print(f\"üéØ Escopo da an√°lise: {len(df1_analise.columns)} colunas\")\n",
    "    print(f\"   üìä DF1: {df1_analise.shape[0]:,} linhas\")\n",
    "    print(f\"   üìä DF2: {df2_analise.shape[0]:,} linhas\")\n",
    "    \n",
    "    # an√°lise coluna por coluna\n",
    "    relatorio_colunas = []\n",
    "    \n",
    "    for i, col in enumerate(df1_analise.columns):\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"üìã COLUNA {i+1}: '{col}'\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # verificar se a coluna existe em ambos os dataframes\n",
    "        if col not in df2_analise.columns:\n",
    "            print(f\"‚ùå Coluna '{col}' n√£o existe no DF2!\")\n",
    "            continue\n",
    "            \n",
    "        # obter dados das colunas\n",
    "        serie1 = df1_analise[col]\n",
    "        serie2 = df2_analise[col]\n",
    "        \n",
    "        # informa√ß√µes b√°sicas\n",
    "        print(f\"üîç INFORMA√á√ïES B√ÅSICAS:\")\n",
    "        print(f\"   üìä DF1 - Tipo: {serie1.dtype} | Valores √∫nicos: {serie1.nunique():,} | Nulos: {serie1.isnull().sum():,}\")\n",
    "        print(f\"   üìä DF2 - Tipo: {serie2.dtype} | Valores √∫nicos: {serie2.nunique():,} | Nulos: {serie2.isnull().sum():,}\")\n",
    "        \n",
    "        # estat√≠sticas detalhadas\n",
    "        diagnostico = {\n",
    "            'coluna': col,\n",
    "            'posicao': i,\n",
    "            'tipo_df1': str(serie1.dtype),\n",
    "            'tipo_df2': str(serie2.dtype),\n",
    "            'valores_unicos_df1': serie1.nunique(),\n",
    "            'valores_unicos_df2': serie2.nunique(),\n",
    "            'nulos_df1': serie1.isnull().sum(),\n",
    "            'nulos_df2': serie2.isnull().sum(),\n",
    "            'tamanho_df1': len(serie1),\n",
    "            'tamanho_df2': len(serie2)\n",
    "        }\n",
    "        \n",
    "        # verificar compatibilidade de tipos\n",
    "        if serie1.dtype != serie2.dtype:\n",
    "            print(f\"‚ö†Ô∏è TIPOS DIFERENTES: DF1={serie1.dtype} vs DF2={serie2.dtype}\")\n",
    "            diagnostico['problema_tipo'] = True\n",
    "        else:\n",
    "            print(f\"‚úÖ Tipos compat√≠veis: {serie1.dtype}\")\n",
    "            diagnostico['problema_tipo'] = False\n",
    "        \n",
    "        # an√°lise para colunas num√©ricas\n",
    "        if pandas.api.types.is_numeric_dtype(serie1) and pandas.api.types.is_numeric_dtype(serie2):\n",
    "            print(f\"\\nüìä ESTAT√çSTICAS NUM√âRICAS:\")\n",
    "            \n",
    "            # estat√≠sticas b√°sicas\n",
    "            stats1 = serie1.describe()\n",
    "            stats2 = serie2.describe()\n",
    "            \n",
    "            print(f\"   DF1 - Min: {stats1['min']:.2f} | Max: {stats1['max']:.2f} | M√©dia: {stats1['mean']:.2f}\")\n",
    "            print(f\"   DF2 - Min: {stats2['min']:.2f} | Max: {stats2['max']:.2f} | M√©dia: {stats2['mean']:.2f}\")\n",
    "            \n",
    "            # diferen√ßas nas estat√≠sticas\n",
    "            diff_min = abs(stats1['min'] - stats2['min'])\n",
    "            diff_max = abs(stats1['max'] - stats2['max'])\n",
    "            diff_mean = abs(stats1['mean'] - stats2['mean'])\n",
    "            \n",
    "            print(f\"   üîÑ Diferen√ßas - Min: {diff_min:.2f} | Max: {diff_max:.2f} | M√©dia: {diff_mean:.2f}\")\n",
    "            \n",
    "            diagnostico.update({\n",
    "                'tipo_coluna': 'numerica',\n",
    "                'min_df1': stats1['min'],\n",
    "                'max_df1': stats1['max'], \n",
    "                'media_df1': stats1['mean'],\n",
    "                'min_df2': stats2['min'],\n",
    "                'max_df2': stats2['max'],\n",
    "                'media_df2': stats2['mean'],\n",
    "                'diff_min': diff_min,\n",
    "                'diff_max': diff_max,\n",
    "                'diff_media': diff_mean\n",
    "            })\n",
    "            \n",
    "        # an√°lise para colunas de texto\n",
    "        elif pandas.api.types.is_string_dtype(serie1) or pandas.api.types.is_object_dtype(serie1):\n",
    "            print(f\"\\nüìù ESTAT√çSTICAS DE TEXTO:\")\n",
    "            \n",
    "            # comprimento m√©dio das strings\n",
    "            try:\n",
    "                len_medio1 = serie1.astype(str).str.len().mean()\n",
    "                len_medio2 = serie2.astype(str).str.len().mean()\n",
    "                print(f\"   DF1 - Comprimento m√©dio: {len_medio1:.1f} caracteres\")\n",
    "                print(f\"   DF2 - Comprimento m√©dio: {len_medio2:.1f} caracteres\")\n",
    "                \n",
    "                diagnostico.update({\n",
    "                    'tipo_coluna': 'texto',\n",
    "                    'comprimento_medio_df1': len_medio1,\n",
    "                    'comprimento_medio_df2': len_medio2\n",
    "                })\n",
    "            except:\n",
    "                print(f\"   ‚ö†Ô∏è Erro ao calcular comprimento m√©dio\")\n",
    "                diagnostico['tipo_coluna'] = 'texto'\n",
    "        \n",
    "        # an√°lise para colunas de data\n",
    "        elif pandas.api.types.is_datetime64_any_dtype(serie1):\n",
    "            print(f\"\\nüìÖ ESTAT√çSTICAS DE DATA:\")\n",
    "            print(f\"   DF1 - Data m√≠n: {serie1.min()} | Data m√°x: {serie1.max()}\")\n",
    "            print(f\"   DF2 - Data m√≠n: {serie2.min()} | Data m√°x: {serie2.max()}\")\n",
    "            \n",
    "            diagnostico.update({\n",
    "                'tipo_coluna': 'data',\n",
    "                'data_min_df1': serie1.min(),\n",
    "                'data_max_df1': serie1.max(),\n",
    "                'data_min_df2': serie2.min(),\n",
    "                'data_max_df2': serie2.max()\n",
    "            })\n",
    "        \n",
    "        else:\n",
    "            diagnostico['tipo_coluna'] = 'outro'\n",
    "        \n",
    "        # compara√ß√£o de valores √∫nicos\n",
    "        print(f\"\\nüîç AN√ÅLISE DE VALORES √öNICOS:\")\n",
    "        \n",
    "        # valores √∫nicos em cada dataframe\n",
    "        unicos1 = set(serie1.dropna().astype(str))\n",
    "        unicos2 = set(serie2.dropna().astype(str))\n",
    "        \n",
    "        # interse√ß√£o e diferen√ßas\n",
    "        intersecao = unicos1.intersection(unicos2)\n",
    "        so_df1 = unicos1 - unicos2\n",
    "        so_df2 = unicos2 - unicos1\n",
    "        \n",
    "        print(f\"   ü§ù Valores comuns: {len(intersecao):,}\")\n",
    "        print(f\"   üìã S√≥ no DF1: {len(so_df1):,}\")\n",
    "        print(f\"   üìã S√≥ no DF2: {len(so_df2):,}\")\n",
    "        \n",
    "        diagnostico.update({\n",
    "            'valores_comuns': len(intersecao),\n",
    "            'valores_so_df1': len(so_df1),\n",
    "            'valores_so_df2': len(so_df2)\n",
    "        })\n",
    "        \n",
    "        # mostrar alguns valores √∫nicos se houver diferen√ßas\n",
    "        if so_df1:\n",
    "            print(f\"   üîç Exemplos s√≥ no DF1: {list(so_df1)[:5]}\")\n",
    "        if so_df2:\n",
    "            print(f\"   üîç Exemplos s√≥ no DF2: {list(so_df2)[:5]}\")\n",
    "        \n",
    "        # compara√ß√£o direta de valores (amostra)\n",
    "        min_size = min(len(serie1), len(serie2))\n",
    "        if min_size > 0:\n",
    "            # comparar primeiras 1000 linhas para performance\n",
    "            sample_size = min(1000, min_size)\n",
    "            comparacao_sample = (serie1.iloc[:sample_size].astype(str) == serie2.iloc[:sample_size].astype(str))\n",
    "            valores_iguais = comparacao_sample.sum()\n",
    "            \n",
    "            print(f\"\\nüìä COMPARA√á√ÉO DIRETA (amostra de {sample_size:,} linhas):\")\n",
    "            print(f\"   ‚úÖ Valores iguais: {valores_iguais:,} ({valores_iguais/sample_size*100:.1f}%)\")\n",
    "            print(f\"   ‚ùå Valores diferentes: {sample_size - valores_iguais:,} ({(sample_size - valores_iguais)/sample_size*100:.1f}%)\")\n",
    "            \n",
    "            diagnostico.update({\n",
    "                'amostra_size': sample_size,\n",
    "                'valores_iguais_amostra': valores_iguais,\n",
    "                'taxa_igualdade_amostra': valores_iguais/sample_size*100\n",
    "            })\n",
    "        \n",
    "        # diagn√≥stico final da coluna\n",
    "        problemas = []\n",
    "        if diagnostico.get('problema_tipo', False):\n",
    "            problemas.append(\"Tipos incompat√≠veis\")\n",
    "        if diagnostico['nulos_df1'] != diagnostico['nulos_df2']:\n",
    "            problemas.append(\"Quantidade de nulos diferentes\")\n",
    "        if diagnostico['valores_so_df1'] > 0:\n",
    "            problemas.append(f\"{diagnostico['valores_so_df1']} valores √∫nicos s√≥ no DF1\")\n",
    "        if diagnostico['valores_so_df2'] > 0:\n",
    "            problemas.append(f\"{diagnostico['valores_so_df2']} valores √∫nicos s√≥ no DF2\")\n",
    "        if diagnostico.get('taxa_igualdade_amostra', 100) < 95:\n",
    "            problemas.append(f\"Taxa de igualdade baixa: {diagnostico.get('taxa_igualdade_amostra', 0):.1f}%\")\n",
    "        \n",
    "        if problemas:\n",
    "            print(f\"\\n‚ö†Ô∏è PROBLEMAS DETECTADOS:\")\n",
    "            for problema in problemas:\n",
    "                print(f\"   ‚ùå {problema}\")\n",
    "            diagnostico['status'] = 'COM_PROBLEMAS'\n",
    "            diagnostico['problemas'] = problemas\n",
    "        else:\n",
    "            print(f\"\\n‚úÖ COLUNA OK: Sem problemas detectados\")\n",
    "            diagnostico['status'] = 'OK'\n",
    "            diagnostico['problemas'] = []\n",
    "        \n",
    "        relatorio_colunas.append(diagnostico)\n",
    "    \n",
    "    # RESUMO GERAL\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üìä RESUMO GERAL DA AN√ÅLISE\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    colunas_ok = [r for r in relatorio_colunas if r['status'] == 'OK']\n",
    "    colunas_problemas = [r for r in relatorio_colunas if r['status'] == 'COM_PROBLEMAS']\n",
    "    \n",
    "    print(f\"üéØ Total de colunas analisadas: {len(relatorio_colunas)}\")\n",
    "    print(f\"‚úÖ Colunas sem problemas: {len(colunas_ok)} ({len(colunas_ok)/len(relatorio_colunas)*100:.1f}%)\")\n",
    "    print(f\"‚ö†Ô∏è Colunas com problemas: {len(colunas_problemas)} ({len(colunas_problemas)/len(relatorio_colunas)*100:.1f}%)\")\n",
    "    \n",
    "    if colunas_problemas:\n",
    "        print(f\"\\n‚ùå COLUNAS COM PROBLEMAS:\")\n",
    "        for i, col_info in enumerate(colunas_problemas, 1):\n",
    "            print(f\"   {i}. '{col_info['coluna']}' - {len(col_info['problemas'])} problema(s)\")\n",
    "            for problema in col_info['problemas']:\n",
    "                print(f\"      ‚Ä¢ {problema}\")\n",
    "    \n",
    "    # estat√≠sticas por tipo de coluna\n",
    "    tipos_coluna = {}\n",
    "    for r in relatorio_colunas:\n",
    "        tipo = r.get('tipo_coluna', 'outro')\n",
    "        if tipo not in tipos_coluna:\n",
    "            tipos_coluna[tipo] = 0\n",
    "        tipos_coluna[tipo] += 1\n",
    "    \n",
    "    print(f\"\\nüìã DISTRIBUI√á√ÉO POR TIPO DE COLUNA:\")\n",
    "    for tipo, count in tipos_coluna.items():\n",
    "        print(f\"   {tipo.title()}: {count} colunas\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ AN√ÅLISE DETALHADA CONCLU√çDA!\")\n",
    "    print(f\"üíæ Relat√≥rio salvo na vari√°vel 'relatorio_colunas'\")\n",
    "    \n",
    "except NameError:\n",
    "    print(\"‚ùå Dataframes n√£o encontrados. Execute primeiro a c√©lula de carregamento.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro durante a an√°lise: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fc948bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ EXPORTANDO RELAT√ìRIO DE COLUNAS\n",
      "==================================================\n",
      "‚úÖ Relat√≥rio encontrado com 12 colunas analisadas\n",
      "üìÇ Pasta de sa√≠da: G:/PROJETOS PYTHON/aeronautas_azul/AERONAUTAS/ARQUIVOS TRABALHADOS/RICARDO LAZZARINI\n",
      "üìù Nome base: relatorio_comparacao_colunas_20250704_182137\n",
      "‚úÖ CSV salvo: G:/PROJETOS PYTHON/aeronautas_azul/AERONAUTAS/ARQUIVOS TRABALHADOS/RICARDO LAZZARINI\\relatorio_comparacao_colunas_20250704_182137.csv\n",
      "‚úÖ Excel salvo: G:/PROJETOS PYTHON/aeronautas_azul/AERONAUTAS/ARQUIVOS TRABALHADOS/RICARDO LAZZARINI\\relatorio_comparacao_colunas_20250704_182137.xlsx\n",
      "‚ùå Erro ao salvar relat√≥rio: The truth value of an empty array is ambiguous. Use `array.size > 0` to check that an array is not empty.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rilaz\\AppData\\Local\\Temp\\ipykernel_2208\\532715654.py\", line 99, in <module>\n",
      "    if pd.isna(valor):\n",
      "       ^^^^^^^^^^^^^^\n",
      "ValueError: The truth value of an empty array is ambiguous. Use `array.size > 0` to check that an array is not empty.\n"
     ]
    }
   ],
   "source": [
    "# SALVAR RELAT√ìRIO DE COLUNAS EM ARQUIVO\n",
    "print(\"üíæ EXPORTANDO RELAT√ìRIO DE COLUNAS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "try:\n",
    "    # verificar se o relat√≥rio existe\n",
    "    relatorio_colunas\n",
    "    print(f\"‚úÖ Relat√≥rio encontrado com {len(relatorio_colunas)} colunas analisadas\")\n",
    "    \n",
    "    # definir nome do arquivo baseado nos arquivos originais\n",
    "    import os\n",
    "    from datetime import datetime\n",
    "    \n",
    "    # pegar o diret√≥rio atual onde est√£o os arquivos\n",
    "    if 'diretorio' in locals() and diretorio:\n",
    "        pasta_saida = diretorio\n",
    "    else:\n",
    "        pasta_saida = os.getcwd()\n",
    "    \n",
    "    # criar nome do arquivo com timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    nome_base = f\"relatorio_comparacao_colunas_{timestamp}\"\n",
    "    \n",
    "    print(f\"üìÇ Pasta de sa√≠da: {pasta_saida}\")\n",
    "    print(f\"üìù Nome base: {nome_base}\")\n",
    "    \n",
    "    # 1. SALVAR COMO CSV (formato tabular)\n",
    "    import pandas as pd\n",
    "    \n",
    "    # converter lista de dicion√°rios para DataFrame\n",
    "    df_relatorio = pd.DataFrame(relatorio_colunas)\n",
    "    \n",
    "    # reorganizar colunas para melhor visualiza√ß√£o\n",
    "    colunas_principais = ['coluna', 'posicao', 'status', 'tipo_coluna', 'tipo_df1', 'tipo_df2', \n",
    "                         'valores_unicos_df1', 'valores_unicos_df2', 'nulos_df1', 'nulos_df2']\n",
    "    \n",
    "    # garantir que as colunas principais existam\n",
    "    colunas_ordenadas = [col for col in colunas_principais if col in df_relatorio.columns]\n",
    "    colunas_restantes = [col for col in df_relatorio.columns if col not in colunas_ordenadas]\n",
    "    colunas_finais = colunas_ordenadas + colunas_restantes\n",
    "    \n",
    "    df_relatorio_ordenado = df_relatorio[colunas_finais]\n",
    "    \n",
    "    # salvar CSV\n",
    "    caminho_csv = os.path.join(pasta_saida, f\"{nome_base}.csv\")\n",
    "    df_relatorio_ordenado.to_csv(caminho_csv, index=False, encoding='utf-8-sig')\n",
    "    print(f\"‚úÖ CSV salvo: {caminho_csv}\")\n",
    "    \n",
    "    # 2. SALVAR COMO EXCEL com m√∫ltiplas abas\n",
    "    caminho_excel = os.path.join(pasta_saida, f\"{nome_base}.xlsx\")\n",
    "    \n",
    "    with pd.ExcelWriter(caminho_excel, engine='openpyxl') as writer:\n",
    "        # Aba 1: Relat√≥rio completo\n",
    "        df_relatorio_ordenado.to_excel(writer, sheet_name='Relat√≥rio Completo', index=False)\n",
    "        \n",
    "        # Aba 2: Apenas problemas\n",
    "        df_problemas = df_relatorio_ordenado[df_relatorio_ordenado['status'] == 'COM_PROBLEMAS']\n",
    "        if not df_problemas.empty:\n",
    "            df_problemas.to_excel(writer, sheet_name='Colunas com Problemas', index=False)\n",
    "        \n",
    "        # Aba 3: Resumo estat√≠stico\n",
    "        resumo_stats = {\n",
    "            'M√©trica': [\n",
    "                'Total de Colunas',\n",
    "                'Colunas OK',\n",
    "                'Colunas com Problemas',\n",
    "                'Taxa de Sucesso (%)',\n",
    "                'Colunas Num√©ricas',\n",
    "                'Colunas de Texto',\n",
    "                'Colunas de Data',\n",
    "                'Outros Tipos'\n",
    "            ],\n",
    "            'Valor': [\n",
    "                len(relatorio_colunas),\n",
    "                len([r for r in relatorio_colunas if r['status'] == 'OK']),\n",
    "                len([r for r in relatorio_colunas if r['status'] == 'COM_PROBLEMAS']),\n",
    "                len([r for r in relatorio_colunas if r['status'] == 'OK']) / len(relatorio_colunas) * 100,\n",
    "                len([r for r in relatorio_colunas if r.get('tipo_coluna') == 'numerica']),\n",
    "                len([r for r in relatorio_colunas if r.get('tipo_coluna') == 'texto']),\n",
    "                len([r for r in relatorio_colunas if r.get('tipo_coluna') == 'data']),\n",
    "                len([r for r in relatorio_colunas if r.get('tipo_coluna') == 'outro'])\n",
    "            ]\n",
    "        }\n",
    "        df_resumo = pd.DataFrame(resumo_stats)\n",
    "        df_resumo.to_excel(writer, sheet_name='Resumo Estat√≠stico', index=False)\n",
    "    \n",
    "    print(f\"‚úÖ Excel salvo: {caminho_excel}\")\n",
    "    \n",
    "    # 3. SALVAR COMO JSON (formato estruturado)\n",
    "    import json\n",
    "    caminho_json = os.path.join(pasta_saida, f\"{nome_base}.json\")\n",
    "    \n",
    "    # preparar dados para JSON (converter tipos numpy para tipos Python)\n",
    "    dados_json = []\n",
    "    for item in relatorio_colunas:\n",
    "        item_limpo = {}\n",
    "        for chave, valor in item.items():\n",
    "            # converter tipos especiais para tipos serializ√°veis\n",
    "            if pd.isna(valor):\n",
    "                item_limpo[chave] = None\n",
    "            elif hasattr(valor, 'item'):  # numpy types\n",
    "                item_limpo[chave] = valor.item()\n",
    "            elif isinstance(valor, (list, set)):\n",
    "                item_limpo[chave] = list(valor)\n",
    "            else:\n",
    "                item_limpo[chave] = valor\n",
    "        dados_json.append(item_limpo)\n",
    "    \n",
    "    with open(caminho_json, 'w', encoding='utf-8') as f:\n",
    "        json.dump({\n",
    "            'metadados': {\n",
    "                'data_criacao': datetime.now().isoformat(),\n",
    "                'total_colunas': len(relatorio_colunas),\n",
    "                'arquivo_origem': globals().get('nome_arquivo1', 'N/A'),\n",
    "                'arquivo_comparacao': globals().get('nome_arquivo2', 'N/A')\n",
    "            },\n",
    "            'relatorio': dados_json\n",
    "        }, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"‚úÖ JSON salvo: {caminho_json}\")\n",
    "    \n",
    "    # 4. SALVAR RELAT√ìRIO DE TEXTO RESUMIDO\n",
    "    caminho_txt = os.path.join(pasta_saida, f\"{nome_base}_resumo.txt\")\n",
    "    \n",
    "    with open(caminho_txt, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"RELAT√ìRIO DE COMPARA√á√ÉO DE COLUNAS\\n\")\n",
    "        f.write(\"=\"*50 + \"\\n\\n\")\n",
    "        f.write(f\"Data: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\\n\")\n",
    "        f.write(f\"Arquivo 1: {globals().get('nome_arquivo1', 'N/A')}\\n\")\n",
    "        f.write(f\"Arquivo 2: {globals().get('nome_arquivo2', 'N/A')}\\n\\n\")\n",
    "        \n",
    "        # estat√≠sticas gerais\n",
    "        total = len(relatorio_colunas)\n",
    "        ok = len([r for r in relatorio_colunas if r['status'] == 'OK'])\n",
    "        problemas = total - ok\n",
    "        \n",
    "        f.write(\"RESUMO GERAL:\\n\")\n",
    "        f.write(f\"  Total de colunas analisadas: {total}\\n\")\n",
    "        f.write(f\"  Colunas sem problemas: {ok} ({ok/total*100:.1f}%)\\n\")\n",
    "        f.write(f\"  Colunas com problemas: {problemas} ({problemas/total*100:.1f}%)\\n\\n\")\n",
    "        \n",
    "        # listar problemas\n",
    "        if problemas > 0:\n",
    "            f.write(\"COLUNAS COM PROBLEMAS:\\n\")\n",
    "            for i, item in enumerate(relatorio_colunas, 1):\n",
    "                if item['status'] == 'COM_PROBLEMAS':\n",
    "                    f.write(f\"  {i}. {item['coluna']}:\\n\")\n",
    "                    for problema in item.get('problemas', []):\n",
    "                        f.write(f\"     - {problema}\\n\")\n",
    "                    f.write(\"\\n\")\n",
    "    \n",
    "    print(f\"‚úÖ Resumo TXT salvo: {caminho_txt}\")\n",
    "    \n",
    "    print(f\"\\nüìÅ ARQUIVOS GERADOS:\")\n",
    "    print(f\"   üìä CSV: {os.path.basename(caminho_csv)}\")\n",
    "    print(f\"   üìà Excel: {os.path.basename(caminho_excel)}\")\n",
    "    print(f\"   üóÇÔ∏è JSON: {os.path.basename(caminho_json)}\")\n",
    "    print(f\"   üìù Resumo: {os.path.basename(caminho_txt)}\")\n",
    "    \n",
    "    print(f\"\\nüìÇ Localiza√ß√£o: {pasta_saida}\")\n",
    "    \n",
    "    # salvar caminhos para uso posterior\n",
    "    caminhos_relatorio = {\n",
    "        'csv': caminho_csv,\n",
    "        'excel': caminho_excel,\n",
    "        'json': caminho_json,\n",
    "        'txt': caminho_txt,\n",
    "        'pasta': pasta_saida\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nüíæ Caminhos salvos na vari√°vel 'caminhos_relatorio'\")\n",
    "    \n",
    "except NameError:\n",
    "    print(\"‚ùå Vari√°vel 'relatorio_colunas' n√£o encontrada.\")\n",
    "    print(\"üí° Execute primeiro a c√©lula de an√°lise detalhada das colunas.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro ao salvar relat√≥rio: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4977ca16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß COMPLETANDO EXPORTA√á√ÉO - JSON E TXT\n",
      "========================================\n",
      "‚úÖ Usando pasta: G:/PROJETOS PYTHON/aeronautas_azul/AERONAUTAS/ARQUIVOS TRABALHADOS/RICARDO LAZZARINI\n",
      "‚úÖ Nome base: relatorio_comparacao_colunas_20250704_182137\n",
      "‚úÖ JSON salvo: G:/PROJETOS PYTHON/aeronautas_azul/AERONAUTAS/ARQUIVOS TRABALHADOS/RICARDO LAZZARINI\\relatorio_comparacao_colunas_20250704_182137.json\n",
      "‚úÖ Resumo TXT salvo: G:/PROJETOS PYTHON/aeronautas_azul/AERONAUTAS/ARQUIVOS TRABALHADOS/RICARDO LAZZARINI\\relatorio_comparacao_colunas_20250704_182137_resumo.txt\n",
      "\n",
      "üìÅ TODOS OS ARQUIVOS GERADOS:\n",
      "   üìä CSV: relatorio_comparacao_colunas_20250704_182137.csv\n",
      "   üìà Excel: relatorio_comparacao_colunas_20250704_182137.xlsx\n",
      "   üóÇÔ∏è JSON: relatorio_comparacao_colunas_20250704_182137.json\n",
      "   üìù Resumo: relatorio_comparacao_colunas_20250704_182137_resumo.txt\n",
      "\n",
      "üìÇ LOCALIZA√á√ÉO COMPLETA:\n",
      "   G:/PROJETOS PYTHON/aeronautas_azul/AERONAUTAS/ARQUIVOS TRABALHADOS/RICARDO LAZZARINI\n",
      "\n",
      "üíæ Todos os caminhos salvos na vari√°vel 'caminhos_relatorio'\n",
      "üéâ EXPORTA√á√ÉO CONCLU√çDA COM SUCESSO!\n"
     ]
    }
   ],
   "source": [
    "# COMPLETAR SALVAMENTO - JSON E TXT (com corre√ß√£o)\n",
    "print(\"üîß COMPLETANDO EXPORTA√á√ÉO - JSON E TXT\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "try:\n",
    "    # verificar se j√° temos os caminhos\n",
    "    if 'pasta_saida' in locals() and 'nome_base' in locals():\n",
    "        print(f\"‚úÖ Usando pasta: {pasta_saida}\")\n",
    "        print(f\"‚úÖ Nome base: {nome_base}\")\n",
    "    else:\n",
    "        # redefinir se necess√°rio\n",
    "        import os\n",
    "        from datetime import datetime\n",
    "        pasta_saida = diretorio if 'diretorio' in locals() and diretorio else os.getcwd()\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        nome_base = f\"relatorio_comparacao_colunas_{timestamp}\"\n",
    "    \n",
    "    # 3. SALVAR COMO JSON (formato estruturado) - VERS√ÉO CORRIGIDA\n",
    "    import json\n",
    "    caminho_json = os.path.join(pasta_saida, f\"{nome_base}.json\")\n",
    "    \n",
    "    # fun√ß√£o auxiliar para converter valores para JSON\n",
    "    def converter_para_json(valor):\n",
    "        if valor is None:\n",
    "            return None\n",
    "        elif isinstance(valor, (int, float, str, bool)):\n",
    "            return valor\n",
    "        elif isinstance(valor, (list, tuple)):\n",
    "            return [converter_para_json(v) for v in valor]\n",
    "        elif isinstance(valor, set):\n",
    "            return list(valor)\n",
    "        elif hasattr(valor, 'item'):  # numpy types\n",
    "            return valor.item()\n",
    "        elif hasattr(valor, 'tolist'):  # numpy arrays\n",
    "            return valor.tolist()\n",
    "        else:\n",
    "            return str(valor)\n",
    "    \n",
    "    # preparar dados para JSON\n",
    "    dados_json = []\n",
    "    for item in relatorio_colunas:\n",
    "        item_limpo = {}\n",
    "        for chave, valor in item.items():\n",
    "            try:\n",
    "                item_limpo[chave] = converter_para_json(valor)\n",
    "            except:\n",
    "                item_limpo[chave] = str(valor)  # fallback para string\n",
    "        dados_json.append(item_limpo)\n",
    "    \n",
    "    with open(caminho_json, 'w', encoding='utf-8') as f:\n",
    "        json.dump({\n",
    "            'metadados': {\n",
    "                'data_criacao': datetime.now().isoformat(),\n",
    "                'total_colunas': len(relatorio_colunas),\n",
    "                'arquivo_origem': globals().get('nome_arquivo1', 'N/A'),\n",
    "                'arquivo_comparacao': globals().get('nome_arquivo2', 'N/A')\n",
    "            },\n",
    "            'relatorio': dados_json\n",
    "        }, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"‚úÖ JSON salvo: {caminho_json}\")\n",
    "    \n",
    "    # 4. SALVAR RELAT√ìRIO DE TEXTO RESUMIDO\n",
    "    caminho_txt = os.path.join(pasta_saida, f\"{nome_base}_resumo.txt\")\n",
    "    \n",
    "    with open(caminho_txt, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"RELAT√ìRIO DE COMPARA√á√ÉO DE COLUNAS\\n\")\n",
    "        f.write(\"=\"*50 + \"\\n\\n\")\n",
    "        f.write(f\"Data: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\\n\")\n",
    "        f.write(f\"Arquivo 1: {globals().get('nome_arquivo1', 'N/A')}\\n\")\n",
    "        f.write(f\"Arquivo 2: {globals().get('nome_arquivo2', 'N/A')}\\n\\n\")\n",
    "        \n",
    "        # estat√≠sticas gerais\n",
    "        total = len(relatorio_colunas)\n",
    "        ok = len([r for r in relatorio_colunas if r['status'] == 'OK'])\n",
    "        problemas = total - ok\n",
    "        \n",
    "        f.write(\"RESUMO GERAL:\\n\")\n",
    "        f.write(f\"  Total de colunas analisadas: {total}\\n\")\n",
    "        f.write(f\"  Colunas sem problemas: {ok} ({ok/total*100:.1f}%)\\n\")\n",
    "        f.write(f\"  Colunas com problemas: {problemas} ({problemas/total*100:.1f}%)\\n\\n\")\n",
    "        \n",
    "        # listar problemas\n",
    "        if problemas > 0:\n",
    "            f.write(\"COLUNAS COM PROBLEMAS:\\n\")\n",
    "            for i, item in enumerate(relatorio_colunas, 1):\n",
    "                if item['status'] == 'COM_PROBLEMAS':\n",
    "                    f.write(f\"  {i}. {item['coluna']}:\\n\")\n",
    "                    for problema in item.get('problemas', []):\n",
    "                        f.write(f\"     - {problema}\\n\")\n",
    "                    f.write(\"\\n\")\n",
    "        \n",
    "        # adicionar detalhes por tipo de coluna\n",
    "        tipos_resumo = {}\n",
    "        for item in relatorio_colunas:\n",
    "            tipo = item.get('tipo_coluna', 'outro')\n",
    "            if tipo not in tipos_resumo:\n",
    "                tipos_resumo[tipo] = 0\n",
    "            tipos_resumo[tipo] += 1\n",
    "        \n",
    "        f.write(\"DISTRIBUI√á√ÉO POR TIPO:\\n\")\n",
    "        for tipo, count in tipos_resumo.items():\n",
    "            f.write(f\"  {tipo.title()}: {count} colunas\\n\")\n",
    "    \n",
    "    print(f\"‚úÖ Resumo TXT salvo: {caminho_txt}\")\n",
    "    \n",
    "    # atualizar caminhos completos\n",
    "    caminhos_relatorio = {\n",
    "        'csv': os.path.join(pasta_saida, f\"{nome_base}.csv\"),\n",
    "        'excel': os.path.join(pasta_saida, f\"{nome_base}.xlsx\"),\n",
    "        'json': caminho_json,\n",
    "        'txt': caminho_txt,\n",
    "        'pasta': pasta_saida\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nüìÅ TODOS OS ARQUIVOS GERADOS:\")\n",
    "    print(f\"   üìä CSV: {os.path.basename(caminhos_relatorio['csv'])}\")\n",
    "    print(f\"   üìà Excel: {os.path.basename(caminhos_relatorio['excel'])}\")\n",
    "    print(f\"   üóÇÔ∏è JSON: {os.path.basename(caminhos_relatorio['json'])}\")\n",
    "    print(f\"   üìù Resumo: {os.path.basename(caminhos_relatorio['txt'])}\")\n",
    "    \n",
    "    print(f\"\\nüìÇ LOCALIZA√á√ÉO COMPLETA:\")\n",
    "    print(f\"   {pasta_saida}\")\n",
    "    \n",
    "    print(f\"\\nüíæ Todos os caminhos salvos na vari√°vel 'caminhos_relatorio'\")\n",
    "    print(f\"üéâ EXPORTA√á√ÉO CONCLU√çDA COM SUCESSO!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "671e17bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ CAMINHOS COMPLETOS DOS ARQUIVOS GERADOS:\n",
      "============================================================\n",
      "üìÑ CSV: G:/PROJETOS PYTHON/aeronautas_azul/AERONAUTAS/ARQUIVOS TRABALHADOS/RICARDO LAZZARINI\\relatorio_comparacao_colunas_20250704_182137.csv\n",
      "üìÑ EXCEL: G:/PROJETOS PYTHON/aeronautas_azul/AERONAUTAS/ARQUIVOS TRABALHADOS/RICARDO LAZZARINI\\relatorio_comparacao_colunas_20250704_182137.xlsx\n",
      "üìÑ JSON: G:/PROJETOS PYTHON/aeronautas_azul/AERONAUTAS/ARQUIVOS TRABALHADOS/RICARDO LAZZARINI\\relatorio_comparacao_colunas_20250704_182137.json\n",
      "üìÑ TXT: G:/PROJETOS PYTHON/aeronautas_azul/AERONAUTAS/ARQUIVOS TRABALHADOS/RICARDO LAZZARINI\\relatorio_comparacao_colunas_20250704_182137_resumo.txt\n",
      "\n",
      "üìÇ PASTA: G:/PROJETOS PYTHON/aeronautas_azul/AERONAUTAS/ARQUIVOS TRABALHADOS/RICARDO LAZZARINI\n",
      "\n",
      "‚úÖ VERIFICA√á√ÉO DE ARQUIVOS:\n",
      "   CSV: ‚úÖ Existe (2,211 bytes)\n",
      "   EXCEL: ‚úÖ Existe (8,467 bytes)\n",
      "   JSON: ‚úÖ Existe (9,425 bytes)\n",
      "   TXT: ‚úÖ Existe (1,294 bytes)\n"
     ]
    }
   ],
   "source": [
    "# EXIBIR CAMINHOS DOS ARQUIVOS DO RELAT√ìRIO\n",
    "print(\"üìÅ CAMINHOS COMPLETOS DOS ARQUIVOS GERADOS:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    if 'caminhos_relatorio' in locals():\n",
    "        for tipo, caminho in caminhos_relatorio.items():\n",
    "            if tipo != 'pasta':\n",
    "                print(f\"üìÑ {tipo.upper()}: {caminho}\")\n",
    "        \n",
    "        print(f\"\\nüìÇ PASTA: {caminhos_relatorio['pasta']}\")\n",
    "        \n",
    "        # verificar se os arquivos existem\n",
    "        import os\n",
    "        print(f\"\\n‚úÖ VERIFICA√á√ÉO DE ARQUIVOS:\")\n",
    "        for tipo, caminho in caminhos_relatorio.items():\n",
    "            if tipo != 'pasta' and os.path.exists(caminho):\n",
    "                tamanho = os.path.getsize(caminho)\n",
    "                print(f\"   {tipo.upper()}: ‚úÖ Existe ({tamanho:,} bytes)\")\n",
    "            elif tipo != 'pasta':\n",
    "                print(f\"   {tipo.upper()}: ‚ùå N√£o encontrado\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Vari√°vel 'caminhos_relatorio' n√£o encontrada.\")\n",
    "        print(\"üí° Execute primeiro as c√©lulas de salvamento do relat√≥rio.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8744c1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ IMPORTA√á√ÉO DE ARQUIVOS JSON E EXCEL\n",
      "==================================================\n",
      "üóÇÔ∏è Selecionando diret√≥rio do relat√≥rio...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Diret√≥rio selecionado: G:/PROJETOS PYTHON/aeronautas_azul/AERONAUTAS/ARQUIVOS TRABALHADOS/RICARDO LAZZARINI\n",
      "\n",
      "üìÑ Selecionando arquivos JSON e Excel...\n",
      "‚úÖ 2 arquivo(s) selecionado(s)!\n",
      "   1. G:/PROJETOS PYTHON/aeronautas_azul/AERONAUTAS/ARQUIVOS TRABALHADOS/RICARDO LAZZARINI/relatorio_comparacao_colunas_20250704_182137.json (JSON)\n",
      "   2. G:/PROJETOS PYTHON/aeronautas_azul/AERONAUTAS/ARQUIVOS TRABALHADOS/RICARDO LAZZARINI/relatorio_comparacao_colunas_20250704_182137.xlsx (XLSX)\n",
      "\n",
      "üìä Resumo dos arquivos:\n",
      "   üóÇÔ∏è JSON: 1 arquivo(s)\n",
      "   üìà Excel: 1 arquivo(s)\n",
      "\n",
      "üîç IMPORTANDO ARQUIVOS JSON...\n",
      "   üìÑ Carregando: G:/PROJETOS PYTHON/aeronautas_azul/AERONAUTAS/ARQUIVOS TRABALHADOS/RICARDO LAZZARINI/relatorio_comparacao_colunas_20250704_182137.json\n",
      "      ‚úÖ Carregado com sucesso\n",
      "      üìä Metadados: 4 itens\n",
      "      üìã Relat√≥rio: 12 colunas\n",
      "      üìÖ Data cria√ß√£o: 2025-07-04T18:21:37.964467\n",
      "      üìÅ Arquivo origem: G:/PROJETOS PYTHON/aeronautas_azul/AERONAUTAS/ARQUIVOS TRABALHADOS/RICARDO LAZZARINI/escala_e_ricardo_lazzarini_vcp_3394_112017_022023_COM_SUFIXO.csv\n",
      "      üìÅ Arquivo compara√ß√£o: G:/PROJETOS PYTHON/aeronautas_azul/AERONAUTAS/ARQUIVOS TRABALHADOS/RICARDO LAZZARINI/escala_e_ricardo_lazzarini_vcp_3394_112017_022023_COM_SUFIXO.csv) - CALCULOS_EM_TIMEDELTA.csv\n",
      "   üéâ 1 arquivo(s) JSON importado(s) com sucesso!\n",
      "   üíæ Dados salvos na vari√°vel 'dados_json_importados'\n",
      "\n",
      "üìä IMPORTANDO ARQUIVOS EXCEL...\n",
      "   üìÑ Carregando: G:/PROJETOS PYTHON/aeronautas_azul/AERONAUTAS/ARQUIVOS TRABALHADOS/RICARDO LAZZARINI/relatorio_comparacao_colunas_20250704_182137.xlsx\n",
      "      ‚úÖ Carregado com sucesso\n",
      "      üìä Abas encontradas: 3\n",
      "         üìã Relat√≥rio Completo: 12 linhas x 22 colunas\n",
      "         üìã Colunas com Problemas: 5 linhas x 22 colunas\n",
      "         üìã Resumo Estat√≠stico: 8 linhas x 2 colunas\n",
      "   üéâ 1 arquivo(s) Excel importado(s) com sucesso!\n",
      "   üíæ Dados salvos na vari√°vel 'dados_excel_importados'\n",
      "\n",
      "üéØ RESUMO DA IMPORTA√á√ÉO:\n",
      "   üìÇ Diret√≥rio: G:/PROJETOS PYTHON/aeronautas_azul/AERONAUTAS/ARQUIVOS TRABALHADOS/RICARDO LAZZARINI\n",
      "   üìÑ Total de arquivos: 2\n",
      "   üóÇÔ∏è JSON importados: 1\n",
      "      ‚Ä¢ G:/PROJETOS PYTHON/aeronautas_azul/AERONAUTAS/ARQUIVOS TRABALHADOS/RICARDO LAZZARINI/relatorio_comparacao_colunas_20250704_182137.json\n",
      "   üìà Excel importados: 1\n",
      "      ‚Ä¢ G:/PROJETOS PYTHON/aeronautas_azul/AERONAUTAS/ARQUIVOS TRABALHADOS/RICARDO LAZZARINI/relatorio_comparacao_colunas_20250704_182137.xlsx\n",
      "\n",
      "‚úÖ IMPORTA√á√ÉO CONCLU√çDA!\n",
      "üíæ Informa√ß√µes completas salvas na vari√°vel 'info_importacao'\n"
     ]
    }
   ],
   "source": [
    "# IMPORTAR ARQUIVOS JSON E EXCEL DO RELAT√ìRIO\n",
    "print(\"üìÇ IMPORTA√á√ÉO DE ARQUIVOS JSON E EXCEL\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# fun√ß√£o para escolher diret√≥rio\n",
    "def escolher_diretorio_relatorio():\n",
    "    from tkinter import Tk\n",
    "    from tkinter.filedialog import askdirectory\n",
    "    \n",
    "    # criar uma janela oculta\n",
    "    Tk().withdraw()\n",
    "    # abrir o di√°logo para escolher o diret√≥rio\n",
    "    diretorio = askdirectory(title=\"Escolha o diret√≥rio onde est√£o os arquivos do relat√≥rio\")\n",
    "    return diretorio\n",
    "\n",
    "# fun√ß√£o para escolher arquivos JSON e Excel\n",
    "def escolher_arquivos_relatorio():\n",
    "    from tkinter import Tk\n",
    "    from tkinter.filedialog import askopenfilenames\n",
    "    \n",
    "    # criar uma janela oculta\n",
    "    Tk().withdraw()\n",
    "    # abrir o di√°logo para escolher os arquivos\n",
    "    arquivos = askopenfilenames(\n",
    "        title=\"Escolha os arquivos JSON e Excel do relat√≥rio\",\n",
    "        filetypes=[\n",
    "            (\"Arquivos de Relat√≥rio\", \"*.json;*.xlsx\"),\n",
    "            (\"JSON files\", \"*.json\"),\n",
    "            (\"Excel files\", \"*.xlsx\"),\n",
    "            (\"Todos os arquivos\", \"*.*\")\n",
    "        ]\n",
    "    )\n",
    "    return arquivos if arquivos else None\n",
    "\n",
    "# escolher diret√≥rio do relat√≥rio\n",
    "print(\"üóÇÔ∏è Selecionando diret√≥rio do relat√≥rio...\")\n",
    "diretorio_relatorio = escolher_diretorio_relatorio()\n",
    "\n",
    "if diretorio_relatorio:\n",
    "    print(f\"‚úÖ Diret√≥rio selecionado: {diretorio_relatorio}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Nenhum diret√≥rio foi selecionado\")\n",
    "\n",
    "# escolher arquivos JSON e Excel\n",
    "print(\"\\nüìÑ Selecionando arquivos JSON e Excel...\")\n",
    "arquivos_relatorio = escolher_arquivos_relatorio()\n",
    "\n",
    "if arquivos_relatorio is None or len(arquivos_relatorio) == 0:\n",
    "    print(\"‚ùå Nenhum arquivo foi selecionado.\")\n",
    "    print(\"üí° Dica: Selecione pelo menos um arquivo JSON ou Excel\")\n",
    "else:\n",
    "    print(f\"‚úÖ {len(arquivos_relatorio)} arquivo(s) selecionado(s)!\")\n",
    "    \n",
    "    # mostrar os arquivos selecionados\n",
    "    for i, arquivo in enumerate(arquivos_relatorio, 1):\n",
    "        nome_arquivo = arquivo.split('\\\\')[-1]\n",
    "        extensao = nome_arquivo.split('.')[-1].lower()\n",
    "        print(f\"   {i}. {nome_arquivo} ({extensao.upper()})\")\n",
    "    \n",
    "    # separar arquivos por tipo\n",
    "    arquivos_json = [arq for arq in arquivos_relatorio if arq.lower().endswith('.json')]\n",
    "    arquivos_excel = [arq for arq in arquivos_relatorio if arq.lower().endswith('.xlsx')]\n",
    "    \n",
    "    print(f\"\\nüìä Resumo dos arquivos:\")\n",
    "    print(f\"   üóÇÔ∏è JSON: {len(arquivos_json)} arquivo(s)\")\n",
    "    print(f\"   üìà Excel: {len(arquivos_excel)} arquivo(s)\")\n",
    "    \n",
    "    # IMPORTAR ARQUIVOS JSON\n",
    "    if arquivos_json:\n",
    "        print(f\"\\nüîç IMPORTANDO ARQUIVOS JSON...\")\n",
    "        import json\n",
    "        \n",
    "        dados_json_importados = {}\n",
    "        \n",
    "        for arquivo_json in arquivos_json:\n",
    "            try:\n",
    "                nome_arquivo = arquivo_json.split('\\\\')[-1]\n",
    "                print(f\"   üìÑ Carregando: {nome_arquivo}\")\n",
    "                \n",
    "                with open(arquivo_json, 'r', encoding='utf-8') as f:\n",
    "                    dados = json.load(f)\n",
    "                \n",
    "                dados_json_importados[nome_arquivo] = dados\n",
    "                \n",
    "                # mostrar informa√ß√µes b√°sicas\n",
    "                metadados = dados.get('metadados', {})\n",
    "                relatorio = dados.get('relatorio', [])\n",
    "                \n",
    "                print(f\"      ‚úÖ Carregado com sucesso\")\n",
    "                print(f\"      üìä Metadados: {len(metadados)} itens\")\n",
    "                print(f\"      üìã Relat√≥rio: {len(relatorio)} colunas\")\n",
    "                \n",
    "                if metadados:\n",
    "                    print(f\"      üìÖ Data cria√ß√£o: {metadados.get('data_criacao', 'N/A')}\")\n",
    "                    print(f\"      üìÅ Arquivo origem: {metadados.get('arquivo_origem', 'N/A')}\")\n",
    "                    print(f\"      üìÅ Arquivo compara√ß√£o: {metadados.get('arquivo_comparacao', 'N/A')}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"      ‚ùå Erro ao carregar {nome_arquivo}: {e}\")\n",
    "        \n",
    "        print(f\"   üéâ {len(dados_json_importados)} arquivo(s) JSON importado(s) com sucesso!\")\n",
    "        print(f\"   üíæ Dados salvos na vari√°vel 'dados_json_importados'\")\n",
    "    \n",
    "    # IMPORTAR ARQUIVOS EXCEL\n",
    "    if arquivos_excel:\n",
    "        print(f\"\\nüìä IMPORTANDO ARQUIVOS EXCEL...\")\n",
    "        import pandas as pd\n",
    "        \n",
    "        dados_excel_importados = {}\n",
    "        \n",
    "        for arquivo_excel in arquivos_excel:\n",
    "            try:\n",
    "                nome_arquivo = arquivo_excel.split('\\\\')[-1]\n",
    "                print(f\"   üìÑ Carregando: {nome_arquivo}\")\n",
    "                \n",
    "                # ler todas as abas do Excel\n",
    "                excel_data = pd.read_excel(arquivo_excel, sheet_name=None)\n",
    "                dados_excel_importados[nome_arquivo] = excel_data\n",
    "                \n",
    "                print(f\"      ‚úÖ Carregado com sucesso\")\n",
    "                print(f\"      üìä Abas encontradas: {len(excel_data)}\")\n",
    "                \n",
    "                # mostrar informa√ß√µes de cada aba\n",
    "                for nome_aba, df_aba in excel_data.items():\n",
    "                    print(f\"         üìã {nome_aba}: {df_aba.shape[0]} linhas x {df_aba.shape[1]} colunas\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"      ‚ùå Erro ao carregar {nome_arquivo}: {e}\")\n",
    "        \n",
    "        print(f\"   üéâ {len(dados_excel_importados)} arquivo(s) Excel importado(s) com sucesso!\")\n",
    "        print(f\"   üíæ Dados salvos na vari√°vel 'dados_excel_importados'\")\n",
    "    \n",
    "    # RESUMO FINAL\n",
    "    print(f\"\\nüéØ RESUMO DA IMPORTA√á√ÉO:\")\n",
    "    print(f\"   üìÇ Diret√≥rio: {diretorio_relatorio}\")\n",
    "    print(f\"   üìÑ Total de arquivos: {len(arquivos_relatorio)}\")\n",
    "    \n",
    "    if arquivos_json:\n",
    "        print(f\"   üóÇÔ∏è JSON importados: {len(dados_json_importados)}\")\n",
    "        for nome in dados_json_importados.keys():\n",
    "            print(f\"      ‚Ä¢ {nome}\")\n",
    "    \n",
    "    if arquivos_excel:\n",
    "        print(f\"   üìà Excel importados: {len(dados_excel_importados)}\")\n",
    "        for nome in dados_excel_importados.keys():\n",
    "            print(f\"      ‚Ä¢ {nome}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ IMPORTA√á√ÉO CONCLU√çDA!\")\n",
    "    \n",
    "    # salvar informa√ß√µes dos arquivos importados\n",
    "    info_importacao = {\n",
    "        'diretorio': diretorio_relatorio,\n",
    "        'arquivos_selecionados': arquivos_relatorio,\n",
    "        'arquivos_json': arquivos_json,\n",
    "        'arquivos_excel': arquivos_excel,\n",
    "        'dados_json': dados_json_importados if arquivos_json else {},\n",
    "        'dados_excel': dados_excel_importados if arquivos_excel else {}\n",
    "    }\n",
    "    \n",
    "    print(f\"üíæ Informa√ß√µes completas salvas na vari√°vel 'info_importacao'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "80d62470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ IMPORTA√á√ÉO DE RELAT√ìRIOS\n",
      "========================================\n",
      "üîç Selecionando arquivos...\n",
      "‚úÖ 1 arquivo(s) selecionado(s)\n",
      "\n",
      "üìÑ Processando: relatorio_comparacao_colunas_20250704_182137.xlsx\n",
      "   ‚úÖ Excel carregado - 3 aba(s): ['Relat√≥rio Completo', 'Colunas com Problemas', 'Resumo Estat√≠stico']\n",
      "\n",
      "üìä RESUMO:\n",
      "   üìÅ Arquivos processados: 1\n",
      "   üóÇÔ∏è JSON: 0\n",
      "   üìä Excel: 1\n",
      "      ‚Ä¢ relatorio_comparacao_colunas_20250704_182137.xlsx: 3 abas\n",
      "\n",
      "üíæ Dados salvos na vari√°vel 'dados_importados'\n",
      "‚úÖ Importa√ß√£o conclu√≠da!\n"
     ]
    }
   ],
   "source": [
    "# IMPORTA√á√ÉO SIMPLES - JSON E EXCEL\n",
    "print(\"üìÅ IMPORTA√á√ÉO DE RELAT√ìRIOS\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from tkinter import Tk, filedialog\n",
    "\n",
    "# fun√ß√£o simples para selecionar arquivos\n",
    "def selecionar_arquivos():\n",
    "    root = Tk()\n",
    "    root.withdraw()  # esconder janela principal\n",
    "    \n",
    "    arquivos = filedialog.askopenfilenames(\n",
    "        title=\"Selecione os arquivos JSON e/ou Excel\",\n",
    "        filetypes=[\n",
    "            (\"Arquivos do Relat√≥rio\", \"*.json *.xlsx\"),\n",
    "            (\"JSON\", \"*.json\"),\n",
    "            (\"Excel\", \"*.xlsx\"),\n",
    "            (\"Todos\", \"*.*\")\n",
    "        ]\n",
    "    )\n",
    "    root.destroy()\n",
    "    return arquivos\n",
    "\n",
    "# selecionar arquivos\n",
    "print(\"üîç Selecionando arquivos...\")\n",
    "arquivos_selecionados = selecionar_arquivos()\n",
    "\n",
    "if not arquivos_selecionados:\n",
    "    print(\"‚ùå Nenhum arquivo selecionado!\")\n",
    "else:\n",
    "    print(f\"‚úÖ {len(arquivos_selecionados)} arquivo(s) selecionado(s)\")\n",
    "    \n",
    "    # processar cada arquivo\n",
    "    dados_importados = {}\n",
    "    \n",
    "    for arquivo in arquivos_selecionados:\n",
    "        nome = os.path.basename(arquivo)\n",
    "        extensao = os.path.splitext(nome)[1].lower()\n",
    "        \n",
    "        print(f\"\\nüìÑ Processando: {nome}\")\n",
    "        \n",
    "        try:\n",
    "            if extensao == '.json':\n",
    "                # carregar JSON\n",
    "                with open(arquivo, 'r', encoding='utf-8') as f:\n",
    "                    dados = json.load(f)\n",
    "                dados_importados[nome] = {\n",
    "                    'tipo': 'json',\n",
    "                    'dados': dados,\n",
    "                    'metadados': dados.get('metadados', {}),\n",
    "                    'relatorio': dados.get('relatorio', [])\n",
    "                }\n",
    "                print(f\"   ‚úÖ JSON carregado - {len(dados.get('relatorio', []))} registros\")\n",
    "                \n",
    "            elif extensao == '.xlsx':\n",
    "                # carregar Excel\n",
    "                dados = pd.read_excel(arquivo, sheet_name=None)\n",
    "                dados_importados[nome] = {\n",
    "                    'tipo': 'excel',\n",
    "                    'dados': dados,\n",
    "                    'abas': list(dados.keys())\n",
    "                }\n",
    "                print(f\"   ‚úÖ Excel carregado - {len(dados)} aba(s): {list(dados.keys())}\")\n",
    "                \n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è Formato n√£o suportado: {extensao}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Erro ao carregar: {e}\")\n",
    "    \n",
    "    # resumo final\n",
    "    print(f\"\\nüìä RESUMO:\")\n",
    "    print(f\"   üìÅ Arquivos processados: {len(dados_importados)}\")\n",
    "    \n",
    "    json_count = sum(1 for d in dados_importados.values() if d['tipo'] == 'json')\n",
    "    excel_count = sum(1 for d in dados_importados.values() if d['tipo'] == 'excel')\n",
    "    \n",
    "    print(f\"   üóÇÔ∏è JSON: {json_count}\")\n",
    "    print(f\"   üìä Excel: {excel_count}\")\n",
    "    \n",
    "    # listar arquivos carregados\n",
    "    for nome, dados in dados_importados.items():\n",
    "        if dados['tipo'] == 'json':\n",
    "            registros = len(dados['relatorio'])\n",
    "            print(f\"      ‚Ä¢ {nome}: {registros} registros\")\n",
    "        else:\n",
    "            abas = len(dados['abas'])\n",
    "            print(f\"      ‚Ä¢ {nome}: {abas} abas\")\n",
    "    \n",
    "    print(f\"\\nüíæ Dados salvos na vari√°vel 'dados_importados'\")\n",
    "    print(\"‚úÖ Importa√ß√£o conclu√≠da!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "30c99e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä RESUMO DOS DADOS IMPORTADOS\n",
      "============================================================\n",
      "üìÅ Total de arquivos importados: 1\n",
      "\n",
      "üìÑ relatorio_comparacao_colunas_20250704_182137.xlsx\n",
      "   üîπ Tipo: EXCEL\n",
      "   üîπ Abas encontradas: 3\n",
      "      üìä Relat√≥rio Completo\n",
      "      üìä Colunas com Problemas\n",
      "      üìä Resumo Estat√≠stico\n",
      "   üîπ Dados das abas:\n",
      "      üìä Relat√≥rio Completo: 12 registros, 22 colunas\n",
      "         Colunas: ['coluna', 'posicao', 'status', 'tipo_coluna', 'tipo_df1']...\n",
      "      üìä Colunas com Problemas: 5 registros, 22 colunas\n",
      "         Colunas: ['coluna', 'posicao', 'status', 'tipo_coluna', 'tipo_df1']...\n",
      "      üìä Resumo Estat√≠stico: 8 registros, 2 colunas\n",
      "         Colunas: ['M√©trica', 'Valor']\n",
      "\n",
      "üìà ESTAT√çSTICAS:\n",
      "   üóÇÔ∏è Arquivos JSON: 0\n",
      "   üìä Arquivos Excel: 1\n"
     ]
    }
   ],
   "source": [
    "# üìä RESUMO DOS DADOS IMPORTADOS\n",
    "print(\"üìä RESUMO DOS DADOS IMPORTADOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if 'dados_importados' in locals():\n",
    "    print(f\"üìÅ Total de arquivos importados: {len(dados_importados)}\")\n",
    "    \n",
    "    # Contadores\n",
    "    json_files = 0\n",
    "    excel_files = 0\n",
    "    \n",
    "    for arquivo, dados in dados_importados.items():\n",
    "        tipo = dados['tipo']\n",
    "        print(f\"\\nüìÑ {arquivo}\")\n",
    "        print(f\"   üîπ Tipo: {tipo.upper()}\")\n",
    "        \n",
    "        if tipo.lower() == 'json':\n",
    "            json_files += 1\n",
    "            print(f\"   üîπ Registros: {len(dados['dados'])}\")\n",
    "            print(f\"   üîπ Primeiros 3 registros:\")\n",
    "            for i, reg in enumerate(dados['dados'][:3]):\n",
    "                print(f\"      {i+1}. {reg}\")\n",
    "                \n",
    "        elif tipo.lower() == 'excel':\n",
    "            excel_files += 1\n",
    "            # Corrigir: 'abas' √© uma lista, n√£o um dicion√°rio\n",
    "            if isinstance(dados['abas'], list):\n",
    "                print(f\"   üîπ Abas encontradas: {len(dados['abas'])}\")\n",
    "                for aba in dados['abas']:\n",
    "                    print(f\"      üìä {aba}\")\n",
    "                    \n",
    "                # Verificar se existe dados das abas\n",
    "                if 'dados' in dados and isinstance(dados['dados'], dict):\n",
    "                    print(f\"   üîπ Dados das abas:\")\n",
    "                    for aba_nome, df in dados['dados'].items():\n",
    "                        if hasattr(df, 'shape'):  # Se √© um DataFrame\n",
    "                            print(f\"      üìä {aba_nome}: {len(df)} registros, {len(df.columns)} colunas\")\n",
    "                            if len(df) > 0:\n",
    "                                print(f\"         Colunas: {list(df.columns)[:5]}{'...' if len(df.columns) > 5 else ''}\")\n",
    "    \n",
    "    print(f\"\\nüìà ESTAT√çSTICAS:\")\n",
    "    print(f\"   üóÇÔ∏è Arquivos JSON: {json_files}\")\n",
    "    print(f\"   üìä Arquivos Excel: {excel_files}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Nenhum dado foi importado ainda.\")\n",
    "    print(\"Execute a c√©lula de importa√ß√£o acima primeiro.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "797e76a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç VERIFICA√á√ÉO DA ESTRUTURA DOS DADOS\n",
      "==================================================\n",
      "Tipo de dados_importados: <class 'dict'>\n",
      "Chaves: ['relatorio_comparacao_colunas_20250704_182137.xlsx']\n",
      "\n",
      "üìÑ relatorio_comparacao_colunas_20250704_182137.xlsx:\n",
      "   Tipo de dados: <class 'dict'>\n",
      "   Chaves: ['tipo', 'dados', 'abas']\n",
      "   Tipo registrado: excel\n",
      "   Dados diretos: <class 'dict'>\n",
      "   Abas: <class 'list'>\n",
      "\n",
      "üìä Vari√°veis relacionadas:\n",
      "   json_count: 0\n",
      "   excel_count: 1\n"
     ]
    }
   ],
   "source": [
    "# üîç VERIFICA√á√ÉO DA ESTRUTURA DOS DADOS\n",
    "print(\"üîç VERIFICA√á√ÉO DA ESTRUTURA DOS DADOS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"Tipo de dados_importados: {type(dados_importados)}\")\n",
    "print(f\"Chaves: {list(dados_importados.keys())}\")\n",
    "\n",
    "for arquivo, dados in dados_importados.items():\n",
    "    print(f\"\\nüìÑ {arquivo}:\")\n",
    "    print(f\"   Tipo de dados: {type(dados)}\")\n",
    "    print(f\"   Chaves: {list(dados.keys())}\")\n",
    "    \n",
    "    # Verificar tipo\n",
    "    print(f\"   Tipo registrado: {dados.get('tipo', 'N√£o definido')}\")\n",
    "    \n",
    "    # Verificar estrutura\n",
    "    if 'dados' in dados:\n",
    "        print(f\"   Dados diretos: {type(dados['dados'])}\")\n",
    "    if 'abas' in dados:\n",
    "        print(f\"   Abas: {type(dados['abas'])}\")\n",
    "        if isinstance(dados['abas'], dict):\n",
    "            print(f\"   Nomes das abas: {list(dados['abas'].keys())}\")\n",
    "    if 'metadados' in dados:\n",
    "        print(f\"   Metadados: {dados['metadados']}\")\n",
    "\n",
    "print(f\"\\nüìä Vari√°veis relacionadas:\")\n",
    "print(f\"   json_count: {json_count if 'json_count' in locals() else 'N√£o definido'}\")\n",
    "print(f\"   excel_count: {excel_count if 'excel_count' in locals() else 'N√£o definido'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5c56bc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç AN√ÅLISE DOS DADOS IMPORTADOS\n",
      "==================================================\n",
      "üìÑ Analisando: relatorio_comparacao_colunas_20250704_182137.xlsx\n",
      "üîπ Tipo: EXCEL\n",
      "\n",
      "üìä ABAS DISPON√çVEIS:\n",
      "\n",
      "üìã Relat√≥rio Completo:\n",
      "   üìè Dimens√µes: (12, 22)\n",
      "   üî§ Colunas: ['coluna', 'posicao', 'status', 'tipo_coluna', 'tipo_df1', 'tipo_df2', 'valores_unicos_df1', 'valores_unicos_df2', 'nulos_df1', 'nulos_df2', 'tamanho_df1', 'tamanho_df2', 'problema_tipo', 'comprimento_medio_df1', 'comprimento_medio_df2', 'valores_comuns', 'valores_so_df1', 'valores_so_df2', 'amostra_size', 'valores_iguais_amostra', 'taxa_igualdade_amostra', 'problemas']\n",
      "   üìÑ Primeiras 3 linhas:\n",
      "     coluna  posicao         status tipo_coluna tipo_df1 tipo_df2  valores_unicos_df1  valores_unicos_df2  nulos_df1  nulos_df2  tamanho_df1  tamanho_df2  problema_tipo  comprimento_medio_df1  comprimento_medio_df2  valores_comuns  valores_so_df1  valores_so_df2  amostra_size  valores_iguais_amostra  taxa_igualdade_amostra                                                                                           problemas\n",
      "0  Activity        0             OK       texto   object   object                 733                 733          0          0         2541         2541          False               4.059819               4.059819             733               0               0          1000                    1000                   100.0                                                                                                  []\n",
      "1    Id_Leg        1             OK       texto   object   object                   4                   4          0          0         2541         2541          False               2.576938               2.576938               4               0               0          1000                    1000                   100.0                                                                                                  []\n",
      "2   Checkin        2  COM_PROBLEMAS       texto   object   object                1857                1857          0          0         2541         2541          False              16.123967              19.000000             971             886             886          1000                     706                    70.6  ['886 valores √∫nicos s√≥ no DF1', '886 valores √∫nicos s√≥ no DF2', 'Taxa de igualdade baixa: 70.6%']\n",
      "\n",
      "   üîç An√°lise do Relat√≥rio Completo:\n",
      "      Status das colunas: {'OK': 7, 'COM_PROBLEMAS': 5}\n",
      "----------------------------------------\n",
      "\n",
      "üìã Colunas com Problemas:\n",
      "   üìè Dimens√µes: (5, 22)\n",
      "   üî§ Colunas: ['coluna', 'posicao', 'status', 'tipo_coluna', 'tipo_df1', 'tipo_df2', 'valores_unicos_df1', 'valores_unicos_df2', 'nulos_df1', 'nulos_df2', 'tamanho_df1', 'tamanho_df2', 'problema_tipo', 'comprimento_medio_df1', 'comprimento_medio_df2', 'valores_comuns', 'valores_so_df1', 'valores_so_df2', 'amostra_size', 'valores_iguais_amostra', 'taxa_igualdade_amostra', 'problemas']\n",
      "   üìÑ Primeiras 3 linhas:\n",
      "    coluna  posicao         status tipo_coluna tipo_df1 tipo_df2  valores_unicos_df1  valores_unicos_df2  nulos_df1  nulos_df2  tamanho_df1  tamanho_df2  problema_tipo  comprimento_medio_df1  comprimento_medio_df2  valores_comuns  valores_so_df1  valores_so_df2  amostra_size  valores_iguais_amostra  taxa_igualdade_amostra                                                                                             problemas\n",
      "0  Checkin        2  COM_PROBLEMAS       texto   object   object                1857                1857          0          0         2541         2541          False              16.123967                   19.0             971             886             886          1000                     706                    70.6    ['886 valores √∫nicos s√≥ no DF1', '886 valores √∫nicos s√≥ no DF2', 'Taxa de igualdade baixa: 70.6%']\n",
      "1    Start        3  COM_PROBLEMAS       texto   object   object                2541                2541          0          0         2541         2541          False              16.121606                   19.0            1322            1219            1219          1000                     706                    70.6  ['1219 valores √∫nicos s√≥ no DF1', '1219 valores √∫nicos s√≥ no DF2', 'Taxa de igualdade baixa: 70.6%']\n",
      "2      End        6  COM_PROBLEMAS       texto   object   object                2541                2541          0          0         2541         2541          False              16.121606                   19.0            1322            1219            1219          1000                     707                    70.7  ['1219 valores √∫nicos s√≥ no DF1', '1219 valores √∫nicos s√≥ no DF2', 'Taxa de igualdade baixa: 70.7%']\n",
      "\n",
      "   ‚ö†Ô∏è  An√°lise de Problemas:\n",
      "----------------------------------------\n",
      "\n",
      "üìã Resumo Estat√≠stico:\n",
      "   üìè Dimens√µes: (8, 2)\n",
      "   üî§ Colunas: ['M√©trica', 'Valor']\n",
      "   üìÑ Primeiras 3 linhas:\n",
      "                 M√©trica  Valor\n",
      "0       Total de Colunas   12.0\n",
      "1             Colunas OK    7.0\n",
      "2  Colunas com Problemas    5.0\n",
      "\n",
      "   üìà Resumo Estat√≠stico:\n",
      "      Total de Colunas: 12.0\n",
      "      Colunas OK: 7.0\n",
      "      Colunas com Problemas: 5.0\n",
      "      Taxa de Sucesso (%): 58.33333333333334\n",
      "      Colunas Num√©ricas: 0.0\n",
      "      Colunas de Texto: 12.0\n",
      "      Colunas de Data: 0.0\n",
      "      Outros Tipos: 0.0\n",
      "----------------------------------------\n",
      "\n",
      "‚úÖ An√°lise conclu√≠da!\n",
      "üí° Use 'dados_importados[\"relatorio_comparacao_colunas_20250704_182137.xlsx\"][\"dados\"][\"Nome_da_Aba\"]' para acessar os DataFrames.\n"
     ]
    }
   ],
   "source": [
    "# üîç AN√ÅLISE DOS DADOS IMPORTADOS\n",
    "print(\"üîç AN√ÅLISE DOS DADOS IMPORTADOS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Acessar o primeiro arquivo importado\n",
    "arquivo_nome = list(dados_importados.keys())[0]\n",
    "arquivo_dados = dados_importados[arquivo_nome]\n",
    "\n",
    "print(f\"üìÑ Analisando: {arquivo_nome}\")\n",
    "print(f\"üîπ Tipo: {arquivo_dados['tipo'].upper()}\")\n",
    "\n",
    "# Acessar as abas do Excel\n",
    "if 'dados' in arquivo_dados and isinstance(arquivo_dados['dados'], dict):\n",
    "    print(f\"\\nüìä ABAS DISPON√çVEIS:\")\n",
    "    \n",
    "    for aba_nome, df in arquivo_dados['dados'].items():\n",
    "        print(f\"\\nüìã {aba_nome}:\")\n",
    "        print(f\"   üìè Dimens√µes: {df.shape}\")\n",
    "        print(f\"   üî§ Colunas: {list(df.columns)}\")\n",
    "        \n",
    "        # Mostrar primeiras linhas\n",
    "        if len(df) > 0:\n",
    "            print(f\"   üìÑ Primeiras 3 linhas:\")\n",
    "            print(df.head(3).to_string())\n",
    "            \n",
    "            # An√°lise espec√≠fica por aba\n",
    "            if 'Relat√≥rio Completo' in aba_nome:\n",
    "                print(f\"\\n   üîç An√°lise do Relat√≥rio Completo:\")\n",
    "                if 'status' in df.columns:\n",
    "                    status_counts = df['status'].value_counts()\n",
    "                    print(f\"      Status das colunas: {status_counts.to_dict()}\")\n",
    "                \n",
    "                if 'taxa_igualdade' in df.columns:\n",
    "                    taxa_media = df['taxa_igualdade'].mean()\n",
    "                    print(f\"      Taxa m√©dia de igualdade: {taxa_media:.2f}%\")\n",
    "                    \n",
    "            elif 'Problemas' in aba_nome:\n",
    "                print(f\"\\n   ‚ö†Ô∏è  An√°lise de Problemas:\")\n",
    "                if 'problema' in df.columns:\n",
    "                    problemas = df['problema'].value_counts()\n",
    "                    print(f\"      Tipos de problemas: {problemas.to_dict()}\")\n",
    "                    \n",
    "            elif 'Estat√≠stico' in aba_nome:\n",
    "                print(f\"\\n   üìà Resumo Estat√≠stico:\")\n",
    "                if 'M√©trica' in df.columns and 'Valor' in df.columns:\n",
    "                    for _, row in df.iterrows():\n",
    "                        print(f\"      {row['M√©trica']}: {row['Valor']}\")\n",
    "        \n",
    "        print(\"-\" * 40)\n",
    "\n",
    "print(f\"\\n‚úÖ An√°lise conclu√≠da!\")\n",
    "print(f\"üí° Use 'dados_importados[\\\"{arquivo_nome}\\\"][\\\"dados\\\"][\\\"Nome_da_Aba\\\"]' para acessar os DataFrames.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8792f31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä AN√ÅLISE COMPACTA DOS DADOS IMPORTADOS\n",
      "==================================================\n",
      "üìÑ Arquivo: relatorio_comparacao_colunas_20250704_182137.xlsx\n",
      "üîπ Tipo: EXCEL\n",
      "\n",
      "üìä RESUMO DAS ABAS:\n",
      "\n",
      "üìã Relat√≥rio Completo: 12 registros, 22 colunas\n",
      "   üìä Status: {'OK': np.int64(7), 'COM_PROBLEMAS': np.int64(5)}\n",
      "\n",
      "üìã Colunas com Problemas: 5 registros, 22 colunas\n",
      "\n",
      "üìã Resumo Estat√≠stico: 8 registros, 2 colunas\n",
      "   üìà Estat√≠sticas principais:\n",
      "      ‚Ä¢ Total de Colunas: 12.0\n",
      "      ‚Ä¢ Colunas OK: 7.0\n",
      "      ‚Ä¢ Colunas com Problemas: 5.0\n",
      "      ‚Ä¢ Taxa de Sucesso (%): 58.33333333333334\n",
      "      ‚Ä¢ Colunas Num√©ricas: 0.0\n",
      "      ‚Ä¢ Colunas de Texto: 12.0\n",
      "      ‚Ä¢ Colunas de Data: 0.0\n",
      "      ‚Ä¢ Outros Tipos: 0.0\n",
      "\n",
      "‚úÖ An√°lise conclu√≠da!\n",
      "üí° Acesse os dados com: dados_importados[\"relatorio_comparacao_colunas_20250704_182137.xlsx\"][\"dados\"][\"Nome_da_Aba\"]\n"
     ]
    }
   ],
   "source": [
    "# üìä AN√ÅLISE COMPACTA DOS DADOS IMPORTADOS\n",
    "print(\"üìä AN√ÅLISE COMPACTA DOS DADOS IMPORTADOS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Acessar o primeiro arquivo importado\n",
    "arquivo_nome = list(dados_importados.keys())[0]\n",
    "arquivo_dados = dados_importados[arquivo_nome]\n",
    "\n",
    "print(f\"üìÑ Arquivo: {arquivo_nome}\")\n",
    "print(f\"üîπ Tipo: {arquivo_dados['tipo'].upper()}\")\n",
    "\n",
    "# An√°lise das abas\n",
    "if 'dados' in arquivo_dados and isinstance(arquivo_dados['dados'], dict):\n",
    "    print(f\"\\nüìä RESUMO DAS ABAS:\")\n",
    "    \n",
    "    for aba_nome, df in arquivo_dados['dados'].items():\n",
    "        print(f\"\\nüìã {aba_nome}: {df.shape[0]} registros, {df.shape[1]} colunas\")\n",
    "        \n",
    "        # An√°lise espec√≠fica por aba\n",
    "        if 'Relat√≥rio Completo' in aba_nome:\n",
    "            if 'status' in df.columns:\n",
    "                status_counts = df['status'].value_counts()\n",
    "                print(f\"   üìä Status: {dict(status_counts)}\")\n",
    "            \n",
    "            if 'taxa_igualdade' in df.columns:\n",
    "                taxa_media = df['taxa_igualdade'].mean()\n",
    "                print(f\"   üìà Taxa m√©dia de igualdade: {taxa_media:.2f}%\")\n",
    "                \n",
    "        elif 'Problemas' in aba_nome:\n",
    "            if 'problema' in df.columns:\n",
    "                problemas = df['problema'].value_counts()\n",
    "                print(f\"   ‚ö†Ô∏è  Problemas: {dict(problemas)}\")\n",
    "                \n",
    "        elif 'Estat√≠stico' in aba_nome:\n",
    "            print(f\"   üìà Estat√≠sticas principais:\")\n",
    "            if 'M√©trica' in df.columns and 'Valor' in df.columns:\n",
    "                for _, row in df.iterrows():\n",
    "                    print(f\"      ‚Ä¢ {row['M√©trica']}: {row['Valor']}\")\n",
    "\n",
    "print(f\"\\n‚úÖ An√°lise conclu√≠da!\")\n",
    "print(f\"üí° Acesse os dados com: dados_importados[\\\"{arquivo_nome}\\\"][\\\"dados\\\"][\\\"Nome_da_Aba\\\"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "81dac02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ EXEMPLOS DE MANIPULA√á√ÉO DOS DADOS IMPORTADOS\n",
      "============================================================\n",
      "üìÑ Trabalhando com: relatorio_comparacao_colunas_20250704_182137.xlsx\n",
      "üìä Abas dispon√≠veis: ['Relat√≥rio Completo', 'Colunas com Problemas', 'Resumo Estat√≠stico']\n",
      "\n",
      "üîç EXEMPLO 1: An√°lise do Relat√≥rio Completo\n",
      "   üìè Dimens√µes: (12, 22)\n",
      "   üî§ Colunas principais: ['coluna', 'posicao', 'status', 'tipo_coluna', 'tipo_df1']...\n",
      "   ‚ö†Ô∏è  Colunas com problemas: 5\n",
      "   üîç Quais colunas: ['Checkin', 'Start', 'End', 'Checkout', 'Crew']\n",
      "\n",
      "üìà EXEMPLO 2: Resumo Estat√≠stico\n",
      "   ‚Ä¢ Total de Colunas: 12.0\n",
      "   ‚Ä¢ Colunas OK: 7.0\n",
      "   ‚Ä¢ Colunas com Problemas: 5.0\n",
      "   ‚Ä¢ Taxa de Sucesso (%): 58.33333333333334\n",
      "   ‚Ä¢ Colunas Num√©ricas: 0.0\n",
      "   ‚Ä¢ Colunas de Texto: 12.0\n",
      "   ‚Ä¢ Colunas de Data: 0.0\n",
      "   ‚Ä¢ Outros Tipos: 0.0\n",
      "\n",
      "‚úÖ EXEMPLO 3: Colunas OK\n",
      "   üìä Total de colunas OK: 7\n",
      "   üîç Primeiras 5 colunas OK: ['Activity', 'Id_Leg', 'Dep', 'Arr', 'AcVer']\n",
      "\n",
      "üíæ VARI√ÅVEIS CRIADAS:\n",
      "   üìä df_relatorio_completo: (12, 22)\n",
      "   ‚ö†Ô∏è  df_colunas_problemas: (5, 22)\n",
      "   üìà df_resumo_estatistico: (8, 2)\n",
      "\n",
      "‚úÖ Pronto! Agora voc√™ pode usar essas vari√°veis para an√°lises mais detalhadas.\n",
      "üí° Exemplo: df_relatorio_completo[df_relatorio_completo['coluna'] == 'Nome_da_Coluna']\n"
     ]
    }
   ],
   "source": [
    "# üéØ EXEMPLOS DE MANIPULA√á√ÉO DOS DADOS IMPORTADOS\n",
    "print(\"üéØ EXEMPLOS DE MANIPULA√á√ÉO DOS DADOS IMPORTADOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Vari√°veis de conveni√™ncia\n",
    "arquivo_nome = list(dados_importados.keys())[0]\n",
    "dados_excel = dados_importados[arquivo_nome]['dados']\n",
    "\n",
    "print(f\"üìÑ Trabalhando com: {arquivo_nome}\")\n",
    "print(f\"üìä Abas dispon√≠veis: {list(dados_excel.keys())}\")\n",
    "\n",
    "# Exemplo 1: Acessar relat√≥rio completo\n",
    "print(f\"\\nüîç EXEMPLO 1: An√°lise do Relat√≥rio Completo\")\n",
    "df_completo = dados_excel['Relat√≥rio Completo']\n",
    "print(f\"   üìè Dimens√µes: {df_completo.shape}\")\n",
    "print(f\"   üî§ Colunas principais: {df_completo.columns.tolist()[:5]}...\")\n",
    "\n",
    "# Filtrar apenas colunas com problemas\n",
    "colunas_com_problemas = df_completo[df_completo['status'] == 'COM_PROBLEMAS']\n",
    "print(f\"   ‚ö†Ô∏è  Colunas com problemas: {len(colunas_com_problemas)}\")\n",
    "if len(colunas_com_problemas) > 0:\n",
    "    print(f\"   üîç Quais colunas: {colunas_com_problemas['coluna'].tolist()}\")\n",
    "\n",
    "# Exemplo 2: Acessar resumo estat√≠stico\n",
    "print(f\"\\nüìà EXEMPLO 2: Resumo Estat√≠stico\")\n",
    "df_stats = dados_excel['Resumo Estat√≠stico']\n",
    "for _, row in df_stats.iterrows():\n",
    "    print(f\"   ‚Ä¢ {row['M√©trica']}: {row['Valor']}\")\n",
    "\n",
    "# Exemplo 3: An√°lise das colunas OK\n",
    "print(f\"\\n‚úÖ EXEMPLO 3: Colunas OK\")\n",
    "colunas_ok = df_completo[df_completo['status'] == 'OK']\n",
    "print(f\"   üìä Total de colunas OK: {len(colunas_ok)}\")\n",
    "print(f\"   üîç Primeiras 5 colunas OK: {colunas_ok['coluna'].head().tolist()}\")\n",
    "\n",
    "# Criar vari√°veis globais para facilitar uso posterior\n",
    "df_relatorio_completo = dados_excel['Relat√≥rio Completo']\n",
    "df_colunas_problemas = dados_excel['Colunas com Problemas']\n",
    "df_resumo_estatistico = dados_excel['Resumo Estat√≠stico']\n",
    "\n",
    "print(f\"\\nüíæ VARI√ÅVEIS CRIADAS:\")\n",
    "print(f\"   üìä df_relatorio_completo: {df_relatorio_completo.shape}\")\n",
    "print(f\"   ‚ö†Ô∏è  df_colunas_problemas: {df_colunas_problemas.shape}\")\n",
    "print(f\"   üìà df_resumo_estatistico: {df_resumo_estatistico.shape}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Pronto! Agora voc√™ pode usar essas vari√°veis para an√°lises mais detalhadas.\")\n",
    "print(f\"üí° Exemplo: df_relatorio_completo[df_relatorio_completo['coluna'] == 'Nome_da_Coluna']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "17c51760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç AN√ÅLISE ESPEC√çFICA DO DF2 - TEMPO APRESENTA√á√ÉO\n",
      "============================================================\n",
      "‚úÖ DF2 encontrado: (2541, 25)\n",
      "üìã Colunas necess√°rias: ['Id_Leg', 'Activity', 'Tempo Apresentacao', 'Start', 'Checkin']\n",
      "üìã Colunas existentes: ['Id_Leg', 'Activity', 'Tempo Apresentacao', 'Start', 'Checkin']\n",
      "‚úÖ Todas as colunas necess√°rias est√£o presentes!\n",
      "‚úÖ Arquivo tipos_voo.json encontrado: tipos_voo.json\n",
      "üìã Tipos de voo carregados: 1 tipos\n",
      "üîç Primeiros 5 tipos: ['tipos_voo']\n"
     ]
    }
   ],
   "source": [
    "# üîç AN√ÅLISE ESPEC√çFICA DO DF2 - TEMPO APRESENTA√á√ÉO\n",
    "print(\"üîç AN√ÅLISE ESPEC√çFICA DO DF2 - TEMPO APRESENTA√á√ÉO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Verificar se DF2 existe\n",
    "if 'df2' not in locals():\n",
    "    print(\"‚ùå DF2 n√£o encontrado. Execute primeiro as c√©lulas de carregamento.\")\n",
    "else:\n",
    "    print(f\"‚úÖ DF2 encontrado: {df2.shape}\")\n",
    "    \n",
    "    # Verificar se as colunas necess√°rias existem\n",
    "    colunas_necessarias = ['Id_Leg', 'Activity', 'Tempo Apresentacao', 'Start', 'Checkin']\n",
    "    colunas_existentes = [col for col in colunas_necessarias if col in df2.columns]\n",
    "    \n",
    "    print(f\"üìã Colunas necess√°rias: {colunas_necessarias}\")\n",
    "    print(f\"üìã Colunas existentes: {colunas_existentes}\")\n",
    "    \n",
    "    if len(colunas_existentes) == len(colunas_necessarias):\n",
    "        print(\"‚úÖ Todas as colunas necess√°rias est√£o presentes!\")\n",
    "    else:\n",
    "        print(f\"‚ùå Faltam colunas: {set(colunas_necessarias) - set(colunas_existentes)}\")\n",
    "        print(\"üí° Verificando nomes similares...\")\n",
    "        for col in df2.columns:\n",
    "            print(f\"   - {col}\")\n",
    "        \n",
    "    # Verificar se existe o arquivo tipos_voo.json\n",
    "    import os\n",
    "    import json\n",
    "    \n",
    "    # Procurar o arquivo tipos_voo.json no diret√≥rio atual e adjacentes\n",
    "    caminhos_possiveis = [\n",
    "        \"tipos_voo.json\",\n",
    "        \"../tipos_voo.json\",\n",
    "        \"../../tipos_voo.json\",\n",
    "        os.path.join(diretorio, \"tipos_voo.json\") if 'diretorio' in locals() else None\n",
    "    ]\n",
    "    \n",
    "    # Remover None values\n",
    "    caminhos_possiveis = [c for c in caminhos_possiveis if c is not None]\n",
    "    \n",
    "    arquivo_tipos_voo = None\n",
    "    for caminho in caminhos_possiveis:\n",
    "        if os.path.exists(caminho):\n",
    "            arquivo_tipos_voo = caminho\n",
    "            break\n",
    "    \n",
    "    if arquivo_tipos_voo:\n",
    "        print(f\"‚úÖ Arquivo tipos_voo.json encontrado: {arquivo_tipos_voo}\")\n",
    "        try:\n",
    "            with open(arquivo_tipos_voo, 'r', encoding='utf-8') as f:\n",
    "                tipos_voo = json.load(f)\n",
    "            print(f\"üìã Tipos de voo carregados: {len(tipos_voo)} tipos\")\n",
    "            print(f\"üîç Primeiros 5 tipos: {list(tipos_voo.keys())[:5] if isinstance(tipos_voo, dict) else tipos_voo[:5]}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erro ao carregar tipos_voo.json: {e}\")\n",
    "            tipos_voo = None\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Arquivo tipos_voo.json n√£o encontrado nos caminhos:\")\n",
    "        for caminho in caminhos_possiveis:\n",
    "            print(f\"   - {caminho}\")\n",
    "        print(\"üí° Vou criar um arquivo de exemplo ou usar uma lista padr√£o\")\n",
    "        tipos_voo = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ababa2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä AN√ÅLISE DETALHADA - TEMPO APRESENTA√á√ÉO NO DF2\n",
      "============================================================\n",
      "‚úÖ Tipos de voo carregados: 11 tipos\n",
      "üìã Tipos: ['AD', 'SFX', 'PSM', 'S02', 'S06', 'S10', 'S14', '818', 'S22', 'CPT', 'APT']\n",
      "\n",
      "üîç CONDI√á√ïES DE AN√ÅLISE:\n",
      "   1. Id_Leg deve terminar com '-I' ou '-IF'\n",
      "   2. Activity deve estar na lista de tipos_voo\n",
      "   3. Tempo Apresentacao deve ser Start - Checkin\n",
      "\n",
      "üìã APLICANDO FILTROS...\n",
      "   üìä Registros com Id_Leg terminando em '-I' ou '-IF': 1,858\n",
      "   üìä Registros com Activity nos tipos_voo: 43\n",
      "   üìä Registros que atendem AMBAS as condi√ß√µes: 43\n",
      "\n",
      "üîç VERIFICANDO C√ÅLCULO: Tempo Apresentacao = Start - Checkin\n",
      "   üìä Analisando 43 registros filtrados...\n",
      "   üîç Comparando valores...\n",
      "\n",
      "üìà RESULTADOS:\n",
      "   ‚úÖ Registros com c√°lculo CORRETO: 43\n",
      "   ‚ùå Registros com c√°lculo INCORRETO: 0\n",
      "   üìä Taxa de acerto: 100.0%\n",
      "\n",
      "üéØ RESUMO FINAL:\n",
      "   üìä Total de registros no DF2: 2,541\n",
      "   üìä Registros com Id_Leg (-I ou -IF): 1,858\n",
      "   üìä Registros com Activity v√°lido: 43\n",
      "   üìä Registros que atendem AMBAS condi√ß√µes: 43\n",
      "   üíæ Dados salvos em 'df2_tempo_apresentacao'\n"
     ]
    }
   ],
   "source": [
    "# üìä AN√ÅLISE DETALHADA - TEMPO APRESENTA√á√ÉO NO DF2\n",
    "print(\"üìä AN√ÅLISE DETALHADA - TEMPO APRESENTA√á√ÉO NO DF2\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Carregar tipos_voo.json\n",
    "if arquivo_tipos_voo:\n",
    "    with open(arquivo_tipos_voo, 'r', encoding='utf-8') as f:\n",
    "        tipos_voo_data = json.load(f)\n",
    "    \n",
    "    # Extrair a lista de tipos de voo\n",
    "    if isinstance(tipos_voo_data, dict) and 'tipos_voo' in tipos_voo_data:\n",
    "        tipos_voo_lista = tipos_voo_data['tipos_voo']\n",
    "    elif isinstance(tipos_voo_data, list):\n",
    "        tipos_voo_lista = tipos_voo_data\n",
    "    else:\n",
    "        tipos_voo_lista = list(tipos_voo_data.keys()) if isinstance(tipos_voo_data, dict) else []\n",
    "    \n",
    "    print(f\"‚úÖ Tipos de voo carregados: {len(tipos_voo_lista)} tipos\")\n",
    "    print(f\"üìã Tipos: {tipos_voo_lista}\")\n",
    "else:\n",
    "    # Lista padr√£o de tipos de voo se n√£o encontrar o arquivo\n",
    "    tipos_voo_lista = ['FLT', 'VOO', 'FLIGHT', 'FL', 'VL']\n",
    "    print(f\"‚ö†Ô∏è Usando lista padr√£o: {tipos_voo_lista}\")\n",
    "\n",
    "print(f\"\\nüîç CONDI√á√ïES DE AN√ÅLISE:\")\n",
    "print(f\"   1. Id_Leg deve terminar com '-I' ou '-IF'\")\n",
    "print(f\"   2. Activity deve estar na lista de tipos_voo\")\n",
    "print(f\"   3. Tempo Apresentacao deve ser Start - Checkin\")\n",
    "\n",
    "# 2. Filtrar registros que atendem √†s condi√ß√µes\n",
    "print(f\"\\nüìã APLICANDO FILTROS...\")\n",
    "\n",
    "# Condi√ß√£o 1: Id_Leg termina com -I ou -IF\n",
    "filtro_id_leg = df2['Id_Leg'].str.endswith(('-I', '-IF'))\n",
    "df2_filtrado_id = df2[filtro_id_leg]\n",
    "print(f\"   üìä Registros com Id_Leg terminando em '-I' ou '-IF': {len(df2_filtrado_id):,}\")\n",
    "\n",
    "# Condi√ß√£o 2: Activity est√° na lista de tipos_voo\n",
    "filtro_activity = df2['Activity'].isin(tipos_voo_lista)\n",
    "df2_filtrado_activity = df2[filtro_activity]\n",
    "print(f\"   üìä Registros com Activity nos tipos_voo: {len(df2_filtrado_activity):,}\")\n",
    "\n",
    "# Aplicar ambos os filtros\n",
    "filtro_combinado = filtro_id_leg & filtro_activity\n",
    "df2_filtrado_final = df2[filtro_combinado]\n",
    "print(f\"   üìä Registros que atendem AMBAS as condi√ß√µes: {len(df2_filtrado_final):,}\")\n",
    "\n",
    "# 3. Verificar se Tempo Apresentacao = Start - Checkin\n",
    "print(f\"\\nüîç VERIFICANDO C√ÅLCULO: Tempo Apresentacao = Start - Checkin\")\n",
    "\n",
    "if len(df2_filtrado_final) > 0:\n",
    "    print(f\"   üìä Analisando {len(df2_filtrado_final):,} registros filtrados...\")\n",
    "    \n",
    "    # Converter para datetime se necess√°rio\n",
    "    try:\n",
    "        # Tentar converter as colunas para datetime\n",
    "        df2_temp = df2_filtrado_final.copy()\n",
    "        \n",
    "        # Fun√ß√£o para converter string datetime para datetime object\n",
    "        def converter_datetime(col):\n",
    "            if col.dtype == 'object':\n",
    "                try:\n",
    "                    return pd.to_datetime(col)\n",
    "                except:\n",
    "                    return col\n",
    "            return col\n",
    "        \n",
    "        df2_temp['Start_dt'] = converter_datetime(df2_temp['Start'])\n",
    "        df2_temp['Checkin_dt'] = converter_datetime(df2_temp['Checkin'])\n",
    "        \n",
    "        # Calcular diferen√ßa\n",
    "        df2_temp['Tempo_Calculado'] = df2_temp['Start_dt'] - df2_temp['Checkin_dt']\n",
    "        \n",
    "        # Comparar com Tempo Apresentacao\n",
    "        tempo_apresentacao_original = df2_temp['Tempo Apresentacao']\n",
    "        tempo_calculado = df2_temp['Tempo_Calculado']\n",
    "        \n",
    "        # Verificar se s√£o iguais (considerando diferentes formatos)\n",
    "        registros_corretos = 0\n",
    "        registros_incorretos = 0\n",
    "        exemplos_incorretos = []\n",
    "        \n",
    "        print(f\"   üîç Comparando valores...\")\n",
    "        \n",
    "        for idx, row in df2_temp.iterrows():\n",
    "            tempo_orig = str(row['Tempo Apresentacao'])\n",
    "            tempo_calc = str(row['Tempo_Calculado'])\n",
    "            \n",
    "            # Verificar se s√£o iguais (considerando diferentes formatos)\n",
    "            if tempo_orig == tempo_calc:\n",
    "                registros_corretos += 1\n",
    "            else:\n",
    "                registros_incorretos += 1\n",
    "                if len(exemplos_incorretos) < 5:  # Guardar apenas 5 exemplos\n",
    "                    exemplos_incorretos.append({\n",
    "                        'indice': idx,\n",
    "                        'id_leg': row['Id_Leg'],\n",
    "                        'activity': row['Activity'],\n",
    "                        'tempo_apresentacao': tempo_orig,\n",
    "                        'tempo_calculado': tempo_calc,\n",
    "                        'start': row['Start'],\n",
    "                        'checkin': row['Checkin']\n",
    "                    })\n",
    "        \n",
    "        print(f\"\\nüìà RESULTADOS:\")\n",
    "        print(f\"   ‚úÖ Registros com c√°lculo CORRETO: {registros_corretos:,}\")\n",
    "        print(f\"   ‚ùå Registros com c√°lculo INCORRETO: {registros_incorretos:,}\")\n",
    "        print(f\"   üìä Taxa de acerto: {(registros_corretos / len(df2_filtrado_final) * 100):.1f}%\")\n",
    "        \n",
    "        if exemplos_incorretos:\n",
    "            print(f\"\\nüîç EXEMPLOS DE C√ÅLCULOS INCORRETOS:\")\n",
    "            for i, ex in enumerate(exemplos_incorretos, 1):\n",
    "                print(f\"   {i}. √çndice {ex['indice']} - {ex['id_leg']} - {ex['activity']}\")\n",
    "                print(f\"      Tempo Apresentacao: {ex['tempo_apresentacao']}\")\n",
    "                print(f\"      Tempo Calculado: {ex['tempo_calculado']}\")\n",
    "                print(f\"      Start: {ex['start']}\")\n",
    "                print(f\"      Checkin: {ex['checkin']}\")\n",
    "                print()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Erro ao processar datas: {e}\")\n",
    "        print(f\"   üí° Vou fazer uma an√°lise mais simples...\")\n",
    "        \n",
    "        # An√°lise mais simples - apenas mostrar alguns exemplos\n",
    "        print(f\"\\nüìã PRIMEIROS 5 REGISTROS FILTRADOS:\")\n",
    "        colunas_mostrar = ['Id_Leg', 'Activity', 'Tempo Apresentacao', 'Start', 'Checkin']\n",
    "        for i, (idx, row) in enumerate(df2_filtrado_final[colunas_mostrar].head().iterrows()):\n",
    "            print(f\"   {i+1}. {dict(row)}\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Nenhum registro atende √†s condi√ß√µes especificadas\")\n",
    "\n",
    "print(f\"\\nüéØ RESUMO FINAL:\")\n",
    "print(f\"   üìä Total de registros no DF2: {len(df2):,}\")\n",
    "print(f\"   üìä Registros com Id_Leg (-I ou -IF): {len(df2_filtrado_id):,}\")\n",
    "print(f\"   üìä Registros com Activity v√°lido: {len(df2_filtrado_activity):,}\")\n",
    "print(f\"   üìä Registros que atendem AMBAS condi√ß√µes: {len(df2_filtrado_final):,}\")\n",
    "\n",
    "# Salvar o dataframe filtrado para uso posterior\n",
    "df2_tempo_apresentacao = df2_filtrado_final\n",
    "print(f\"   üíæ Dados salvos em 'df2_tempo_apresentacao'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3560ea0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä AN√ÅLISE MELHORADA - TEMPO APRESENTA√á√ÉO NO DF2\n",
      "============================================================\n",
      "‚úÖ Tipos de voo carregados: 11 tipos\n",
      "üìã Tipos: ['AD', 'SFX', 'PSM', 'S02', 'S06', 'S10', 'S14', '818', 'S22', 'CPT', 'APT']\n",
      "\n",
      "üìã APLICANDO FILTROS PASSO A PASSO...\n",
      "üìä Total de registros no DF2: 2,541\n",
      "üìä Valores √∫nicos em Id_Leg: 4\n",
      "üìä Primeiros 10 valores: ['-IF', '-I', '-F', '-M']\n",
      "üìä Valores √∫nicos em Activity: 733\n",
      "üìä Primeiros 10 valores: ['FR', 'FER', 'SNA', 'F', 'EAD', 'SFX', 'DOP', 'FP', 'BUS', 'PP1']\n",
      "\n",
      "üîç FILTRO 1: Id_Leg termina com '-I' ou '-IF'\n",
      "   üìä Registros que passaram: 1,858 (73.1%)\n",
      "\n",
      "üîç FILTRO 2: Activity est√° em tipos_voo\n",
      "   üìä Registros que passaram: 43 (1.7%)\n",
      "\n",
      "üîç FILTRO COMBINADO: Ambas as condi√ß√µes\n",
      "   üìä Registros que passaram: 43 (1.7%)\n",
      "\n",
      "üîç AN√ÅLISE DO TEMPO APRESENTA√á√ÉO\n",
      "üìä Analisando 43 registros filtrados...\n",
      "\n",
      "üìã PRIMEIROS 5 REGISTROS FILTRADOS:\n",
      "   1. √çndice 222:\n",
      "      Id_Leg: -IF\n",
      "      Activity: S10\n",
      "      Tempo Apresentacao: 0 days 01:30:00\n",
      "      Start: 2018-04-14 13:00:00\n",
      "      Checkin: 2018-04-14 11:30:00\n",
      "\n",
      "   2. √çndice 223:\n",
      "      Id_Leg: -IF\n",
      "      Activity: S10\n",
      "      Tempo Apresentacao: 0 days 01:30:00\n",
      "      Start: 2018-04-15 13:00:00\n",
      "      Checkin: 2018-04-15 11:30:00\n",
      "\n",
      "   3. √çndice 224:\n",
      "      Id_Leg: -IF\n",
      "      Activity: S10\n",
      "      Tempo Apresentacao: 0 days 01:30:00\n",
      "      Start: 2018-04-16 13:00:00\n",
      "      Checkin: 2018-04-16 11:30:00\n",
      "\n",
      "   4. √çndice 420:\n",
      "      Id_Leg: -IF\n",
      "      Activity: S06\n",
      "      Tempo Apresentacao: 0 days 01:30:00\n",
      "      Start: 2018-09-13 09:00:00\n",
      "      Checkin: 2018-09-13 07:30:00\n",
      "\n",
      "   5. √çndice 421:\n",
      "      Id_Leg: -IF\n",
      "      Activity: S10\n",
      "      Tempo Apresentacao: 0 days 01:30:00\n",
      "      Start: 2018-09-14 13:00:00\n",
      "      Checkin: 2018-09-14 11:30:00\n",
      "\n",
      "üìã AN√ÅLISE DE FORMATOS:\n",
      "   Start exemplos: ['2018-04-14 13:00:00', '2018-04-15 13:00:00', '2018-04-16 13:00:00']\n",
      "   Checkin exemplos: ['2018-04-14 11:30:00', '2018-04-15 11:30:00', '2018-04-16 11:30:00']\n",
      "   Tempo Apresentacao exemplos: ['0 days 01:30:00', '0 days 01:30:00', '0 days 01:30:00']\n",
      "\n",
      "üìä ESTAT√çSTICAS DOS REGISTROS FILTRADOS:\n",
      "   Id_Leg √∫nicos: 1\n",
      "   Activity √∫nicos: 7\n",
      "   Tempo Apresentacao √∫nicos: 2\n",
      "\n",
      "üíæ RESULTADOS SALVOS:\n",
      "   df2_tempo_apresentacao: 43 registros\n",
      "\n",
      "üéØ RESUMO FINAL:\n",
      "   üìä Total original: 2,541\n",
      "   üìä Ap√≥s filtros: 43\n",
      "   üìä Taxa de filtro: 1.7%\n"
     ]
    }
   ],
   "source": [
    "# üìä AN√ÅLISE MELHORADA - TEMPO APRESENTA√á√ÉO NO DF2\n",
    "print(\"üìä AN√ÅLISE MELHORADA - TEMPO APRESENTA√á√ÉO NO DF2\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Importar pandas para manipula√ß√£o de datas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Verificar o arquivo tipos_voo.json\n",
    "if arquivo_tipos_voo:\n",
    "    with open(arquivo_tipos_voo, 'r', encoding='utf-8') as f:\n",
    "        tipos_voo_data = json.load(f)\n",
    "    \n",
    "    # Extrair a lista de tipos de voo\n",
    "    if isinstance(tipos_voo_data, dict) and 'tipos_voo' in tipos_voo_data:\n",
    "        tipos_voo_lista = tipos_voo_data['tipos_voo']\n",
    "    elif isinstance(tipos_voo_data, list):\n",
    "        tipos_voo_lista = tipos_voo_data\n",
    "    else:\n",
    "        tipos_voo_lista = list(tipos_voo_data.keys()) if isinstance(tipos_voo_data, dict) else []\n",
    "    \n",
    "    print(f\"‚úÖ Tipos de voo carregados: {len(tipos_voo_lista)} tipos\")\n",
    "    print(f\"üìã Tipos: {tipos_voo_lista}\")\n",
    "else:\n",
    "    # Lista padr√£o de tipos de voo se n√£o encontrar o arquivo\n",
    "    tipos_voo_lista = ['FLT', 'VOO', 'FLIGHT', 'FL', 'VL']\n",
    "    print(f\"‚ö†Ô∏è Usando lista padr√£o: {tipos_voo_lista}\")\n",
    "\n",
    "# 2. Aplicar filtros passo a passo\n",
    "print(f\"\\nüìã APLICANDO FILTROS PASSO A PASSO...\")\n",
    "\n",
    "# Mostrar estat√≠sticas iniciais\n",
    "print(f\"üìä Total de registros no DF2: {len(df2):,}\")\n",
    "\n",
    "# Verificar valores √∫nicos em Id_Leg\n",
    "id_leg_valores = df2['Id_Leg'].value_counts()\n",
    "print(f\"üìä Valores √∫nicos em Id_Leg: {df2['Id_Leg'].nunique()}\")\n",
    "print(f\"üìä Primeiros 10 valores: {list(id_leg_valores.head(10).index)}\")\n",
    "\n",
    "# Verificar valores √∫nicos em Activity\n",
    "activity_valores = df2['Activity'].value_counts()\n",
    "print(f\"üìä Valores √∫nicos em Activity: {df2['Activity'].nunique()}\")\n",
    "print(f\"üìä Primeiros 10 valores: {list(activity_valores.head(10).index)}\")\n",
    "\n",
    "# Aplicar filtro 1: Id_Leg termina com -I ou -IF\n",
    "print(f\"\\nüîç FILTRO 1: Id_Leg termina com '-I' ou '-IF'\")\n",
    "filtro_id_leg = df2['Id_Leg'].str.endswith(('-I', '-IF'))\n",
    "df2_filtro1 = df2[filtro_id_leg]\n",
    "print(f\"   üìä Registros que passaram: {len(df2_filtro1):,} ({len(df2_filtro1)/len(df2)*100:.1f}%)\")\n",
    "\n",
    "# Aplicar filtro 2: Activity est√° na lista de tipos_voo\n",
    "print(f\"\\nüîç FILTRO 2: Activity est√° em tipos_voo\")\n",
    "filtro_activity = df2['Activity'].isin(tipos_voo_lista)\n",
    "df2_filtro2 = df2[filtro_activity]\n",
    "print(f\"   üìä Registros que passaram: {len(df2_filtro2):,} ({len(df2_filtro2)/len(df2)*100:.1f}%)\")\n",
    "\n",
    "# Aplicar ambos os filtros\n",
    "print(f\"\\nüîç FILTRO COMBINADO: Ambas as condi√ß√µes\")\n",
    "filtro_combinado = filtro_id_leg & filtro_activity\n",
    "df2_filtrado = df2[filtro_combinado]\n",
    "print(f\"   üìä Registros que passaram: {len(df2_filtrado):,} ({len(df2_filtrado)/len(df2)*100:.1f}%)\")\n",
    "\n",
    "# 3. Analisar Tempo Apresentacao nos registros filtrados\n",
    "print(f\"\\nüîç AN√ÅLISE DO TEMPO APRESENTA√á√ÉO\")\n",
    "\n",
    "if len(df2_filtrado) > 0:\n",
    "    print(f\"üìä Analisando {len(df2_filtrado):,} registros filtrados...\")\n",
    "    \n",
    "    # Mostrar exemplos dos dados\n",
    "    print(f\"\\nüìã PRIMEIROS 5 REGISTROS FILTRADOS:\")\n",
    "    colunas_principais = ['Id_Leg', 'Activity', 'Tempo Apresentacao', 'Start', 'Checkin']\n",
    "    \n",
    "    for i, (idx, row) in enumerate(df2_filtrado[colunas_principais].head().iterrows()):\n",
    "        print(f\"   {i+1}. √çndice {idx}:\")\n",
    "        print(f\"      Id_Leg: {row['Id_Leg']}\")\n",
    "        print(f\"      Activity: {row['Activity']}\")\n",
    "        print(f\"      Tempo Apresentacao: {row['Tempo Apresentacao']}\")\n",
    "        print(f\"      Start: {row['Start']}\")\n",
    "        print(f\"      Checkin: {row['Checkin']}\")\n",
    "        print()\n",
    "    \n",
    "    # Analisar formatos de data\n",
    "    print(f\"üìã AN√ÅLISE DE FORMATOS:\")\n",
    "    start_exemplos = df2_filtrado['Start'].head(3).tolist()\n",
    "    checkin_exemplos = df2_filtrado['Checkin'].head(3).tolist()\n",
    "    tempo_exemplos = df2_filtrado['Tempo Apresentacao'].head(3).tolist()\n",
    "    \n",
    "    print(f\"   Start exemplos: {start_exemplos}\")\n",
    "    print(f\"   Checkin exemplos: {checkin_exemplos}\")\n",
    "    print(f\"   Tempo Apresentacao exemplos: {tempo_exemplos}\")\n",
    "    \n",
    "    # Verificar se h√° diferen√ßas √≥bvias\n",
    "    print(f\"\\nüìä ESTAT√çSTICAS DOS REGISTROS FILTRADOS:\")\n",
    "    print(f\"   Id_Leg √∫nicos: {df2_filtrado['Id_Leg'].nunique()}\")\n",
    "    print(f\"   Activity √∫nicos: {df2_filtrado['Activity'].nunique()}\")\n",
    "    print(f\"   Tempo Apresentacao √∫nicos: {df2_filtrado['Tempo Apresentacao'].nunique()}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Nenhum registro passou pelos filtros!\")\n",
    "    \n",
    "    # Diagn√≥stico dos filtros\n",
    "    print(f\"\\nüîç DIAGN√ìSTICO:\")\n",
    "    print(f\"   Registros com Id_Leg terminando em '-I' ou '-IF': {filtro_id_leg.sum()}\")\n",
    "    print(f\"   Registros com Activity em tipos_voo: {filtro_activity.sum()}\")\n",
    "    \n",
    "    # Verificar se h√° problemas com os tipos de voo\n",
    "    print(f\"\\nüìã Activities √∫nicos no DF2:\")\n",
    "    for activity in df2['Activity'].unique()[:10]:\n",
    "        print(f\"   - '{activity}'\")\n",
    "    \n",
    "    print(f\"\\nüìã Id_Leg √∫nicos no DF2:\")\n",
    "    for id_leg in df2['Id_Leg'].unique()[:10]:\n",
    "        print(f\"   - '{id_leg}'\")\n",
    "\n",
    "# 4. Salvar resultados\n",
    "df2_tempo_apresentacao = df2_filtrado\n",
    "print(f\"\\nüíæ RESULTADOS SALVOS:\")\n",
    "print(f\"   df2_tempo_apresentacao: {len(df2_tempo_apresentacao):,} registros\")\n",
    "\n",
    "print(f\"\\nüéØ RESUMO FINAL:\")\n",
    "print(f\"   üìä Total original: {len(df2):,}\")\n",
    "print(f\"   üìä Ap√≥s filtros: {len(df2_filtrado):,}\")\n",
    "print(f\"   üìä Taxa de filtro: {len(df2_filtrado)/len(df2)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "67f8387a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öóÔ∏è VERIFICA√á√ÉO DO C√ÅLCULO: Tempo Apresenta√ß√£o = Start - Checkin\n",
      "======================================================================\n",
      "üìä Verificando 43 registros...\n",
      "üîÑ Convertendo datas...\n",
      "   üìä Start convertidos: 0/43\n",
      "   üìä Checkin convertidos: 0/43\n",
      "‚ö†Ô∏è Algumas datas n√£o foram convertidas. Verificando formatos...\n",
      "   Start n√£o convertidos: ['2018-04-14 13:00:00', '2018-04-15 13:00:00', '2018-04-16 13:00:00']\n",
      "   Checkin n√£o convertidos: ['2018-04-14 11:30:00', '2018-04-15 11:30:00', '2018-04-16 11:30:00']\n",
      "üìä Registros com datas v√°lidas: 0\n",
      "‚ùå Nenhum registro com datas v√°lidas encontrado!\n",
      "\n",
      "üéØ RESUMO FINAL DA VERIFICA√á√ÉO:\n",
      "   üìä Total de registros DF2: 2,541\n",
      "   üìä Registros filtrados: 43\n",
      "   üìä Registros com datas v√°lidas: 0\n",
      "\n",
      "üíæ Vari√°veis criadas:\n",
      "   - df2_tempo_apresentacao: 43 registros\n",
      "   - df_validos: 0 registros (com datas v√°lidas)\n"
     ]
    }
   ],
   "source": [
    "# ‚öóÔ∏è VERIFICA√á√ÉO DO C√ÅLCULO: Tempo Apresenta√ß√£o = Start - Checkin\n",
    "print(\"‚öóÔ∏è VERIFICA√á√ÉO DO C√ÅLCULO: Tempo Apresenta√ß√£o = Start - Checkin\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if len(df2_tempo_apresentacao) > 0:\n",
    "    print(f\"üìä Verificando {len(df2_tempo_apresentacao):,} registros...\")\n",
    "    \n",
    "    # Criar c√≥pia para n√£o modificar o original\n",
    "    df_verifica = df2_tempo_apresentacao.copy()\n",
    "    \n",
    "    # Fun√ß√£o para converter datetime com formato brasileiro\n",
    "    def converter_datetime_br(serie):\n",
    "        \"\"\"Converte string datetime para datetime object com formato brasileiro\"\"\"\n",
    "        if serie.dtype == 'object':\n",
    "            try:\n",
    "                # Tentar formato brasileiro primeiro\n",
    "                return pd.to_datetime(serie, format='%d/%m/%Y %H:%M', errors='coerce')\n",
    "            except:\n",
    "                try:\n",
    "                    # Tentar formato alternativo\n",
    "                    return pd.to_datetime(serie, dayfirst=True, errors='coerce')\n",
    "                except:\n",
    "                    return serie\n",
    "        return serie\n",
    "    \n",
    "    # Converter datas\n",
    "    print(\"üîÑ Convertendo datas...\")\n",
    "    df_verifica['Start_dt'] = converter_datetime_br(df_verifica['Start'])\n",
    "    df_verifica['Checkin_dt'] = converter_datetime_br(df_verifica['Checkin'])\n",
    "    \n",
    "    # Verificar se as convers√µes funcionaram\n",
    "    start_nulos = df_verifica['Start_dt'].isna().sum()\n",
    "    checkin_nulos = df_verifica['Checkin_dt'].isna().sum()\n",
    "    \n",
    "    print(f\"   üìä Start convertidos: {len(df_verifica) - start_nulos:,}/{len(df_verifica):,}\")\n",
    "    print(f\"   üìä Checkin convertidos: {len(df_verifica) - checkin_nulos:,}/{len(df_verifica):,}\")\n",
    "    \n",
    "    if start_nulos > 0 or checkin_nulos > 0:\n",
    "        print(\"‚ö†Ô∏è Algumas datas n√£o foram convertidas. Verificando formatos...\")\n",
    "        if start_nulos > 0:\n",
    "            print(f\"   Start n√£o convertidos: {df_verifica[df_verifica['Start_dt'].isna()]['Start'].head(3).tolist()}\")\n",
    "        if checkin_nulos > 0:\n",
    "            print(f\"   Checkin n√£o convertidos: {df_verifica[df_verifica['Checkin_dt'].isna()]['Checkin'].head(3).tolist()}\")\n",
    "    \n",
    "    # Calcular diferen√ßa apenas para registros com datas v√°lidas\n",
    "    mask_validos = ~df_verifica['Start_dt'].isna() & ~df_verifica['Checkin_dt'].isna()\n",
    "    df_validos = df_verifica[mask_validos]\n",
    "    \n",
    "    print(f\"üìä Registros com datas v√°lidas: {len(df_validos):,}\")\n",
    "    \n",
    "    if len(df_validos) > 0:\n",
    "        # Calcular diferen√ßa\n",
    "        df_validos['Tempo_Calculado'] = df_validos['Start_dt'] - df_validos['Checkin_dt']\n",
    "        \n",
    "        print(f\"\\nüîç VERIFICANDO C√ÅLCULOS...\")\n",
    "        \n",
    "        # Converter Tempo Apresenta√ß√£o para timedelta se necess√°rio\n",
    "        try:\n",
    "            # Tentar converter Tempo Apresenta√ß√£o para timedelta\n",
    "            df_validos['Tempo_Apresentacao_td'] = pd.to_timedelta(df_validos['Tempo Apresentacao'])\n",
    "            \n",
    "            # Comparar\n",
    "            diferenca = df_validos['Tempo_Calculado'] - df_validos['Tempo_Apresentacao_td']\n",
    "            \n",
    "            # Verificar se s√£o iguais (toler√¢ncia de 1 minuto)\n",
    "            corretos = (diferenca.abs() <= pd.Timedelta(minutes=1)).sum()\n",
    "            incorretos = len(df_validos) - corretos\n",
    "            \n",
    "            print(f\"‚úÖ Registros com c√°lculo CORRETO: {corretos:,}\")\n",
    "            print(f\"‚ùå Registros com c√°lculo INCORRETO: {incorretos:,}\")\n",
    "            print(f\"üìä Taxa de acerto: {corretos/len(df_validos)*100:.1f}%\")\n",
    "            \n",
    "            if incorretos > 0:\n",
    "                print(f\"\\nüîç EXEMPLOS DE C√ÅLCULOS INCORRETOS:\")\n",
    "                incorretos_mask = diferenca.abs() > pd.Timedelta(minutes=1)\n",
    "                exemplos = df_validos[incorretos_mask].head(3)\n",
    "                \n",
    "                for i, (idx, row) in enumerate(exemplos.iterrows(), 1):\n",
    "                    print(f\"   {i}. √çndice {idx}:\")\n",
    "                    print(f\"      Id_Leg: {row['Id_Leg']}\")\n",
    "                    print(f\"      Activity: {row['Activity']}\")\n",
    "                    print(f\"      Start: {row['Start']}\")\n",
    "                    print(f\"      Checkin: {row['Checkin']}\")\n",
    "                    print(f\"      Tempo Apresenta√ß√£o: {row['Tempo Apresentacao']}\")\n",
    "                    print(f\"      Tempo Calculado: {row['Tempo_Calculado']}\")\n",
    "                    print(f\"      Diferen√ßa: {diferenca.loc[idx]}\")\n",
    "                    print()\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erro ao processar timedelta: {e}\")\n",
    "            \n",
    "            # An√°lise mais simples - comparar strings\n",
    "            print(f\"\\nüîç AN√ÅLISE ALTERNATIVA (compara√ß√£o de strings):\")\n",
    "            \n",
    "            # Mostrar alguns exemplos para an√°lise manual\n",
    "            print(f\"üìã PRIMEIROS 5 REGISTROS PARA AN√ÅLISE MANUAL:\")\n",
    "            for i, (idx, row) in enumerate(df_validos.head().iterrows(), 1):\n",
    "                print(f\"   {i}. √çndice {idx}:\")\n",
    "                print(f\"      Start: {row['Start']} -> {row['Start_dt']}\")\n",
    "                print(f\"      Checkin: {row['Checkin']} -> {row['Checkin_dt']}\")\n",
    "                print(f\"      Tempo Apresenta√ß√£o: {row['Tempo Apresentacao']}\")\n",
    "                print(f\"      Tempo Calculado: {row['Tempo_Calculado']}\")\n",
    "                print()\n",
    "    \n",
    "    else:\n",
    "        print(\"‚ùå Nenhum registro com datas v√°lidas encontrado!\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Nenhum registro passou pelos filtros anteriores!\")\n",
    "\n",
    "# Resumo final\n",
    "print(f\"\\nüéØ RESUMO FINAL DA VERIFICA√á√ÉO:\")\n",
    "print(f\"   üìä Total de registros DF2: {len(df2):,}\")\n",
    "print(f\"   üìä Registros filtrados: {len(df2_tempo_apresentacao):,}\")\n",
    "if len(df2_tempo_apresentacao) > 0:\n",
    "    print(f\"   üìä Registros com datas v√°lidas: {len(df_validos) if 'df_validos' in locals() else 'N/A'}\")\n",
    "    if 'corretos' in locals():\n",
    "        print(f\"   ‚úÖ Registros com c√°lculo correto: {corretos:,}\")\n",
    "        print(f\"   ‚ùå Registros com c√°lculo incorreto: {incorretos:,}\")\n",
    "        print(f\"   üìä Taxa de acerto: {corretos/len(df_validos)*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nüíæ Vari√°veis criadas:\")\n",
    "print(f\"   - df2_tempo_apresentacao: {len(df2_tempo_apresentacao):,} registros\")\n",
    "if 'df_validos' in locals():\n",
    "    print(f\"   - df_validos: {len(df_validos):,} registros (com datas v√°lidas)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1b584b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ RESUMO CONSOLIDADO - AN√ÅLISE TEMPO APRESENTA√á√ÉO\n",
      "============================================================\n",
      "üìä RESULTADOS PRINCIPAIS:\n",
      "   üìã Total de registros no DF2: 2,541\n",
      "   üìã Registros que atendem aos crit√©rios: 43\n",
      "   üìã Percentual: 1.7%\n",
      "   üìã Registros com datas v√°lidas: 0\n",
      "\n",
      "üìã CRIT√âRIOS APLICADOS:\n",
      "   1. ‚úÖ Id_Leg termina com '-I' ou '-IF'\n",
      "   2. ‚úÖ Activity est√° na lista tipos_voo.json\n",
      "   3. ‚úÖ Verifica√ß√£o: Tempo Apresenta√ß√£o = Start - Checkin\n",
      "\n",
      "üìä BREAKDOWN POR CRIT√âRIO:\n",
      "   üîç Registros com Id_Leg (-I ou -IF): 1,858 (73.1%)\n",
      "   üîç Registros com Activity v√°lido: 43 (1.7%)\n",
      "\n",
      "üìà ESTAT√çSTICAS FINAIS:\n",
      "   üìä Id_Leg √∫nicos nos dados filtrados: 1\n",
      "   üìä Activity √∫nicos nos dados filtrados: 7\n",
      "   üìä Top 5 Activities filtrados:\n",
      "      - SFX: 27 registros\n",
      "      - APT: 8 registros\n",
      "      - S10: 4 registros\n",
      "      - S22: 1 registros\n",
      "      - S06: 1 registros\n",
      "   üìä Top 5 Id_Leg filtrados:\n",
      "      - -IF: 43 registros\n",
      "\n",
      "üîß VARI√ÅVEIS DISPON√çVEIS:\n",
      "   - df2: DataFrame original (2,541 registros)\n",
      "   - df2_tempo_apresentacao: DataFrame filtrado (43 registros)\n",
      "   - df_validos: DataFrame com datas v√°lidas (0 registros)\n",
      "\n",
      "‚úÖ AN√ÅLISE CONCLU√çDA!\n",
      "üí° Use as vari√°veis acima para an√°lises mais detalhadas.\n"
     ]
    }
   ],
   "source": [
    "# üéØ RESUMO CONSOLIDADO - AN√ÅLISE TEMPO APRESENTA√á√ÉO\n",
    "print(\"üéØ RESUMO CONSOLIDADO - AN√ÅLISE TEMPO APRESENTA√á√ÉO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Verificar se as vari√°veis existem\n",
    "if 'df2_tempo_apresentacao' in locals():\n",
    "    total_filtrados = len(df2_tempo_apresentacao)\n",
    "    total_original = len(df2)\n",
    "    \n",
    "    print(f\"üìä RESULTADOS PRINCIPAIS:\")\n",
    "    print(f\"   üìã Total de registros no DF2: {total_original:,}\")\n",
    "    print(f\"   üìã Registros que atendem aos crit√©rios: {total_filtrados:,}\")\n",
    "    print(f\"   üìã Percentual: {total_filtrados/total_original*100:.1f}%\")\n",
    "    \n",
    "    # Verificar se temos dados v√°lidos\n",
    "    if 'df_validos' in locals():\n",
    "        registros_validos = len(df_validos)\n",
    "        print(f\"   üìã Registros com datas v√°lidas: {registros_validos:,}\")\n",
    "        \n",
    "        if 'corretos' in locals():\n",
    "            print(f\"   ‚úÖ C√°lculos corretos: {corretos:,}\")\n",
    "            print(f\"   ‚ùå C√°lculos incorretos: {incorretos:,}\")\n",
    "            print(f\"   üìä Taxa de acerto: {corretos/registros_validos*100:.1f}%\")\n",
    "    \n",
    "    print(f\"\\nüìã CRIT√âRIOS APLICADOS:\")\n",
    "    print(f\"   1. ‚úÖ Id_Leg termina com '-I' ou '-IF'\")\n",
    "    print(f\"   2. ‚úÖ Activity est√° na lista tipos_voo.json\")\n",
    "    print(f\"   3. ‚úÖ Verifica√ß√£o: Tempo Apresenta√ß√£o = Start - Checkin\")\n",
    "    \n",
    "    # Mostrar breakdown por crit√©rio\n",
    "    if 'filtro_id_leg' in locals():\n",
    "        registros_id_leg = filtro_id_leg.sum()\n",
    "        print(f\"\\nüìä BREAKDOWN POR CRIT√âRIO:\")\n",
    "        print(f\"   üîç Registros com Id_Leg (-I ou -IF): {registros_id_leg:,} ({registros_id_leg/total_original*100:.1f}%)\")\n",
    "        \n",
    "    if 'filtro_activity' in locals():\n",
    "        registros_activity = filtro_activity.sum()\n",
    "        print(f\"   üîç Registros com Activity v√°lido: {registros_activity:,} ({registros_activity/total_original*100:.1f}%)\")\n",
    "    \n",
    "    # Estat√≠sticas finais\n",
    "    print(f\"\\nüìà ESTAT√çSTICAS FINAIS:\")\n",
    "    \n",
    "    if total_filtrados > 0:\n",
    "        # An√°lise dos dados filtrados\n",
    "        print(f\"   üìä Id_Leg √∫nicos nos dados filtrados: {df2_tempo_apresentacao['Id_Leg'].nunique()}\")\n",
    "        print(f\"   üìä Activity √∫nicos nos dados filtrados: {df2_tempo_apresentacao['Activity'].nunique()}\")\n",
    "        \n",
    "        # Top 5 Activities\n",
    "        top_activities = df2_tempo_apresentacao['Activity'].value_counts().head()\n",
    "        print(f\"   üìä Top 5 Activities filtrados:\")\n",
    "        for activity, count in top_activities.items():\n",
    "            print(f\"      - {activity}: {count:,} registros\")\n",
    "        \n",
    "        # Top 5 Id_Leg\n",
    "        top_id_leg = df2_tempo_apresentacao['Id_Leg'].value_counts().head()\n",
    "        print(f\"   üìä Top 5 Id_Leg filtrados:\")\n",
    "        for id_leg, count in top_id_leg.items():\n",
    "            print(f\"      - {id_leg}: {count:,} registros\")\n",
    "            \n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è Nenhum registro passou pelos filtros!\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå An√°lise n√£o foi executada. Execute as c√©lulas anteriores primeiro.\")\n",
    "\n",
    "print(f\"\\nüîß VARI√ÅVEIS DISPON√çVEIS:\")\n",
    "print(f\"   - df2: DataFrame original ({len(df2):,} registros)\")\n",
    "if 'df2_tempo_apresentacao' in locals():\n",
    "    print(f\"   - df2_tempo_apresentacao: DataFrame filtrado ({len(df2_tempo_apresentacao):,} registros)\")\n",
    "if 'df_validos' in locals():\n",
    "    print(f\"   - df_validos: DataFrame com datas v√°lidas ({len(df_validos):,} registros)\")\n",
    "\n",
    "print(f\"\\n‚úÖ AN√ÅLISE CONCLU√çDA!\")\n",
    "print(f\"üí° Use as vari√°veis acima para an√°lises mais detalhadas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c38f5d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öóÔ∏è AN√ÅLISE DA COLUNA TEMPO SOLO - DF2\n",
      "============================================================\n",
      "üìã Colunas necess√°rias: ['Id_Leg', 'Activity', 'Tempo Solo', 'Start', 'End']\n",
      "üìã Colunas existentes: ['Id_Leg', 'Activity', 'Tempo Solo', 'Start', 'End']\n",
      "‚úÖ Todas as colunas necess√°rias est√£o presentes!\n",
      "\n",
      "üîç CONDI√á√ïES PARA TEMPO SOLO:\n",
      "   1. Activity deve conter 'AD'\n",
      "   2. Id_Leg deve terminar com '-I' ou '-M'\n",
      "   3. Tempo Solo = Start(linha seguinte) - End(linha atual)\n",
      "\n",
      "üìä ESTAT√çSTICAS INICIAIS:\n",
      "   Total de registros: 2,541\n",
      "   Valores √∫nicos em Activity: 733\n",
      "   Valores √∫nicos em Id_Leg: 4\n",
      "   Registros com Activity = 'AD': 0\n",
      "   Registros com Id_Leg (-I ou -M): 683\n",
      "\n",
      "üìä REGISTROS FILTRADOS:\n",
      "   Registros que atendem AMBAS condi√ß√µes: 0\n",
      "   ‚ö†Ô∏è Nenhum registro atende √†s condi√ß√µes!\n",
      "\n",
      "üîç DIAGN√ìSTICO:\n",
      "   Activities √∫nicos:\n",
      "      - 'AD5046': 1 registros\n",
      "      - 'AD2852': 5 registros\n",
      "      - 'AD2898': 3 registros\n",
      "      - 'AD2899': 3 registros\n",
      "      - 'AD2433': 1 registros\n",
      "      - 'AD4446': 5 registros\n",
      "      - 'AD4441': 1 registros\n",
      "      - 'AD4150': 4 registros\n",
      "      - 'AD4151': 2 registros\n",
      "      - 'FR': 485 registros\n",
      "\n",
      "   Id_Leg √∫nicos (primeiros 10):\n",
      "      - '-I': 392 registros\n",
      "      - '-M': 291 registros\n",
      "      - '-F': 392 registros\n",
      "      - '-IF': 1,466 registros\n",
      "\n",
      "   Registros com Activity contendo 'AD': 1,180\n",
      "   Valores √∫nicos: ['AD5046' 'AD2852' 'AD2898' 'AD2899' 'AD2433' 'AD4446' 'AD4441' 'AD4150'\n",
      " 'AD4151' 'AD5215' 'AD4013' 'AD4282' 'AD5093' 'AD6902' 'AD6903' 'AD9087'\n",
      " 'AD5352' 'AD5353' 'AD5065' 'AD2518' 'AD4290' 'AD2769' 'AD2940' 'AD5127'\n",
      " 'AD4286' 'AD5028' 'AD4942' 'AD4990' 'AD4137' 'AD5388' 'AD5348' 'AD5029'\n",
      " 'AD2995' 'AD2724' 'AD6964' 'AD2786' 'AD2487' 'AD2538' 'AD4231' 'AD9021'\n",
      " 'AD4040' 'AD5162' 'AD4952' 'AD5728' 'AD2787' 'AD4096' 'AD5066' 'AD2840'\n",
      " 'AD2841' 'AD2800' 'AD2801' 'AD4113' 'AD2829' 'AD5244' 'AD5245' 'AD9161'\n",
      " 'AD9110' 'AD4487' 'AD9288' 'AD4433' 'AD4233' 'AD4021' 'AD4260' 'AD4261'\n",
      " 'AD4474' 'AD4252' 'AD4288' 'AD4148' 'AD4149' 'AD2498' 'AD2499' 'AD2669'\n",
      " 'AD2749' 'AD4496' 'AD2741' 'AD9157' 'AD4289' 'AD4005' 'AD4048' 'AD2468'\n",
      " 'AD5756' 'AD2890' 'AD2891' 'AD4204' 'AD6962' 'AD2434' 'AD5257' 'AD4092'\n",
      " 'AD4408' 'AD4409' 'AD4008' 'AD4055' 'AD4063' 'AD4059' 'AD4361' 'AD4203'\n",
      " 'AD9126' 'AD2934' 'AD5703' 'AD4031' 'AD4403' 'AD2500' 'AD2503' 'AD2576'\n",
      " 'AD2577' 'AD4154' 'AD2709' 'AD5749' 'AD5364' 'AD4964' 'AD4195' 'AD5136'\n",
      " 'AD5282' 'AD5283' 'AD4450' 'AD4107' 'AD4166' 'AD4167' 'AD5168' 'AD5169'\n",
      " 'AD5016' 'AD9640' 'AD4082' 'AD4432' 'AD5210' 'AD5211' 'AD6418' 'AD4489'\n",
      " 'AD4179' 'AD4493' 'AD5024' 'AD4016' 'AD5052' 'AD2610' 'AD2611' 'AD2866'\n",
      " 'AD4249' 'AD5500' 'AD2688' 'AD2837' 'AD5187' 'AD2520' 'AD4177' 'AD2543'\n",
      " 'AD4007' 'AD5188' 'AD5189' 'AD4346' 'AD4347' 'AD2621' 'AD2690' 'AD4284'\n",
      " 'AD6936' 'AD4987' 'AD4293' 'AD5226' 'AD5227' 'AD4083' 'AD4163' 'AD6419'\n",
      " 'AD4103' 'AD9128' 'AD9129' 'AD4079' 'AD6956' 'AD9643' 'AD4044' 'AD4175'\n",
      " 'AD4490' 'AD5158' 'AD9058' 'AD9059' 'AD6991' 'AD5166' 'AD6928' 'AD9068'\n",
      " 'AD9096' 'AD4011' 'AD9106' 'AD9105' 'AD4018' 'AD4316' 'AD4000' 'AD2590'\n",
      " 'AD4295' 'AD4269' 'AD4090' 'AD4043' 'AD5200' 'AD2632' 'AD4251' 'AD5450'\n",
      " 'AD9134' 'AD5468' 'AD5801' 'AD2411' 'AD4469' 'AD2517' 'AD2602' 'AD2768'\n",
      " 'AD9206' 'AD4494' 'AD4477' 'AD4004' 'AD4028' 'AD2409' 'AD4405' 'AD6422'\n",
      " 'AD4986' 'AD4406' 'AD4407' 'AD5149' 'AD9646' 'AD12' 'AD5059' 'AD4253'\n",
      " 'AD9641' 'AD5280' 'AD2458' 'AD2978' 'AD4064' 'AD5137' 'AD4439' 'AD4080'\n",
      " 'AD5790' 'AD4236' 'AD2553' 'AD5071' 'AD6976' 'AD6977' 'AD4019' 'AD4146'\n",
      " 'AD2479' 'AD2445' 'AD5454' 'AD5467' 'AD2580' 'AD2989' 'AD4264' 'AD9801'\n",
      " 'AD9094' 'AD9095' 'AD2937' 'AD4298' 'AD4299' 'AD2933' 'AD5402' 'AD5403'\n",
      " 'AD5704' 'AD5709' 'AD4411' 'AD4412' 'AD4058' 'AD5107' 'AD4988' 'AD4989'\n",
      " 'AD5438' 'AD5439' 'AD4331' 'AD2475' 'AD4159' 'AD4110' 'AD2645' 'AD2665'\n",
      " 'AD4296' 'AD5123' 'AD2556' 'AD4877' 'AD4862' 'AD4869' 'AD4870' 'AD5114'\n",
      " 'AD4237' 'AD2953' 'AD5798' 'AD4859' 'AD4133' 'AD5201' 'AD4873' 'AD4876'\n",
      " 'AD4244' 'AD5175' 'AD4949' 'AD4036' 'AD2643' 'AD4871' 'AD4879' 'AD5808'\n",
      " 'AD2813' 'AD2406' 'AD4104' 'AD2781' 'AD4860' 'AD5312' 'AD5313' 'AD4864'\n",
      " 'AD5740' 'AD4359' 'AD5442' 'AD5435' 'AD2638' 'AD2772' 'AD4109' 'AD4470'\n",
      " 'AD4471' 'AD5100' 'AD5373' 'AD2883' 'AD5333' 'AD5108' 'AD4209' 'AD2565'\n",
      " 'AD4115' 'AD2456' 'AD4174' 'AD4171' 'AD4241' 'AD5011' 'AD2432' 'AD5346'\n",
      " 'AD2885' 'AD6944' 'AD5374' 'AD4138' 'AD4139' 'AD6973' 'AD6970' 'AD2612'\n",
      " 'AD6988' 'AD4191' 'AD5329' 'AD4121' 'AD5216' 'AD5217' 'AD5055' 'AD5042'\n",
      " 'AD2428' 'AD4427' 'AD6943' 'AD6407' 'AD4227' 'AD2444' 'AD2844' 'AD5005'\n",
      " 'AD2874' 'AD2875' 'AD5782' 'AD4378' 'AD4379' 'AD4491' 'AD4698' 'AD4599'\n",
      " 'AD4330' 'AD9251' 'AD4370' 'AD4572' 'AD4573' 'AD4568' 'AD4526' 'AD4527'\n",
      " 'AD4333' 'AD2005' 'AD2006' 'AD4396' 'AD4431' 'AD4562' 'AD4372' 'AD4373'\n",
      " 'AD4161' 'AD4329' 'AD9242' 'AD9243' 'AD4451' 'AD4170' 'AD4544' 'AD4545'\n",
      " 'AD4169' 'AD4383' 'AD4940' 'AD4319' 'AD4569' 'AD4472' 'AD4246' 'AD4817'\n",
      " 'AD4620' 'AD4201' 'AD9262' 'AD4605' 'AD4317' 'AD4106' 'AD4444' 'AD4445'\n",
      " 'AD4651' 'AD4100' 'AD4218' 'AD4463' 'AD4101' 'AD4348' 'AD4371' 'AD4725'\n",
      " 'AD4026' 'AD4927' 'AD9752' 'AD9286' 'AD9066' 'AD9067' 'AD4623' 'AD4522'\n",
      " 'AD4853' 'AD4854' 'AD4855' 'AD4856' 'AD4458' 'AD4014' 'AD4519' 'AD4828'\n",
      " 'AD4913' 'AD4340' 'AD4341' 'AD4995' 'AD4628' 'AD2448' 'AD4794' 'AD4914'\n",
      " 'AD4915' 'AD2551' 'AD4332' 'AD4438' 'AD4429' 'AD4565' 'AD4564' 'AD4483'\n",
      " 'AD4903' 'AD4309' 'AD4153' 'AD4515' 'AD4574' 'AD4447' 'AD4338' 'AD4537'\n",
      " 'AD4528' 'AD4529' 'AD4232' 'AD4619' 'AD4769' 'AD4422' 'AD4423' 'AD4337'\n",
      " 'AD4943' 'AD4250' 'AD4145' 'AD4108' 'AD4234' 'AD4075' 'AD4577' 'AD4543'\n",
      " 'EAD' 'AD4888' 'AD2757' 'AD4524' 'AD4219' 'AD4850' 'AD2400' 'AD2401'\n",
      " 'AD2713' 'AD2810' 'AD4682' 'AD4567' 'AD4554' 'AD4555' 'AD4047' 'AD4508'\n",
      " 'AD4761' 'AD4590' 'AD2483' 'AD2491' 'AD5041' 'AD4866' 'AD4867' 'AD4846'\n",
      " 'AD2608' 'AD4776' 'AD4132' 'AD4140' 'AD4349' 'AD4498' 'AD4336' 'AD2886'\n",
      " 'AD2945' 'AD4303' 'AD2751' 'AD2738' 'AD4917' 'AD4239' 'AD2983' 'AD4840'\n",
      " 'AD4230' 'AD4460' 'AD4210' 'AD4580' 'AD2654' 'AD2649' 'AD4160' 'AD2723'\n",
      " 'AD4352' 'AD4360' 'AD4268' 'AD4238' 'AD4518' 'AD9045' 'AD4342' 'AD4345'\n",
      " 'AD4339' 'AD2476' 'AD2402' 'AD2705' 'AD2954' 'AD4501' 'AD4323' 'AD4049'\n",
      " 'AD4328' 'AD2648' 'AD9807' 'AD2991' 'AD2917' 'AD4503' 'AD9118' 'AD2701'\n",
      " 'AD2578' 'AD2599' 'AD2619' 'AD2624' 'AD2640' 'AD4512' 'AD9103' 'AD4216'\n",
      " 'AD4823' 'AD4631' 'AD4208' 'AD4155' 'AD4248' 'AD2921' 'AD2785' 'AD2926'\n",
      " 'AD4824' 'AD2990' 'AD4087' 'AD2641' 'AD2656' 'AD2960' 'AD2416' 'AD4604'\n",
      " 'AD2652' 'AD4865' 'AD5086' 'AD2684' 'AD2920' 'AD4213' 'AD2697' 'AD4612'\n",
      " 'AD4395' 'AD2404' 'AD2560' 'AD4206' 'AD4283' 'AD4188' 'AD2720' 'AD4254'\n",
      " 'AD2653' 'AD4941' 'AD4789' 'AD4905' 'AD4906' 'AD4144' 'AD2773' 'AD2755'\n",
      " 'AD2629' 'AD4517' 'AD2594' 'AD2438' 'AD4459' 'AD5070' 'AD5056' 'AD4270'\n",
      " 'AD2449' 'AD4765' 'AD4763' 'AD2752' 'AD9089' 'AD9088' 'AD2408' 'AD2419'\n",
      " 'AD4363' 'AD4274' 'AD2655' 'AD4038' 'AD2888' 'AD4708' 'AD4057' 'AD2692'\n",
      " 'AD4805' 'AD2826' 'AD2827' 'AD2902' 'AD4649' 'AD4843' 'AD2744' 'AD4998'\n",
      " 'AD4350' 'AD4351' 'AD4930' 'AD4591' 'AD4039' 'AD4645' 'AD4235' 'AD4430'\n",
      " 'AD4852' 'AD4662' 'AD2797' 'AD2808' 'AD4617' 'AD4885' 'AD4089' 'AD4481'\n",
      " 'AD4479' 'AD4796' 'AD2830' 'AD4070' 'AD4281' 'AD4634' 'AD9503' 'AD2695'\n",
      " 'AD9802' 'AD4745' 'AD2636' 'AD2464' 'AD2465' 'AD4200' 'AD2754' 'AD4335'\n",
      " 'AD4308' 'AD2634' 'AD2863' 'AD2944' 'AD4667' 'AD4310' 'AD4301' 'AD4124'\n",
      " 'AD4125' 'AD4646' 'AD4478' 'AD5064' 'AD4684' 'AD2916' 'AD4751' 'AD4402'\n",
      " 'AD4355' 'AD4849' 'AD4045' 'AD2681' 'AD2326' 'AD2329' 'AD4726' 'AD4025'\n",
      " 'AD9002' 'AD2753' 'AD2948' 'AD4215' 'AD4996' 'AD5098' 'AD4847' 'AD4890'\n",
      " 'AD2987' 'AD4540' 'AD4066']\n",
      "\n",
      "üíæ Vari√°vel criada: df2_tempo_solo (0 registros)\n"
     ]
    }
   ],
   "source": [
    "# ‚öóÔ∏è AN√ÅLISE DA COLUNA TEMPO SOLO - DF2\n",
    "print(\"‚öóÔ∏è AN√ÅLISE DA COLUNA TEMPO SOLO - DF2\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Verificar se as colunas necess√°rias existem\n",
    "colunas_necessarias_solo = ['Id_Leg', 'Activity', 'Tempo Solo', 'Start', 'End']\n",
    "colunas_existentes_solo = [col for col in colunas_necessarias_solo if col in df2.columns]\n",
    "\n",
    "print(f\"üìã Colunas necess√°rias: {colunas_necessarias_solo}\")\n",
    "print(f\"üìã Colunas existentes: {colunas_existentes_solo}\")\n",
    "\n",
    "if len(colunas_existentes_solo) == len(colunas_necessarias_solo):\n",
    "    print(\"‚úÖ Todas as colunas necess√°rias est√£o presentes!\")\n",
    "    \n",
    "    print(f\"\\nüîç CONDI√á√ïES PARA TEMPO SOLO:\")\n",
    "    print(f\"   1. Activity deve conter 'AD'\")\n",
    "    print(f\"   2. Id_Leg deve terminar com '-I' ou '-M'\")\n",
    "    print(f\"   3. Tempo Solo = Start(linha seguinte) - End(linha atual)\")\n",
    "    \n",
    "    # Estat√≠sticas iniciais\n",
    "    print(f\"\\nüìä ESTAT√çSTICAS INICIAIS:\")\n",
    "    print(f\"   Total de registros: {len(df2):,}\")\n",
    "    print(f\"   Valores √∫nicos em Activity: {df2['Activity'].nunique()}\")\n",
    "    print(f\"   Valores √∫nicos em Id_Leg: {df2['Id_Leg'].nunique()}\")\n",
    "    \n",
    "    # Verificar se h√° registros com Activity = 'AD'\n",
    "    activity_ad = df2[df2['Activity'] == 'AD']\n",
    "    print(f\"   Registros com Activity = 'AD': {len(activity_ad):,}\")\n",
    "    \n",
    "    # Verificar se h√° registros com Id_Leg terminando em -I ou -M\n",
    "    id_leg_filtro = df2['Id_Leg'].str.endswith(('-I', '-M'))\n",
    "    id_leg_validos = df2[id_leg_filtro]\n",
    "    print(f\"   Registros com Id_Leg (-I ou -M): {len(id_leg_validos):,}\")\n",
    "    \n",
    "    # Aplicar filtros combinados\n",
    "    filtro_tempo_solo = (df2['Activity'] == 'AD') & (df2['Id_Leg'].str.endswith(('-I', '-M')))\n",
    "    df2_tempo_solo = df2[filtro_tempo_solo]\n",
    "    \n",
    "    print(f\"\\nüìä REGISTROS FILTRADOS:\")\n",
    "    print(f\"   Registros que atendem AMBAS condi√ß√µes: {len(df2_tempo_solo):,}\")\n",
    "    \n",
    "    if len(df2_tempo_solo) > 0:\n",
    "        print(f\"   Percentual do total: {len(df2_tempo_solo)/len(df2)*100:.1f}%\")\n",
    "        \n",
    "        # Mostrar alguns exemplos\n",
    "        print(f\"\\nüìã PRIMEIROS 5 REGISTROS FILTRADOS:\")\n",
    "        for i, (idx, row) in enumerate(df2_tempo_solo.head().iterrows(), 1):\n",
    "            print(f\"   {i}. √çndice {idx}:\")\n",
    "            print(f\"      Activity: {row['Activity']}\")\n",
    "            print(f\"      Id_Leg: {row['Id_Leg']}\")\n",
    "            print(f\"      Tempo Solo: {row['Tempo Solo']}\")\n",
    "            print(f\"      Start: {row['Start']}\")\n",
    "            print(f\"      End: {row['End']}\")\n",
    "            print()\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è Nenhum registro atende √†s condi√ß√µes!\")\n",
    "        \n",
    "        # Diagn√≥stico detalhado\n",
    "        print(f\"\\nüîç DIAGN√ìSTICO:\")\n",
    "        print(f\"   Activities √∫nicos:\")\n",
    "        for activity in df2['Activity'].unique()[:10]:\n",
    "            count = (df2['Activity'] == activity).sum()\n",
    "            print(f\"      - '{activity}': {count:,} registros\")\n",
    "        \n",
    "        print(f\"\\n   Id_Leg √∫nicos (primeiros 10):\")\n",
    "        for id_leg in df2['Id_Leg'].unique()[:10]:\n",
    "            count = (df2['Id_Leg'] == id_leg).sum()\n",
    "            print(f\"      - '{id_leg}': {count:,} registros\")\n",
    "            \n",
    "        # Verificar se h√° registros com Activity contendo 'AD'\n",
    "        activity_contem_ad = df2[df2['Activity'].str.contains('AD', na=False)]\n",
    "        print(f\"\\n   Registros com Activity contendo 'AD': {len(activity_contem_ad):,}\")\n",
    "        if len(activity_contem_ad) > 0:\n",
    "            print(f\"   Valores √∫nicos: {activity_contem_ad['Activity'].unique()}\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Algumas colunas necess√°rias n√£o foram encontradas!\")\n",
    "    print(f\"   Faltam: {set(colunas_necessarias_solo) - set(colunas_existentes_solo)}\")\n",
    "    print(f\"\\nüìã Colunas dispon√≠veis no DF2:\")\n",
    "    for col in sorted(df2.columns):\n",
    "        print(f\"   - {col}\")\n",
    "\n",
    "print(f\"\\nüíæ Vari√°vel criada: df2_tempo_solo ({len(df2_tempo_solo) if 'df2_tempo_solo' in locals() else 0} registros)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1862edca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç VERIFICA√á√ÉO DO C√ÅLCULO TEMPO SOLO\n",
      "============================================================\n",
      "‚ùå Nenhum registro passou pelos filtros anteriores!\n",
      "üí° Execute primeiro a c√©lula anterior para filtrar os dados.\n",
      "\n",
      "üéØ RESUMO:\n",
      "   üìä Registros filtrados: 0\n"
     ]
    }
   ],
   "source": [
    "# üîç VERIFICA√á√ÉO DO C√ÅLCULO TEMPO SOLO\n",
    "print(\"üîç VERIFICA√á√ÉO DO C√ÅLCULO TEMPO SOLO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if 'df2_tempo_solo' in locals() and len(df2_tempo_solo) > 0:\n",
    "    print(f\"üìä Verificando {len(df2_tempo_solo):,} registros filtrados...\")\n",
    "    \n",
    "    # Criar c√≥pia para an√°lise\n",
    "    df_solo_analise = df2_tempo_solo.copy()\n",
    "    \n",
    "    # Ordenar por √≠ndice para garantir ordem sequencial\n",
    "    df_solo_analise = df_solo_analise.sort_index()\n",
    "    \n",
    "    # Fun√ß√£o para converter datetime\n",
    "    def converter_datetime_br(serie):\n",
    "        \"\"\"Converte string datetime para datetime object com formato brasileiro\"\"\"\n",
    "        if serie.dtype == 'object':\n",
    "            try:\n",
    "                return pd.to_datetime(serie, format='%d/%m/%Y %H:%M', errors='coerce')\n",
    "            except:\n",
    "                try:\n",
    "                    return pd.to_datetime(serie, dayfirst=True, errors='coerce')\n",
    "                except:\n",
    "                    return serie\n",
    "        return serie\n",
    "    \n",
    "    # Converter colunas de data\n",
    "    print(\"üîÑ Convertendo datas...\")\n",
    "    df_solo_analise['Start_dt'] = converter_datetime_br(df_solo_analise['Start'])\n",
    "    df_solo_analise['End_dt'] = converter_datetime_br(df_solo_analise['End'])\n",
    "    \n",
    "    # Verificar convers√µes\n",
    "    start_nulos = df_solo_analise['Start_dt'].isna().sum()\n",
    "    end_nulos = df_solo_analise['End_dt'].isna().sum()\n",
    "    \n",
    "    print(f\"   üìä Start convertidos: {len(df_solo_analise) - start_nulos:,}/{len(df_solo_analise):,}\")\n",
    "    print(f\"   üìä End convertidos: {len(df_solo_analise) - end_nulos:,}/{len(df_solo_analise):,}\")\n",
    "    \n",
    "    # Calcular Tempo Solo: Start(linha seguinte) - End(linha atual)\n",
    "    print(f\"\\n‚öóÔ∏è CALCULANDO TEMPO SOLO:\")\n",
    "    print(f\"   F√≥rmula: Start(linha seguinte) - End(linha atual)\")\n",
    "    \n",
    "    # Criar colunas com valores da linha seguinte\n",
    "    df_solo_analise['Start_proxima_linha'] = df_solo_analise['Start_dt'].shift(-1)\n",
    "    df_solo_analise['Start_proxima_str'] = df_solo_analise['Start'].shift(-1)\n",
    "    \n",
    "    # Calcular tempo solo\n",
    "    df_solo_analise['Tempo_Solo_Calculado'] = df_solo_analise['Start_proxima_linha'] - df_solo_analise['End_dt']\n",
    "    \n",
    "    # Remover √∫ltima linha (n√£o tem linha seguinte)\n",
    "    df_solo_valido = df_solo_analise[:-1].copy()\n",
    "    \n",
    "    print(f\"   üìä Registros v√°lidos para c√°lculo: {len(df_solo_valido):,}\")\n",
    "    \n",
    "    if len(df_solo_valido) > 0:\n",
    "        # Mostrar alguns exemplos\n",
    "        print(f\"\\nüìã EXEMPLOS DE C√ÅLCULO:\")\n",
    "        for i, (idx, row) in enumerate(df_solo_valido.head(5).iterrows(), 1):\n",
    "            print(f\"   {i}. √çndice {idx}:\")\n",
    "            print(f\"      Activity: {row['Activity']}\")\n",
    "            print(f\"      Id_Leg: {row['Id_Leg']}\")\n",
    "            print(f\"      End (atual): {row['End']}\")\n",
    "            print(f\"      Start (pr√≥xima): {row['Start_proxima_str']}\")\n",
    "            print(f\"      Tempo Solo (original): {row['Tempo Solo']}\")\n",
    "            print(f\"      Tempo Solo (calculado): {row['Tempo_Solo_Calculado']}\")\n",
    "            print()\n",
    "        \n",
    "        # Comparar valores\n",
    "        print(f\"üîç COMPARA√á√ÉO DOS VALORES:\")\n",
    "        try:\n",
    "            # Tentar converter Tempo Solo original para timedelta\n",
    "            df_solo_valido['Tempo_Solo_td'] = pd.to_timedelta(df_solo_valido['Tempo Solo'])\n",
    "            \n",
    "            # Calcular diferen√ßa\n",
    "            diferenca = df_solo_valido['Tempo_Solo_Calculado'] - df_solo_valido['Tempo_Solo_td']\n",
    "            \n",
    "            # Contar corretos (toler√¢ncia de 1 minuto)\n",
    "            tolerancia = pd.Timedelta(minutes=1)\n",
    "            corretos = (diferenca.abs() <= tolerancia).sum()\n",
    "            incorretos = len(df_solo_valido) - corretos\n",
    "            \n",
    "            print(f\"   ‚úÖ Registros com c√°lculo CORRETO: {corretos:,}\")\n",
    "            print(f\"   ‚ùå Registros com c√°lculo INCORRETO: {incorretos:,}\")\n",
    "            print(f\"   üìä Taxa de acerto: {corretos/len(df_solo_valido)*100:.1f}%\")\n",
    "            \n",
    "            if incorretos > 0:\n",
    "                print(f\"\\nüîç EXEMPLOS DE C√ÅLCULOS INCORRETOS:\")\n",
    "                incorretos_mask = diferenca.abs() > tolerancia\n",
    "                exemplos_incorretos = df_solo_valido[incorretos_mask].head(3)\n",
    "                \n",
    "                for i, (idx, row) in enumerate(exemplos_incorretos.iterrows(), 1):\n",
    "                    print(f\"   {i}. √çndice {idx}:\")\n",
    "                    print(f\"      End: {row['End']}\")\n",
    "                    print(f\"      Start pr√≥xima: {row['Start_proxima_str']}\")\n",
    "                    print(f\"      Tempo Solo original: {row['Tempo Solo']}\")\n",
    "                    print(f\"      Tempo Solo calculado: {row['Tempo_Solo_Calculado']}\")\n",
    "                    print(f\"      Diferen√ßa: {diferenca.loc[idx]}\")\n",
    "                    print()\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erro ao processar timedelta: {e}\")\n",
    "            \n",
    "            # An√°lise alternativa - comparar strings\n",
    "            print(f\"\\nüîç AN√ÅLISE ALTERNATIVA:\")\n",
    "            print(f\"   Comparando formato string dos primeiros registros:\")\n",
    "            \n",
    "            for i, (idx, row) in enumerate(df_solo_valido.head(3).iterrows(), 1):\n",
    "                print(f\"   {i}. √çndice {idx}:\")\n",
    "                print(f\"      Tempo Solo original: '{row['Tempo Solo']}'\")\n",
    "                print(f\"      Tempo Solo calculado: '{row['Tempo_Solo_Calculado']}'\")\n",
    "                print(f\"      S√£o iguais: {str(row['Tempo Solo']) == str(row['Tempo_Solo_Calculado'])}\")\n",
    "                print()\n",
    "        \n",
    "        # Salvar resultado\n",
    "        df2_tempo_solo_verificado = df_solo_valido\n",
    "        print(f\"\\nüíæ Resultado salvo em 'df2_tempo_solo_verificado': {len(df2_tempo_solo_verificado):,} registros\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå Nenhum registro v√°lido para c√°lculo!\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Nenhum registro passou pelos filtros anteriores!\")\n",
    "    print(\"üí° Execute primeiro a c√©lula anterior para filtrar os dados.\")\n",
    "\n",
    "print(f\"\\nüéØ RESUMO:\")\n",
    "if 'df2_tempo_solo' in locals():\n",
    "    print(f\"   üìä Registros filtrados: {len(df2_tempo_solo):,}\")\n",
    "    if 'df_solo_valido' in locals():\n",
    "        print(f\"   üìä Registros v√°lidos para c√°lculo: {len(df_solo_valido):,}\")\n",
    "        if 'corretos' in locals():\n",
    "            print(f\"   ‚úÖ C√°lculos corretos: {corretos:,}\")\n",
    "            print(f\"   ‚ùå C√°lculos incorretos: {incorretos:,}\")\n",
    "            print(f\"   üìä Taxa de acerto: {corretos/len(df_solo_valido)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0219c142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç INVESTIGA√á√ÉO DETALHADA - ACTIVITY E ID_LEG\n",
      "============================================================\n",
      "üìä AN√ÅLISE COMPLETA DOS VALORES:\n",
      "\n",
      "üìã VALORES √öNICOS EM ACTIVITY:\n",
      "   Total de valores √∫nicos: 733\n",
      "    1. 'FR': 485 registros\n",
      "    2. 'FER': 180 registros\n",
      "    3. 'SNA': 178 registros\n",
      "    4. 'F': 147 registros\n",
      "    5. 'EAD': 33 registros\n",
      "    6. 'SFX': 27 registros\n",
      "    7. 'DOP': 26 registros\n",
      "    8. 'FP': 25 registros\n",
      "    9. 'BUS': 25 registros\n",
      "   10. 'PP1': 23 registros\n",
      "   11. 'DMI': 20 registros\n",
      "   12. 'RES': 19 registros\n",
      "   13. 'PP2': 18 registros\n",
      "   14. 'PLT': 16 registros\n",
      "   15. 'FJC24': 13 registros\n",
      "   16. 'DMI24': 12 registros\n",
      "   17. 'CMA': 11 registros\n",
      "   18. 'AD4914': 9 registros\n",
      "   19. 'AD4915': 9 registros\n",
      "   20. 'REX': 9 registros\n",
      "\n",
      "üîç VALORES DE ACTIVITY QUE CONT√äM 'AD':\n",
      "   - 'EAD': 33 registros\n",
      "   - 'AD4915': 9 registros\n",
      "   - 'AD4914': 9 registros\n",
      "   - 'AD4942': 7 registros\n",
      "   - 'AD5024': 7 registros\n",
      "   - 'AD4079': 6 registros\n",
      "   - 'AD4149': 6 registros\n",
      "   - 'AD2926': 6 registros\n",
      "   - 'AD5450': 6 registros\n",
      "   - 'AD4080': 6 registros\n",
      "   - 'AD4840': 6 registros\n",
      "   - 'AD2852': 5 registros\n",
      "   - 'AD4568': 5 registros\n",
      "   - 'AD4446': 5 registros\n",
      "   - 'AD2498': 5 registros\n",
      "   - 'AD2643': 5 registros\n",
      "   - 'AD4572': 5 registros\n",
      "   - 'AD4204': 5 registros\n",
      "   - 'AD5093': 5 registros\n",
      "   - 'AD4361': 5 registros\n",
      "   - 'AD2723': 5 registros\n",
      "   - 'AD4028': 4 registros\n",
      "   - 'AD4057': 4 registros\n",
      "   - 'AD5728': 4 registros\n",
      "   - 'AD4350': 4 registros\n",
      "   - 'AD2953': 4 registros\n",
      "   - 'AD4150': 4 registros\n",
      "   - 'AD4433': 4 registros\n",
      "   - 'AD5215': 4 registros\n",
      "   - 'AD2990': 4 registros\n",
      "   - 'AD4379': 4 registros\n",
      "   - 'AD4698': 4 registros\n",
      "   - 'AD2499': 4 registros\n",
      "   - 'AD4853': 4 registros\n",
      "   - 'AD4769': 4 registros\n",
      "   - 'AD4474': 4 registros\n",
      "   - 'AD4250': 4 registros\n",
      "   - 'AD2520': 4 registros\n",
      "   - 'AD2883': 4 registros\n",
      "   - 'AD4850': 4 registros\n",
      "   - 'AD2810': 4 registros\n",
      "   - 'AD4148': 4 registros\n",
      "   - 'AD5041': 4 registros\n",
      "   - 'AD4239': 4 registros\n",
      "   - 'AD4347': 4 registros\n",
      "   - 'AD4004': 4 registros\n",
      "   - 'AD5749': 4 registros\n",
      "   - 'AD2983': 4 registros\n",
      "   - 'AD5158': 4 registros\n",
      "   - 'AD2705': 4 registros\n",
      "   - 'AD2741': 4 registros\n",
      "   - 'AD2917': 4 registros\n",
      "   - 'AD2921': 4 registros\n",
      "   - 'AD5280': 4 registros\n",
      "   - 'AD2898': 3 registros\n",
      "   - 'AD2899': 3 registros\n",
      "   - 'AD2432': 3 registros\n",
      "   - 'AD2503': 3 registros\n",
      "   - 'AD4316': 3 registros\n",
      "   - 'AD5500': 3 registros\n",
      "   - 'AD9087': 3 registros\n",
      "   - 'AD4432': 3 registros\n",
      "   - 'AD4876': 3 registros\n",
      "   - 'AD4109': 3 registros\n",
      "   - 'AD4064': 3 registros\n",
      "   - 'AD2688': 3 registros\n",
      "   - 'AD4171': 3 registros\n",
      "   - 'AD4490': 3 registros\n",
      "   - 'AD2487': 3 registros\n",
      "   - 'AD4231': 3 registros\n",
      "   - 'AD6422': 3 registros\n",
      "   - 'AD4036': 3 registros\n",
      "   - 'AD2787': 3 registros\n",
      "   - 'AD2829': 3 registros\n",
      "   - 'AD5703': 3 registros\n",
      "   - 'AD4031': 3 registros\n",
      "   - 'AD4431': 3 registros\n",
      "   - 'AD4145': 3 registros\n",
      "   - 'AD4577': 3 registros\n",
      "   - 'AD4103': 3 registros\n",
      "   - 'AD4219': 3 registros\n",
      "   - 'AD4372': 3 registros\n",
      "   - 'AD4472': 3 registros\n",
      "   - 'AD4201': 3 registros\n",
      "   - 'AD4776': 3 registros\n",
      "   - 'AD4336': 3 registros\n",
      "   - 'AD2945': 3 registros\n",
      "   - 'AD4444': 3 registros\n",
      "   - 'AD4218': 3 registros\n",
      "   - 'AD4869': 3 registros\n",
      "   - 'AD4160': 3 registros\n",
      "   - 'AD2840': 3 registros\n",
      "   - 'AD4360': 3 registros\n",
      "   - 'AD4342': 3 registros\n",
      "   - 'AD4345': 3 registros\n",
      "   - 'AD4463': 3 registros\n",
      "   - 'AD4348': 3 registros\n",
      "   - 'AD4248': 3 registros\n",
      "   - 'AD4026': 3 registros\n",
      "   - 'AD4241': 3 registros\n",
      "   - 'AD4824': 3 registros\n",
      "   - 'AD4166': 3 registros\n",
      "   - 'AD4087': 3 registros\n",
      "   - 'AD2641': 3 registros\n",
      "   - 'AD4612': 3 registros\n",
      "   - 'AD4254': 3 registros\n",
      "   - 'AD4941': 3 registros\n",
      "   - 'AD4144': 3 registros\n",
      "   - 'AD5056': 3 registros\n",
      "   - 'AD4522': 3 registros\n",
      "   - 'AD4843': 3 registros\n",
      "   - 'AD2891': 3 registros\n",
      "   - 'AD4351': 3 registros\n",
      "   - 'AD4617': 3 registros\n",
      "   - 'AD4796': 3 registros\n",
      "   - 'AD2830': 3 registros\n",
      "   - 'AD4195': 2 registros\n",
      "   - 'AD5136': 2 registros\n",
      "   - 'AD5282': 2 registros\n",
      "   - 'AD5283': 2 registros\n",
      "   - 'AD4058': 2 registros\n",
      "   - 'AD5808': 2 registros\n",
      "   - 'AD4167': 2 registros\n",
      "   - 'AD5168': 2 registros\n",
      "   - 'AD5169': 2 registros\n",
      "   - 'AD5016': 2 registros\n",
      "   - 'AD9640': 2 registros\n",
      "   - 'AD2885': 2 registros\n",
      "   - 'AD2479': 2 registros\n",
      "   - 'AD4251': 2 registros\n",
      "   - 'AD5373': 2 registros\n",
      "   - 'AD4016': 2 registros\n",
      "   - 'AD5052': 2 registros\n",
      "   - 'AD6407': 2 registros\n",
      "   - 'AD4469': 2 registros\n",
      "   - 'AD4151': 2 registros\n",
      "   - 'AD4330': 2 registros\n",
      "   - 'AD5201': 2 registros\n",
      "   - 'AD4174': 2 registros\n",
      "   - 'AD4527': 2 registros\n",
      "   - 'AD4333': 2 registros\n",
      "   - 'AD5352': 2 registros\n",
      "   - 'AD4562': 2 registros\n",
      "   - 'AD5353': 2 registros\n",
      "   - 'AD4161': 2 registros\n",
      "   - 'AD4329': 2 registros\n",
      "   - 'AD4451': 2 registros\n",
      "   - 'AD4545': 2 registros\n",
      "   - 'AD4383': 2 registros\n",
      "   - 'AD4569': 2 registros\n",
      "   - 'AD2768': 2 registros\n",
      "   - 'AD4620': 2 registros\n",
      "   - 'AD4177': 2 registros\n",
      "   - 'AD4605': 2 registros\n",
      "   - 'AD4007': 2 registros\n",
      "   - 'AD4445': 2 registros\n",
      "   - 'AD4286': 2 registros\n",
      "   - 'AD5188': 2 registros\n",
      "   - 'AD4990': 2 registros\n",
      "   - 'AD5189': 2 registros\n",
      "   - 'AD2690': 2 registros\n",
      "   - 'AD2409': 2 registros\n",
      "   - 'AD4519': 2 registros\n",
      "   - 'AD4340': 2 registros\n",
      "   - 'AD4341': 2 registros\n",
      "   - 'AD4995': 2 registros\n",
      "   - 'AD4628': 2 registros\n",
      "   - 'AD4864': 2 registros\n",
      "   - 'AD4293': 2 registros\n",
      "   - 'AD4332': 2 registros\n",
      "   - 'AD4565': 2 registros\n",
      "   - 'AD4574': 2 registros\n",
      "   - 'AD4338': 2 registros\n",
      "   - 'AD4986': 2 registros\n",
      "   - 'AD4422': 2 registros\n",
      "   - 'AD4423': 2 registros\n",
      "   - 'AD4337': 2 registros\n",
      "   - 'AD4096': 2 registros\n",
      "   - 'AD5066': 2 registros\n",
      "   - 'AD4234': 2 registros\n",
      "   - 'AD2841': 2 registros\n",
      "   - 'AD5149': 2 registros\n",
      "   - 'AD9646': 2 registros\n",
      "   - 'AD4877': 2 registros\n",
      "   - 'AD2401': 2 registros\n",
      "   - 'AD5059': 2 registros\n",
      "   - 'AD4554': 2 registros\n",
      "   - 'AD4555': 2 registros\n",
      "   - 'AD4508': 2 registros\n",
      "   - 'AD4761': 2 registros\n",
      "   - 'AD2483': 2 registros\n",
      "   - 'AD2491': 2 registros\n",
      "   - 'AD9110': 2 registros\n",
      "   - 'AD4487': 2 registros\n",
      "   - 'AD4498': 2 registros\n",
      "   - 'AD4253': 2 registros\n",
      "   - 'AD2886': 2 registros\n",
      "   - 'AD4233': 2 registros\n",
      "   - 'AD4303': 2 registros\n",
      "   - 'AD2751': 2 registros\n",
      "   - 'AD4917': 2 registros\n",
      "   - 'AD4044': 2 registros\n",
      "   - 'AD4260': 2 registros\n",
      "   - 'AD4261': 2 registros\n",
      "   - 'AD2649': 2 registros\n",
      "   - 'AD4252': 2 registros\n",
      "   - 'AD4175': 2 registros\n",
      "   - 'AD4871': 2 registros\n",
      "   - 'AD4518': 2 registros\n",
      "   - 'AD2749': 2 registros\n",
      "   - 'AD2458': 2 registros\n",
      "   - 'AD4339': 2 registros\n",
      "   - 'AD4005': 2 registros\n",
      "   - 'AD2954': 2 registros\n",
      "   - 'AD4501': 2 registros\n",
      "   - 'AD4049': 2 registros\n",
      "   - 'AD4328': 2 registros\n",
      "   - 'AD2991': 2 registros\n",
      "   - 'AD2978': 2 registros\n",
      "   - 'AD4503': 2 registros\n",
      "   - 'AD2619': 2 registros\n",
      "   - 'AD4512': 2 registros\n",
      "   - 'AD4216': 2 registros\n",
      "   - 'AD4823': 2 registros\n",
      "   - 'AD4631': 2 registros\n",
      "   - 'AD5166': 2 registros\n",
      "   - 'AD5756': 2 registros\n",
      "   - 'AD2785': 2 registros\n",
      "   - 'AD2890': 2 registros\n",
      "   - 'AD6962': 2 registros\n",
      "   - 'AD2434': 2 registros\n",
      "   - 'AD5257': 2 registros\n",
      "   - 'AD4092': 2 registros\n",
      "   - 'AD2684': 2 registros\n",
      "   - 'AD2697': 2 registros\n",
      "   - 'AD4408': 2 registros\n",
      "   - 'AD4395': 2 registros\n",
      "   - 'AD4206': 2 registros\n",
      "   - 'AD4409': 2 registros\n",
      "   - 'AD2653': 2 registros\n",
      "   - 'AD6928': 2 registros\n",
      "   - 'AD4789': 2 registros\n",
      "   - 'AD4905': 2 registros\n",
      "   - 'AD4906': 2 registros\n",
      "   - 'AD5137': 2 registros\n",
      "   - 'AD2773': 2 registros\n",
      "   - 'AD4459': 2 registros\n",
      "   - 'AD4011': 2 registros\n",
      "   - 'AD4765': 2 registros\n",
      "   - 'AD4708': 2 registros\n",
      "   - 'AD4439': 2 registros\n",
      "   - 'AD2692': 2 registros\n",
      "   - 'AD2826': 2 registros\n",
      "   - 'AD2827': 2 registros\n",
      "   - 'AD4403': 2 registros\n",
      "   - 'AD2500': 2 registros\n",
      "   - 'AD5704': 2 registros\n",
      "   - 'AD4591': 2 registros\n",
      "   - 'AD4852': 2 registros\n",
      "   - 'AD4154': 2 registros\n",
      "   - 'AD4479': 2 registros\n",
      "   - 'AD5709': 2 registros\n",
      "   - 'AD4411': 2 registros\n",
      "   - 'AD4634': 2 registros\n",
      "   - 'AD2944': 2 registros\n",
      "   - 'AD4684': 2 registros\n",
      "   - 'AD2916': 2 registros\n",
      "   - 'AD4996': 2 registros\n",
      "   - 'AD5402': 1 registros\n",
      "   - 'AD5403': 1 registros\n",
      "   - 'AD4412': 1 registros\n",
      "   - 'AD5107': 1 registros\n",
      "   - 'AD4988': 1 registros\n",
      "   - 'AD4989': 1 registros\n",
      "   - 'AD5438': 1 registros\n",
      "   - 'AD5439': 1 registros\n",
      "   - 'AD4331': 1 registros\n",
      "   - 'AD2475': 1 registros\n",
      "   - 'AD4159': 1 registros\n",
      "   - 'AD4110': 1 registros\n",
      "   - 'AD2645': 1 registros\n",
      "   - 'AD2665': 1 registros\n",
      "   - 'AD4296': 1 registros\n",
      "   - 'AD5123': 1 registros\n",
      "   - 'AD2556': 1 registros\n",
      "   - 'AD4862': 1 registros\n",
      "   - 'AD4870': 1 registros\n",
      "   - 'AD5114': 1 registros\n",
      "   - 'AD4237': 1 registros\n",
      "   - 'AD5798': 1 registros\n",
      "   - 'AD4859': 1 registros\n",
      "   - 'AD4133': 1 registros\n",
      "   - 'AD4873': 1 registros\n",
      "   - 'AD4244': 1 registros\n",
      "   - 'AD5175': 1 registros\n",
      "   - 'AD4949': 1 registros\n",
      "   - 'AD4879': 1 registros\n",
      "   - 'AD2813': 1 registros\n",
      "   - 'AD2406': 1 registros\n",
      "   - 'AD4104': 1 registros\n",
      "   - 'AD2781': 1 registros\n",
      "   - 'AD4860': 1 registros\n",
      "   - 'AD5312': 1 registros\n",
      "   - 'AD5313': 1 registros\n",
      "   - 'AD5740': 1 registros\n",
      "   - 'AD4359': 1 registros\n",
      "   - 'AD5442': 1 registros\n",
      "   - 'AD5435': 1 registros\n",
      "   - 'AD2638': 1 registros\n",
      "   - 'AD2772': 1 registros\n",
      "   - 'AD4470': 1 registros\n",
      "   - 'AD4471': 1 registros\n",
      "   - 'AD5100': 1 registros\n",
      "   - 'AD5333': 1 registros\n",
      "   - 'AD5108': 1 registros\n",
      "   - 'AD4209': 1 registros\n",
      "   - 'AD2565': 1 registros\n",
      "   - 'AD4115': 1 registros\n",
      "   - 'AD2456': 1 registros\n",
      "   - 'AD5011': 1 registros\n",
      "   - 'AD5346': 1 registros\n",
      "   - 'AD6944': 1 registros\n",
      "   - 'AD5374': 1 registros\n",
      "   - 'AD4138': 1 registros\n",
      "   - 'AD4139': 1 registros\n",
      "   - 'AD6973': 1 registros\n",
      "   - 'AD6970': 1 registros\n",
      "   - 'AD2612': 1 registros\n",
      "   - 'AD6988': 1 registros\n",
      "   - 'AD4191': 1 registros\n",
      "   - 'AD5329': 1 registros\n",
      "   - 'AD4121': 1 registros\n",
      "   - 'AD5216': 1 registros\n",
      "   - 'AD5217': 1 registros\n",
      "   - 'AD5055': 1 registros\n",
      "   - 'AD5042': 1 registros\n",
      "   - 'AD2428': 1 registros\n",
      "   - 'AD4427': 1 registros\n",
      "   - 'AD6943': 1 registros\n",
      "   - 'AD2433': 1 registros\n",
      "   - 'AD4227': 1 registros\n",
      "   - 'AD2444': 1 registros\n",
      "   - 'AD2844': 1 registros\n",
      "   - 'AD5005': 1 registros\n",
      "   - 'AD2874': 1 registros\n",
      "   - 'AD2875': 1 registros\n",
      "   - 'AD5782': 1 registros\n",
      "   - 'AD4378': 1 registros\n",
      "   - 'AD4441': 1 registros\n",
      "   - 'AD4491': 1 registros\n",
      "   - 'AD4013': 1 registros\n",
      "   - 'AD4599': 1 registros\n",
      "   - 'AD4282': 1 registros\n",
      "   - 'AD9251': 1 registros\n",
      "   - 'AD4370': 1 registros\n",
      "   - 'AD6902': 1 registros\n",
      "   - 'AD4573': 1 registros\n",
      "   - 'AD6903': 1 registros\n",
      "   - 'AD4526': 1 registros\n",
      "   - 'AD5065': 1 registros\n",
      "   - 'AD2518': 1 registros\n",
      "   - 'AD2005': 1 registros\n",
      "   - 'AD2006': 1 registros\n",
      "   - 'AD4396': 1 registros\n",
      "   - 'AD4290': 1 registros\n",
      "   - 'AD2769': 1 registros\n",
      "   - 'AD2940': 1 registros\n",
      "   - 'AD4373': 1 registros\n",
      "   - 'AD5127': 1 registros\n",
      "   - 'AD5028': 1 registros\n",
      "   - 'AD9242': 1 registros\n",
      "   - 'AD9243': 1 registros\n",
      "   - 'AD4137': 1 registros\n",
      "   - 'AD4170': 1 registros\n",
      "   - 'AD4544': 1 registros\n",
      "   - 'AD5388': 1 registros\n",
      "   - 'AD4169': 1 registros\n",
      "   - 'AD5348': 1 registros\n",
      "   - 'AD4940': 1 registros\n",
      "   - 'AD4319': 1 registros\n",
      "   - 'AD5029': 1 registros\n",
      "   - 'AD2995': 1 registros\n",
      "   - 'AD4246': 1 registros\n",
      "   - 'AD4817': 1 registros\n",
      "   - 'AD2724': 1 registros\n",
      "   - 'AD6964': 1 registros\n",
      "   - 'AD9262': 1 registros\n",
      "   - 'AD2786': 1 registros\n",
      "   - 'AD4317': 1 registros\n",
      "   - 'AD4106': 1 registros\n",
      "   - 'AD2538': 1 registros\n",
      "   - 'AD9021': 1 registros\n",
      "   - 'AD4651': 1 registros\n",
      "   - 'AD4100': 1 registros\n",
      "   - 'AD4040': 1 registros\n",
      "   - 'AD5162': 1 registros\n",
      "   - 'AD4101': 1 registros\n",
      "   - 'AD4952': 1 registros\n",
      "   - 'AD4371': 1 registros\n",
      "   - 'AD4725': 1 registros\n",
      "   - 'AD2800': 1 registros\n",
      "   - 'AD4927': 1 registros\n",
      "   - 'AD9752': 1 registros\n",
      "   - 'AD9286': 1 registros\n",
      "   - 'AD9066': 1 registros\n",
      "   - 'AD9067': 1 registros\n",
      "   - 'AD4623': 1 registros\n",
      "   - 'AD2801': 1 registros\n",
      "   - 'AD4113': 1 registros\n",
      "   - 'AD4854': 1 registros\n",
      "   - 'AD4855': 1 registros\n",
      "   - 'AD4856': 1 registros\n",
      "   - 'AD4458': 1 registros\n",
      "   - 'AD4014': 1 registros\n",
      "   - 'AD5244': 1 registros\n",
      "   - 'AD4828': 1 registros\n",
      "   - 'AD4913': 1 registros\n",
      "   - 'AD5245': 1 registros\n",
      "   - 'AD9161': 1 registros\n",
      "   - 'AD9288': 1 registros\n",
      "   - 'AD4021': 1 registros\n",
      "   - 'AD2448': 1 registros\n",
      "   - 'AD4794': 1 registros\n",
      "   - 'AD4288': 1 registros\n",
      "   - 'AD2669': 1 registros\n",
      "   - 'AD2551': 1 registros\n",
      "   - 'AD4496': 1 registros\n",
      "   - 'AD4438': 1 registros\n",
      "   - 'AD4429': 1 registros\n",
      "   - 'AD9157': 1 registros\n",
      "   - 'AD4564': 1 registros\n",
      "   - 'AD4483': 1 registros\n",
      "   - 'AD4903': 1 registros\n",
      "   - 'AD4309': 1 registros\n",
      "   - 'AD4153': 1 registros\n",
      "   - 'AD4515': 1 registros\n",
      "   - 'AD4289': 1 registros\n",
      "   - 'AD4447': 1 registros\n",
      "   - 'AD4048': 1 registros\n",
      "   - 'AD4537': 1 registros\n",
      "   - 'AD4528': 1 registros\n",
      "   - 'AD4529': 1 registros\n",
      "   - 'AD4232': 1 registros\n",
      "   - 'AD4619': 1 registros\n",
      "   - 'AD2468': 1 registros\n",
      "   - 'AD4008': 1 registros\n",
      "   - 'AD4055': 1 registros\n",
      "   - 'AD4063': 1 registros\n",
      "   - 'AD4943': 1 registros\n",
      "   - 'AD4059': 1 registros\n",
      "   - 'AD4203': 1 registros\n",
      "   - 'AD4108': 1 registros\n",
      "   - 'AD9126': 1 registros\n",
      "   - 'AD4075': 1 registros\n",
      "   - 'AD2934': 1 registros\n",
      "   - 'AD4543': 1 registros\n",
      "   - 'AD2576': 1 registros\n",
      "   - 'AD4888': 1 registros\n",
      "   - 'AD2757': 1 registros\n",
      "   - 'AD4524': 1 registros\n",
      "   - 'AD2577': 1 registros\n",
      "   - 'AD2709': 1 registros\n",
      "   - 'AD2400': 1 registros\n",
      "   - 'AD5364': 1 registros\n",
      "   - 'AD2713': 1 registros\n",
      "   - 'AD4964': 1 registros\n",
      "   - 'AD4682': 1 registros\n",
      "   - 'AD4567': 1 registros\n",
      "   - 'AD4450': 1 registros\n",
      "   - 'AD4107': 1 registros\n",
      "   - 'AD4047': 1 registros\n",
      "   - 'AD4082': 1 registros\n",
      "   - 'AD5210': 1 registros\n",
      "   - 'AD4590': 1 registros\n",
      "   - 'AD5211': 1 registros\n",
      "   - 'AD6418': 1 registros\n",
      "   - 'AD4489': 1 registros\n",
      "   - 'AD4866': 1 registros\n",
      "   - 'AD4867': 1 registros\n",
      "   - 'AD4846': 1 registros\n",
      "   - 'AD2608': 1 registros\n",
      "   - 'AD4179': 1 registros\n",
      "   - 'AD4132': 1 registros\n",
      "   - 'AD4140': 1 registros\n",
      "   - 'AD4349': 1 registros\n",
      "   - 'AD4493': 1 registros\n",
      "   - 'AD2610': 1 registros\n",
      "   - 'AD2611': 1 registros\n",
      "   - 'AD2866': 1 registros\n",
      "   - 'AD4249': 1 registros\n",
      "   - 'AD2837': 1 registros\n",
      "   - 'AD2738': 1 registros\n",
      "   - 'AD5187': 1 registros\n",
      "   - 'AD2543': 1 registros\n",
      "   - 'AD4346': 1 registros\n",
      "   - 'AD2621': 1 registros\n",
      "   - 'AD4230': 1 registros\n",
      "   - 'AD4460': 1 registros\n",
      "   - 'AD4210': 1 registros\n",
      "   - 'AD4580': 1 registros\n",
      "   - 'AD2654': 1 registros\n",
      "   - 'AD4284': 1 registros\n",
      "   - 'AD6936': 1 registros\n",
      "   - 'AD4987': 1 registros\n",
      "   - 'AD4352': 1 registros\n",
      "   - 'AD5226': 1 registros\n",
      "   - 'AD4268': 1 registros\n",
      "   - 'AD4238': 1 registros\n",
      "   - 'AD5227': 1 registros\n",
      "   - 'AD9045': 1 registros\n",
      "   - 'AD4083': 1 registros\n",
      "   - 'AD4163': 1 registros\n",
      "   - 'AD6419': 1 registros\n",
      "   - 'AD2476': 1 registros\n",
      "   - 'AD2402': 1 registros\n",
      "   - 'AD9128': 1 registros\n",
      "   - 'AD9129': 1 registros\n",
      "   - 'AD6956': 1 registros\n",
      "   - 'AD4323': 1 registros\n",
      "   - 'AD9643': 1 registros\n",
      "   - 'AD5046': 1 registros\n",
      "   - 'AD2648': 1 registros\n",
      "   - 'AD9807': 1 registros\n",
      "   - 'AD9058': 1 registros\n",
      "   - 'AD9059': 1 registros\n",
      "   - 'AD6991': 1 registros\n",
      "   - 'AD9118': 1 registros\n",
      "   - 'AD2701': 1 registros\n",
      "   - 'AD2578': 1 registros\n",
      "   - 'AD2599': 1 registros\n",
      "   - 'AD9068': 1 registros\n",
      "   - 'AD2624': 1 registros\n",
      "   - 'AD2640': 1 registros\n",
      "   - 'AD9096': 1 registros\n",
      "   - 'AD9103': 1 registros\n",
      "   - 'AD9106': 1 registros\n",
      "   - 'AD9105': 1 registros\n",
      "   - 'AD4018': 1 registros\n",
      "   - 'AD4208': 1 registros\n",
      "   - 'AD4155': 1 registros\n",
      "   - 'AD4000': 1 registros\n",
      "   - 'AD2590': 1 registros\n",
      "   - 'AD4295': 1 registros\n",
      "   - 'AD4269': 1 registros\n",
      "   - 'AD4090': 1 registros\n",
      "   - 'AD4043': 1 registros\n",
      "   - 'AD5200': 1 registros\n",
      "   - 'AD2632': 1 registros\n",
      "   - 'AD2656': 1 registros\n",
      "   - 'AD2960': 1 registros\n",
      "   - 'AD2416': 1 registros\n",
      "   - 'AD4604': 1 registros\n",
      "   - 'AD2652': 1 registros\n",
      "   - 'AD4865': 1 registros\n",
      "   - 'AD5086': 1 registros\n",
      "   - 'AD9134': 1 registros\n",
      "   - 'AD2920': 1 registros\n",
      "   - 'AD4213': 1 registros\n",
      "   - 'AD5468': 1 registros\n",
      "   - 'AD5801': 1 registros\n",
      "   - 'AD2411': 1 registros\n",
      "   - 'AD2404': 1 registros\n",
      "   - 'AD2560': 1 registros\n",
      "   - 'AD2517': 1 registros\n",
      "   - 'AD4283': 1 registros\n",
      "   - 'AD4188': 1 registros\n",
      "   - 'AD2720': 1 registros\n",
      "   - 'AD2602': 1 registros\n",
      "   - 'AD9206': 1 registros\n",
      "   - 'AD4494': 1 registros\n",
      "   - 'AD4477': 1 registros\n",
      "   - 'AD4405': 1 registros\n",
      "   - 'AD4406': 1 registros\n",
      "   - 'AD4407': 1 registros\n",
      "   - 'AD12': 1 registros\n",
      "   - 'AD2755': 1 registros\n",
      "   - 'AD2629': 1 registros\n",
      "   - 'AD4517': 1 registros\n",
      "   - 'AD2594': 1 registros\n",
      "   - 'AD2438': 1 registros\n",
      "   - 'AD9641': 1 registros\n",
      "   - 'AD5070': 1 registros\n",
      "   - 'AD5790': 1 registros\n",
      "   - 'AD4270': 1 registros\n",
      "   - 'AD2449': 1 registros\n",
      "   - 'AD4236': 1 registros\n",
      "   - 'AD4763': 1 registros\n",
      "   - 'AD2752': 1 registros\n",
      "   - 'AD9089': 1 registros\n",
      "   - 'AD9088': 1 registros\n",
      "   - 'AD2408': 1 registros\n",
      "   - 'AD2419': 1 registros\n",
      "   - 'AD4363': 1 registros\n",
      "   - 'AD4274': 1 registros\n",
      "   - 'AD2655': 1 registros\n",
      "   - 'AD4038': 1 registros\n",
      "   - 'AD2888': 1 registros\n",
      "   - 'AD2553': 1 registros\n",
      "   - 'AD5071': 1 registros\n",
      "   - 'AD6976': 1 registros\n",
      "   - 'AD4805': 1 registros\n",
      "   - 'AD6977': 1 registros\n",
      "   - 'AD4019': 1 registros\n",
      "   - 'AD2902': 1 registros\n",
      "   - 'AD4649': 1 registros\n",
      "   - 'AD4146': 1 registros\n",
      "   - 'AD2744': 1 registros\n",
      "   - 'AD4998': 1 registros\n",
      "   - 'AD2445': 1 registros\n",
      "   - 'AD5454': 1 registros\n",
      "   - 'AD4930': 1 registros\n",
      "   - 'AD5467': 1 registros\n",
      "   - 'AD4039': 1 registros\n",
      "   - 'AD4645': 1 registros\n",
      "   - 'AD4235': 1 registros\n",
      "   - 'AD4430': 1 registros\n",
      "   - 'AD2580': 1 registros\n",
      "   - 'AD4662': 1 registros\n",
      "   - 'AD2797': 1 registros\n",
      "   - 'AD2808': 1 registros\n",
      "   - 'AD2989': 1 registros\n",
      "   - 'AD4885': 1 registros\n",
      "   - 'AD4089': 1 registros\n",
      "   - 'AD4481': 1 registros\n",
      "   - 'AD4264': 1 registros\n",
      "   - 'AD9801': 1 registros\n",
      "   - 'AD9094': 1 registros\n",
      "   - 'AD4070': 1 registros\n",
      "   - 'AD4281': 1 registros\n",
      "   - 'AD9095': 1 registros\n",
      "   - 'AD9503': 1 registros\n",
      "   - 'AD2695': 1 registros\n",
      "   - 'AD9802': 1 registros\n",
      "   - 'AD4745': 1 registros\n",
      "   - 'AD2636': 1 registros\n",
      "   - 'AD2464': 1 registros\n",
      "   - 'AD2465': 1 registros\n",
      "   - 'AD4200': 1 registros\n",
      "   - 'AD2754': 1 registros\n",
      "   - 'AD4335': 1 registros\n",
      "   - 'AD4308': 1 registros\n",
      "   - 'AD2634': 1 registros\n",
      "   - 'AD2863': 1 registros\n",
      "   - 'AD2937': 1 registros\n",
      "   - 'AD4667': 1 registros\n",
      "   - 'AD4310': 1 registros\n",
      "   - 'AD4301': 1 registros\n",
      "   - 'AD4124': 1 registros\n",
      "   - 'AD4125': 1 registros\n",
      "   - 'AD4646': 1 registros\n",
      "   - 'AD4478': 1 registros\n",
      "   - 'AD5064': 1 registros\n",
      "   - 'AD4298': 1 registros\n",
      "   - 'AD4299': 1 registros\n",
      "   - 'AD4751': 1 registros\n",
      "   - 'AD4402': 1 registros\n",
      "   - 'AD4355': 1 registros\n",
      "   - 'AD4849': 1 registros\n",
      "   - 'AD4045': 1 registros\n",
      "   - 'AD2681': 1 registros\n",
      "   - 'AD2326': 1 registros\n",
      "   - 'AD2329': 1 registros\n",
      "   - 'AD4726': 1 registros\n",
      "   - 'AD4025': 1 registros\n",
      "   - 'AD9002': 1 registros\n",
      "   - 'AD2753': 1 registros\n",
      "   - 'AD2948': 1 registros\n",
      "   - 'AD4215': 1 registros\n",
      "   - 'AD2933': 1 registros\n",
      "   - 'AD5098': 1 registros\n",
      "   - 'AD4847': 1 registros\n",
      "   - 'AD4890': 1 registros\n",
      "   - 'AD2987': 1 registros\n",
      "   - 'AD4540': 1 registros\n",
      "   - 'AD4066': 1 registros\n",
      "\n",
      "üìã VALORES √öNICOS EM ID_LEG:\n",
      "   Total de valores √∫nicos: 4\n",
      "    1. '-IF': 1,466 registros\n",
      "    2. '-I': 392 registros\n",
      "    3. '-F': 392 registros\n",
      "    4. '-M': 291 registros\n",
      "\n",
      "üîç PADR√ïES EM ID_LEG:\n",
      "   Terminam com '-I': 392 registros\n",
      "   Terminam com '-M': 291 registros\n",
      "   Terminam com '-I' ou '-M': 683 registros\n",
      "\n",
      "üîç PADR√ïES ALTERNATIVOS:\n",
      "   Activities com n√∫meros: 1,252 registros\n",
      "      - 'PP1': 23\n",
      "      - 'PP2': 18\n",
      "      - 'FJC24': 13\n",
      "      - 'DMI24': 12\n",
      "      - 'AD4914': 9\n",
      "   Activities curtos (‚â§3 chars): 1,356 registros\n",
      "      - 'FR': 485\n",
      "      - 'FER': 180\n",
      "      - 'SNA': 178\n",
      "      - 'F': 147\n",
      "      - 'EAD': 33\n",
      "      - 'SFX': 27\n",
      "      - 'DOP': 26\n",
      "      - 'BUS': 25\n",
      "      - 'FP': 25\n",
      "      - 'PP1': 23\n",
      "\n",
      "üí° TESTE COM FILTROS ALTERNATIVOS:\n",
      "\n",
      "üìä VERIFICA√á√ÉO DA COLUNA TEMPO SOLO:\n",
      "   ‚úÖ Coluna 'Tempo Solo' existe\n",
      "   üìä Valores n√£o-nulos: 2,541\n",
      "   üìä Valores nulos: 0\n",
      "   üìä Valores √∫nicos: 142\n",
      "   üìã Exemplos de valores:\n",
      "      1. '0 days 00:46:00'\n",
      "      2. '0 days 00:31:00'\n",
      "      3. '0 days 00:30:00'\n",
      "      4. '0 days 00:00:00'\n",
      "      5. '0 days 00:00:00'\n",
      "\n",
      "üí° SUGEST√ïES:\n",
      "   1. Verificar se 'AD' √© o c√≥digo correto para Activity\n",
      "   2. Verificar se os c√≥digos Id_Leg est√£o no formato esperado\n",
      "   3. Considerar usar activities mais comuns para teste\n",
      "   4. Verificar documenta√ß√£o dos dados para c√≥digos corretos\n"
     ]
    }
   ],
   "source": [
    "# üîç INVESTIGA√á√ÉO DETALHADA - ACTIVITY E ID_LEG\n",
    "print(\"üîç INVESTIGA√á√ÉO DETALHADA - ACTIVITY E ID_LEG\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"üìä AN√ÅLISE COMPLETA DOS VALORES:\")\n",
    "\n",
    "# An√°lise detalhada de Activity\n",
    "print(f\"\\nüìã VALORES √öNICOS EM ACTIVITY:\")\n",
    "activity_counts = df2['Activity'].value_counts()\n",
    "print(f\"   Total de valores √∫nicos: {len(activity_counts)}\")\n",
    "\n",
    "for i, (activity, count) in enumerate(activity_counts.head(20).items(), 1):\n",
    "    print(f\"   {i:2d}. '{activity}': {count:,} registros\")\n",
    "\n",
    "# Verificar se h√° valores que cont√™m 'AD'\n",
    "print(f\"\\nüîç VALORES DE ACTIVITY QUE CONT√äM 'AD':\")\n",
    "activity_com_ad = df2[df2['Activity'].str.contains('AD', na=False, case=False)]\n",
    "if len(activity_com_ad) > 0:\n",
    "    activity_ad_counts = activity_com_ad['Activity'].value_counts()\n",
    "    for activity, count in activity_ad_counts.items():\n",
    "        print(f\"   - '{activity}': {count:,} registros\")\n",
    "else:\n",
    "    print(\"   ‚ùå Nenhum valor cont√©m 'AD'\")\n",
    "\n",
    "# An√°lise detalhada de Id_Leg\n",
    "print(f\"\\nüìã VALORES √öNICOS EM ID_LEG:\")\n",
    "id_leg_counts = df2['Id_Leg'].value_counts()\n",
    "print(f\"   Total de valores √∫nicos: {len(id_leg_counts)}\")\n",
    "\n",
    "for i, (id_leg, count) in enumerate(id_leg_counts.head(10).items(), 1):\n",
    "    print(f\"   {i:2d}. '{id_leg}': {count:,} registros\")\n",
    "\n",
    "# Verificar padr√µes em Id_Leg\n",
    "print(f\"\\nüîç PADR√ïES EM ID_LEG:\")\n",
    "id_leg_terminam_i = df2[df2['Id_Leg'].str.endswith('-I', na=False)]\n",
    "id_leg_terminam_m = df2[df2['Id_Leg'].str.endswith('-M', na=False)]\n",
    "id_leg_terminam_i_ou_m = df2[df2['Id_Leg'].str.endswith(('-I', '-M'), na=False)]\n",
    "\n",
    "print(f\"   Terminam com '-I': {len(id_leg_terminam_i):,} registros\")\n",
    "print(f\"   Terminam com '-M': {len(id_leg_terminam_m):,} registros\")\n",
    "print(f\"   Terminam com '-I' ou '-M': {len(id_leg_terminam_i_ou_m):,} registros\")\n",
    "\n",
    "# Buscar padr√µes alternativos\n",
    "print(f\"\\nüîç PADR√ïES ALTERNATIVOS:\")\n",
    "\n",
    "# Verificar se h√° activities com n√∫meros ou c√≥digos diferentes\n",
    "activities_com_numeros = df2[df2['Activity'].str.contains(r'\\d', na=False)]\n",
    "print(f\"   Activities com n√∫meros: {len(activities_com_numeros):,} registros\")\n",
    "if len(activities_com_numeros) > 0:\n",
    "    activities_num_unique = activities_com_numeros['Activity'].value_counts().head(5)\n",
    "    for activity, count in activities_num_unique.items():\n",
    "        print(f\"      - '{activity}': {count:,}\")\n",
    "\n",
    "# Verificar activities de 2-3 caracteres (podem ser c√≥digos)\n",
    "activities_curtos = df2[df2['Activity'].str.len() <= 3]\n",
    "print(f\"   Activities curtos (‚â§3 chars): {len(activities_curtos):,} registros\")\n",
    "if len(activities_curtos) > 0:\n",
    "    activities_curtos_unique = activities_curtos['Activity'].value_counts().head(10)\n",
    "    for activity, count in activities_curtos_unique.items():\n",
    "        print(f\"      - '{activity}': {count:,}\")\n",
    "\n",
    "# Criar filtro alternativo para testar\n",
    "print(f\"\\nüí° TESTE COM FILTROS ALTERNATIVOS:\")\n",
    "\n",
    "# Se n√£o h√° 'AD', vamos testar com activities mais comuns que podem representar voos\n",
    "activities_possiveis = ['FLT', 'VOO', 'FLIGHT', 'FL', 'VL']\n",
    "for test_activity in activities_possiveis:\n",
    "    test_count = (df2['Activity'] == test_activity).sum()\n",
    "    if test_count > 0:\n",
    "        print(f\"   Activity '{test_activity}': {test_count:,} registros\")\n",
    "        \n",
    "        # Testar combina√ß√£o com Id_Leg\n",
    "        test_combo = df2[(df2['Activity'] == test_activity) & \n",
    "                        (df2['Id_Leg'].str.endswith(('-I', '-M'), na=False))]\n",
    "        print(f\"      + Id_Leg (-I ou -M): {len(test_combo):,} registros\")\n",
    "\n",
    "# Verificar se existe coluna Tempo Solo\n",
    "print(f\"\\nüìä VERIFICA√á√ÉO DA COLUNA TEMPO SOLO:\")\n",
    "if 'Tempo Solo' in df2.columns:\n",
    "    tempo_solo_nulos = df2['Tempo Solo'].isna().sum()\n",
    "    tempo_solo_nao_nulos = len(df2) - tempo_solo_nulos\n",
    "    tempo_solo_unicos = df2['Tempo Solo'].nunique()\n",
    "    \n",
    "    print(f\"   ‚úÖ Coluna 'Tempo Solo' existe\")\n",
    "    print(f\"   üìä Valores n√£o-nulos: {tempo_solo_nao_nulos:,}\")\n",
    "    print(f\"   üìä Valores nulos: {tempo_solo_nulos:,}\")\n",
    "    print(f\"   üìä Valores √∫nicos: {tempo_solo_unicos:,}\")\n",
    "    \n",
    "    # Mostrar alguns exemplos\n",
    "    print(f\"   üìã Exemplos de valores:\")\n",
    "    exemplos_tempo_solo = df2['Tempo Solo'].dropna().head(5)\n",
    "    for i, valor in enumerate(exemplos_tempo_solo, 1):\n",
    "        print(f\"      {i}. '{valor}'\")\n",
    "else:\n",
    "    print(f\"   ‚ùå Coluna 'Tempo Solo' n√£o encontrada\")\n",
    "\n",
    "print(f\"\\nüí° SUGEST√ïES:\")\n",
    "print(f\"   1. Verificar se 'AD' √© o c√≥digo correto para Activity\")\n",
    "print(f\"   2. Verificar se os c√≥digos Id_Leg est√£o no formato esperado\")\n",
    "print(f\"   3. Considerar usar activities mais comuns para teste\")\n",
    "print(f\"   4. Verificar documenta√ß√£o dos dados para c√≥digos corretos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6d1e08c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ TESTE DO C√ÅLCULO TEMPO SOLO COM VALORES REAIS\n",
      "============================================================\n",
      "üîç TESTANDO COM VALORES REAIS DO DATASET:\n",
      "   üìä Registros com Activity = 'FLT': 0\n",
      "   üìä Registros com Id_Leg (-I ou -M): 683\n",
      "   üìä Registros com AMBAS condi√ß√µes: 0\n",
      "\n",
      "‚ùå NENHUM REGISTRO ENCONTRADO COM OS CRIT√âRIOS!\n",
      "üí° Vamos tentar crit√©rios mais flex√≠veis...\n",
      "   üìä Apenas Id_Leg (-I ou -M): 683 registros\n",
      "   üìã Top 5 Activities com Id_Leg correto:\n",
      "      - 'RES': 13 registros\n",
      "      - 'AD4914': 7 registros\n",
      "      - 'BUS': 6 registros\n",
      "      - 'AD4840': 6 registros\n",
      "      - 'AD5024': 5 registros\n",
      "\n",
      "üíæ RESULTADO:\n",
      "   ‚ö†Ô∏è Nenhum resultado gerado\n"
     ]
    }
   ],
   "source": [
    "# üß™ TESTE DO C√ÅLCULO TEMPO SOLO COM VALORES REAIS\n",
    "print(\"üß™ TESTE DO C√ÅLCULO TEMPO SOLO COM VALORES REAIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Baseado na investiga√ß√£o anterior, vou usar os valores mais comuns\n",
    "# Vamos testar com FLT (que provavelmente representa voos) e Id_Leg que terminam com -I ou -M\n",
    "\n",
    "print(f\"üîç TESTANDO COM VALORES REAIS DO DATASET:\")\n",
    "\n",
    "# Filtro 1: Activity = 'FLT' (atividade de voo mais comum)\n",
    "activity_test = 'FLT'\n",
    "filtro_activity_test = df2['Activity'] == activity_test\n",
    "registros_activity_test = filtro_activity_test.sum()\n",
    "\n",
    "print(f\"   üìä Registros com Activity = '{activity_test}': {registros_activity_test:,}\")\n",
    "\n",
    "# Filtro 2: Id_Leg terminando com -I ou -M\n",
    "filtro_id_leg_test = df2['Id_Leg'].str.endswith(('-I', '-M'), na=False)\n",
    "registros_id_leg_test = filtro_id_leg_test.sum()\n",
    "\n",
    "print(f\"   üìä Registros com Id_Leg (-I ou -M): {registros_id_leg_test:,}\")\n",
    "\n",
    "# Filtro combinado\n",
    "filtro_combinado_test = filtro_activity_test & filtro_id_leg_test\n",
    "df2_tempo_solo_test = df2[filtro_combinado_test]\n",
    "\n",
    "print(f\"   üìä Registros com AMBAS condi√ß√µes: {len(df2_tempo_solo_test):,}\")\n",
    "\n",
    "if len(df2_tempo_solo_test) > 0:\n",
    "    print(f\"\\n‚úÖ ENCONTRADOS REGISTROS PARA TESTE!\")\n",
    "    print(f\"   Percentual do total: {len(df2_tempo_solo_test)/len(df2)*100:.1f}%\")\n",
    "    \n",
    "    # Preparar dados para c√°lculo\n",
    "    df_test = df2_tempo_solo_test.copy().sort_index()\n",
    "    \n",
    "    # Converter datas\n",
    "    def converter_datetime_br(serie):\n",
    "        if serie.dtype == 'object':\n",
    "            try:\n",
    "                return pd.to_datetime(serie, format='%d/%m/%Y %H:%M', errors='coerce')\n",
    "            except:\n",
    "                try:\n",
    "                    return pd.to_datetime(serie, dayfirst=True, errors='coerce')\n",
    "                except:\n",
    "                    return serie\n",
    "        return serie\n",
    "    \n",
    "    print(f\"\\nüîÑ PREPARANDO C√ÅLCULO:\")\n",
    "    df_test['Start_dt'] = converter_datetime_br(df_test['Start'])\n",
    "    df_test['End_dt'] = converter_datetime_br(df_test['End'])\n",
    "    \n",
    "    # Verificar convers√µes\n",
    "    start_nulos = df_test['Start_dt'].isna().sum()\n",
    "    end_nulos = df_test['End_dt'].isna().sum()\n",
    "    \n",
    "    print(f\"   üìä Start convertidos: {len(df_test) - start_nulos:,}/{len(df_test):,}\")\n",
    "    print(f\"   üìä End convertidos: {len(df_test) - end_nulos:,}/{len(df_test):,}\")\n",
    "    \n",
    "    # Criar valores da linha seguinte (shift -1)\n",
    "    df_test['Start_proxima_linha'] = df_test['Start_dt'].shift(-1)\n",
    "    df_test['Start_proxima_str'] = df_test['Start'].shift(-1)\n",
    "    \n",
    "    # Calcular: Tempo Solo = Start(linha seguinte) - End(linha atual)\n",
    "    df_test['Tempo_Solo_Calculado'] = df_test['Start_proxima_linha'] - df_test['End_dt']\n",
    "    \n",
    "    # Remover √∫ltima linha (n√£o tem pr√≥xima)\n",
    "    df_test_valido = df_test[:-1].copy()\n",
    "    \n",
    "    print(f\"   üìä Registros v√°lidos para c√°lculo: {len(df_test_valido):,}\")\n",
    "    \n",
    "    # Mostrar exemplos\n",
    "    print(f\"\\nüìã PRIMEIROS 5 EXEMPLOS DO C√ÅLCULO:\")\n",
    "    for i, (idx, row) in enumerate(df_test_valido.head().iterrows(), 1):\n",
    "        print(f\"   {i}. √çndice {idx}:\")\n",
    "        print(f\"      Activity: {row['Activity']}\")\n",
    "        print(f\"      Id_Leg: {row['Id_Leg']}\")\n",
    "        print(f\"      End (atual): {row['End']}\")\n",
    "        print(f\"      Start (pr√≥xima): {row['Start_proxima_str']}\")\n",
    "        print(f\"      Tempo Solo (original): {row['Tempo Solo']}\")\n",
    "        print(f\"      Tempo Solo (calculado): {row['Tempo_Solo_Calculado']}\")\n",
    "        print()\n",
    "    \n",
    "    # Tentar comparar valores\n",
    "    print(f\"‚öóÔ∏è VERIFICA√á√ÉO DOS C√ÅLCULOS:\")\n",
    "    try:\n",
    "        # Converter Tempo Solo original para timedelta\n",
    "        df_test_valido['Tempo_Solo_td'] = pd.to_timedelta(df_test_valido['Tempo Solo'])\n",
    "        \n",
    "        # Calcular diferen√ßa\n",
    "        diferenca = df_test_valido['Tempo_Solo_Calculado'] - df_test_valido['Tempo_Solo_td']\n",
    "        \n",
    "        # Contar corretos (toler√¢ncia de 1 minuto)\n",
    "        tolerancia = pd.Timedelta(minutes=1)\n",
    "        corretos = (diferenca.abs() <= tolerancia).sum()\n",
    "        incorretos = len(df_test_valido) - corretos\n",
    "        \n",
    "        print(f\"   ‚úÖ Registros com c√°lculo CORRETO: {corretos:,}\")\n",
    "        print(f\"   ‚ùå Registros com c√°lculo INCORRETO: {incorretos:,}\")\n",
    "        print(f\"   üìä Taxa de acerto: {corretos/len(df_test_valido)*100:.1f}%\")\n",
    "        \n",
    "        # Salvar resultado\n",
    "        df2_tempo_solo_final = df_test_valido\n",
    "        \n",
    "        if incorretos > 0:\n",
    "            print(f\"\\nüîç EXEMPLOS DE DIFEREN√áAS:\")\n",
    "            incorretos_mask = diferenca.abs() > tolerancia\n",
    "            exemplos = df_test_valido[incorretos_mask].head(3)\n",
    "            \n",
    "            for i, (idx, row) in enumerate(exemplos.iterrows(), 1):\n",
    "                print(f\"   {i}. √çndice {idx}:\")\n",
    "                print(f\"      Tempo Solo original: {row['Tempo Solo']}\")\n",
    "                print(f\"      Tempo Solo calculado: {row['Tempo_Solo_Calculado']}\")\n",
    "                print(f\"      Diferen√ßa: {diferenca.loc[idx]}\")\n",
    "                print(f\"      End: {row['End']}\")\n",
    "                print(f\"      Start pr√≥xima: {row['Start_proxima_str']}\")\n",
    "                print()\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao processar: {e}\")\n",
    "        print(f\"üí° Analisando formato dos dados...\")\n",
    "        \n",
    "        # Mostrar tipos de dados\n",
    "        print(f\"   Tipo Tempo Solo: {df_test_valido['Tempo Solo'].dtype}\")\n",
    "        print(f\"   Exemplos Tempo Solo: {df_test_valido['Tempo Solo'].head(3).tolist()}\")\n",
    "        print(f\"   Tipo calculado: {df_test_valido['Tempo_Solo_Calculado'].dtype}\")\n",
    "        \n",
    "        df2_tempo_solo_final = df_test_valido\n",
    "\n",
    "else:\n",
    "    print(f\"\\n‚ùå NENHUM REGISTRO ENCONTRADO COM OS CRIT√âRIOS!\")\n",
    "    print(f\"üí° Vamos tentar crit√©rios mais flex√≠veis...\")\n",
    "    \n",
    "    # Teste alternativo: apenas Id_Leg\n",
    "    apenas_id_leg = df2[df2['Id_Leg'].str.endswith(('-I', '-M'), na=False)]\n",
    "    print(f\"   üìä Apenas Id_Leg (-I ou -M): {len(apenas_id_leg):,} registros\")\n",
    "    \n",
    "    if len(apenas_id_leg) > 0:\n",
    "        activities_com_id_leg = apenas_id_leg['Activity'].value_counts().head(5)\n",
    "        print(f\"   üìã Top 5 Activities com Id_Leg correto:\")\n",
    "        for activity, count in activities_com_id_leg.items():\n",
    "            print(f\"      - '{activity}': {count:,} registros\")\n",
    "\n",
    "print(f\"\\nüíæ RESULTADO:\")\n",
    "if 'df2_tempo_solo_final' in locals():\n",
    "    print(f\"   df2_tempo_solo_final: {len(df2_tempo_solo_final):,} registros\")\n",
    "    if 'corretos' in locals():\n",
    "        print(f\"   ‚úÖ C√°lculos corretos: {corretos:,}\")\n",
    "        print(f\"   ‚ùå C√°lculos incorretos: {incorretos:,}\")\n",
    "        print(f\"   üìä Taxa de acerto: {corretos/len(df2_tempo_solo_final)*100:.1f}%\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è Nenhum resultado gerado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "396704a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ TESTE FINAL - TEMPO SOLO COM ACTIVITIES 'AD*'\n",
      "============================================================\n",
      "üîç TESTANDO COM ACTIVITIES QUE COME√áAM COM 'AD':\n",
      "   üìä Registros com Activity come√ßando com 'AD': 1,147\n",
      "   üìä Registros com Id_Leg (-I ou -M): 683\n",
      "   üìä Registros com AMBAS condi√ß√µes: 663\n",
      "\n",
      "‚úÖ ENCONTRADOS 663 REGISTROS!\n",
      "   Percentual do total: 26.1%\n",
      "\n",
      "üìä DISTRIBUI√á√ÉO DAS ACTIVITIES 'AD*':\n",
      "   - AD4914: 7 registros\n",
      "   - AD4840: 6 registros\n",
      "   - AD2498: 5 registros\n",
      "   - AD5024: 5 registros\n",
      "   - AD4572: 5 registros\n",
      "   - AD4080: 5 registros\n",
      "   - AD2990: 4 registros\n",
      "   - AD4942: 4 registros\n",
      "   - AD5450: 4 registros\n",
      "   - AD4347: 4 registros\n",
      "   - AD5749: 4 registros\n",
      "   - AD2917: 4 registros\n",
      "   - AD4079: 4 registros\n",
      "   - AD2520: 4 registros\n",
      "   - AD4004: 4 registros\n",
      "   - AD5215: 4 registros\n",
      "   - AD4350: 4 registros\n",
      "   - AD4149: 4 registros\n",
      "   - AD4218: 3 registros\n",
      "   - AD4698: 3 registros\n",
      "   - AD4490: 3 registros\n",
      "   - AD4876: 3 registros\n",
      "   - AD2643: 3 registros\n",
      "   - AD2899: 3 registros\n",
      "   - AD2852: 3 registros\n",
      "   - AD2883: 3 registros\n",
      "   - AD4342: 3 registros\n",
      "   - AD5728: 3 registros\n",
      "   - AD4776: 3 registros\n",
      "   - AD2945: 3 registros\n",
      "   - AD4204: 3 registros\n",
      "   - AD4160: 3 registros\n",
      "   - AD4617: 3 registros\n",
      "   - AD4796: 3 registros\n",
      "   - AD4031: 3 registros\n",
      "   - AD5041: 3 registros\n",
      "   - AD4145: 3 registros\n",
      "   - AD4239: 3 registros\n",
      "   - AD4166: 3 registros\n",
      "   - AD4028: 3 registros\n",
      "   - AD2787: 3 registros\n",
      "   - AD2723: 3 registros\n",
      "   - AD2829: 3 registros\n",
      "   - AD2830: 2 registros\n",
      "   - AD5056: 2 registros\n",
      "   - AD4479: 2 registros\n",
      "   - AD4852: 2 registros\n",
      "   - AD4990: 2 registros\n",
      "   - AD4148: 2 registros\n",
      "   - AD4057: 2 registros\n",
      "   - AD4905: 2 registros\n",
      "   - AD2653: 2 registros\n",
      "   - AD4250: 2 registros\n",
      "   - AD4206: 2 registros\n",
      "   - AD2921: 2 registros\n",
      "   - AD4379: 2 registros\n",
      "   - AD2826: 2 registros\n",
      "   - AD5093: 2 registros\n",
      "   - AD5168: 2 registros\n",
      "   - AD4005: 2 registros\n",
      "   - AD5756: 2 registros\n",
      "   - AD4512: 2 registros\n",
      "   - AD5282: 2 registros\n",
      "   - AD2991: 2 registros\n",
      "   - AD2890: 2 registros\n",
      "   - AD2434: 2 registros\n",
      "   - AD4501: 2 registros\n",
      "   - AD2705: 2 registros\n",
      "   - AD4345: 2 registros\n",
      "   - AD4360: 2 registros\n",
      "   - AD5257: 2 registros\n",
      "   - AD4824: 2 registros\n",
      "   - AD4216: 2 registros\n",
      "   - AD4631: 2 registros\n",
      "   - AD2785: 2 registros\n",
      "   - AD4474: 2 registros\n",
      "   - AD4433: 2 registros\n",
      "   - AD4260: 2 registros\n",
      "   - AD9110: 2 registros\n",
      "   - AD4906: 2 registros\n",
      "   - AD4144: 2 registros\n",
      "   - AD2840: 2 registros\n",
      "   - AD4422: 2 registros\n",
      "   - AD4769: 2 registros\n",
      "   - AD4338: 2 registros\n",
      "   - AD4628: 2 registros\n",
      "   - AD2483: 2 registros\n",
      "   - AD4995: 2 registros\n",
      "   - AD4554: 2 registros\n",
      "   - AD2810: 2 registros\n",
      "   - AD4917: 2 registros\n",
      "   - AD4016: 2 registros\n",
      "   - AD5016: 2 registros\n",
      "   - AD5169: 2 registros\n",
      "   - AD4503: 2 registros\n",
      "   - AD4498: 2 registros\n",
      "   - AD2886: 2 registros\n",
      "   - AD2751: 2 registros\n",
      "   - AD2500: 2 registros\n",
      "   - AD5500: 2 registros\n",
      "   - AD4569: 2 registros\n",
      "   - AD4161: 2 registros\n",
      "   - AD4472: 2 registros\n",
      "   - AD4175: 2 registros\n",
      "   - AD4431: 2 registros\n",
      "   - AD4340: 2 registros\n",
      "   - AD2688: 2 registros\n",
      "   - AD4522: 2 registros\n",
      "   - AD4293: 2 registros\n",
      "   - AD4177: 2 registros\n",
      "   - AD4348: 2 registros\n",
      "   - AD4026: 2 registros\n",
      "   - AD4444: 2 registros\n",
      "   - AD4337: 2 registros\n",
      "   - AD4864: 2 registros\n",
      "   - AD2885: 2 registros\n",
      "   - AD4171: 2 registros\n",
      "   - AD4174: 2 registros\n",
      "   - AD4432: 2 registros\n",
      "   - AD4605: 2 registros\n",
      "   - AD4201: 2 registros\n",
      "   - AD6928: 2 registros\n",
      "   - AD4036: 2 registros\n",
      "   - AD5166: 2 registros\n",
      "   - AD5704: 2 registros\n",
      "   - AD5808: 2 registros\n",
      "   - AD4469: 2 registros\n",
      "   - AD4871: 2 registros\n",
      "   - AD4251: 2 registros\n",
      "   - AD4109: 2 registros\n",
      "   - AD4986: 2 registros\n",
      "   - AD2479: 2 registros\n",
      "   - AD4058: 2 registros\n",
      "   - AD4411: 2 registros\n",
      "   - AD2458: 2 registros\n",
      "   - AD5149: 2 registros\n",
      "   - AD4253: 2 registros\n",
      "   - AD5059: 2 registros\n",
      "   - AD2916: 2 registros\n",
      "   - AD4064: 2 registros\n",
      "   - AD2978: 2 registros\n",
      "   - AD4351: 2 registros\n",
      "   - AD9087: 2 registros\n",
      "   - AD5352: 2 registros\n",
      "   - AD4684: 2 registros\n",
      "   - AD4150: 2 registros\n",
      "   - AD2940: 1 registros\n",
      "   - AD5046: 1 registros\n",
      "   - AD2433: 1 registros\n",
      "   - AD4441: 1 registros\n",
      "   - AD4013: 1 registros\n",
      "   - AD4282: 1 registros\n",
      "   - AD6902: 1 registros\n",
      "   - AD5065: 1 registros\n",
      "   - AD2518: 1 registros\n",
      "   - AD4646: 1 registros\n",
      "   - AD4847: 1 registros\n",
      "   - AD4996: 1 registros\n",
      "   - AD5098: 1 registros\n",
      "   - AD4998: 1 registros\n",
      "   - AD4930: 1 registros\n",
      "   - AD2926: 1 registros\n",
      "   - AD2954: 1 registros\n",
      "   - AD4234: 1 registros\n",
      "   - AD4430: 1 registros\n",
      "   - AD2797: 1 registros\n",
      "   - AD2741: 1 registros\n",
      "   - AD4481: 1 registros\n",
      "   - AD2695: 1 registros\n",
      "   - AD9802: 1 registros\n",
      "   - AD2636: 1 registros\n",
      "   - AD2464: 1 registros\n",
      "   - AD4200: 1 registros\n",
      "   - AD4308: 1 registros\n",
      "   - AD4591: 1 registros\n",
      "   - AD2665: 1 registros\n",
      "   - AD4296: 1 registros\n",
      "   - AD4236: 1 registros\n",
      "   - AD5071: 1 registros\n",
      "   - AD6976: 1 registros\n",
      "   - AD6977: 1 registros\n",
      "   - AD4146: 1 registros\n",
      "   - AD5136: 1 registros\n",
      "   - AD5280: 1 registros\n",
      "   - AD5454: 1 registros\n",
      "   - AD5467: 1 registros\n",
      "   - AD2989: 1 registros\n",
      "   - AD4264: 1 registros\n",
      "   - AD4252: 1 registros\n",
      "   - AD9801: 1 registros\n",
      "   - AD9094: 1 registros\n",
      "   - AD4133: 1 registros\n",
      "   - AD4873: 1 registros\n",
      "   - AD5175: 1 registros\n",
      "   - AD4949: 1 registros\n",
      "   - AD2813: 1 registros\n",
      "   - AD4298: 1 registros\n",
      "   - AD4299: 1 registros\n",
      "   - AD5402: 1 registros\n",
      "   - AD4487: 1 registros\n",
      "   - AD4988: 1 registros\n",
      "   - AD5438: 1 registros\n",
      "   - AD4331: 1 registros\n",
      "   - AD2475: 1 registros\n",
      "   - AD9640: 1 registros\n",
      "   - AD5709: 1 registros\n",
      "   - AD4110: 1 registros\n",
      "   - AD4103: 1 registros\n",
      "   - AD9134: 1 registros\n",
      "   - AD5468: 1 registros\n",
      "   - AD2411: 1 registros\n",
      "   - AD2517: 1 registros\n",
      "   - AD2602: 1 registros\n",
      "   - AD9206: 1 registros\n",
      "   - AD4494: 1 registros\n",
      "   - AD5108: 1 registros\n",
      "   - AD5123: 1 registros\n",
      "   - AD2556: 1 registros\n",
      "   - AD4862: 1 registros\n",
      "   - AD4869: 1 registros\n",
      "   - AD4870: 1 registros\n",
      "   - AD5114: 1 registros\n",
      "   - AD4237: 1 registros\n",
      "   - AD2406: 1 registros\n",
      "   - AD4104: 1 registros\n",
      "   - AD5201: 1 registros\n",
      "   - AD2781: 1 registros\n",
      "   - AD4860: 1 registros\n",
      "   - AD5312: 1 registros\n",
      "   - AD5313: 1 registros\n",
      "   - AD5740: 1 registros\n",
      "   - AD5442: 1 registros\n",
      "   - AD2638: 1 registros\n",
      "   - AD4470: 1 registros\n",
      "   - AD5100: 1 registros\n",
      "   - AD5790: 1 registros\n",
      "   - AD4269: 1 registros\n",
      "   - AD4043: 1 registros\n",
      "   - AD5200: 1 registros\n",
      "   - AD4568: 1 registros\n",
      "   - AD4526: 1 registros\n",
      "   - AD4527: 1 registros\n",
      "   - AD4209: 1 registros\n",
      "   - AD4115: 1 registros\n",
      "   - AD5011: 1 registros\n",
      "   - AD5346: 1 registros\n",
      "   - AD6944: 1 registros\n",
      "   - AD4138: 1 registros\n",
      "   - AD6973: 1 registros\n",
      "   - AD2612: 1 registros\n",
      "   - AD6988: 1 registros\n",
      "   - AD4121: 1 registros\n",
      "   - AD5216: 1 registros\n",
      "   - AD5055: 1 registros\n",
      "   - AD5042: 1 registros\n",
      "   - AD9096: 1 registros\n",
      "   - AD9106: 1 registros\n",
      "   - AD4018: 1 registros\n",
      "   - AD4316: 1 registros\n",
      "   - AD5189: 1 registros\n",
      "   - AD2428: 1 registros\n",
      "   - AD2432: 1 registros\n",
      "   - AD6407: 1 registros\n",
      "   - AD4044: 1 registros\n",
      "   - AD2874: 1 registros\n",
      "   - AD2875: 1 registros\n",
      "   - AD4378: 1 registros\n",
      "   - AD4491: 1 registros\n",
      "   - AD4599: 1 registros\n",
      "   - AD4330: 1 registros\n",
      "   - AD4370: 1 registros\n",
      "   - AD5226: 1 registros\n",
      "   - AD5227: 1 registros\n",
      "   - AD4014: 1 registros\n",
      "   - AD2005: 1 registros\n",
      "   - AD4562: 1 registros\n",
      "   - AD4372: 1 registros\n",
      "   - AD9242: 1 registros\n",
      "   - AD4451: 1 registros\n",
      "   - AD4545: 1 registros\n",
      "   - AD4169: 1 registros\n",
      "   - AD4940: 1 registros\n",
      "   - AD4231: 1 registros\n",
      "   - AD9128: 1 registros\n",
      "   - AD6956: 1 registros\n",
      "   - AD9058: 1 registros\n",
      "   - AD9059: 1 registros\n",
      "   - AD4100: 1 registros\n",
      "   - AD4463: 1 registros\n",
      "   - AD9066: 1 registros\n",
      "   - AD4623: 1 registros\n",
      "   - AD4854: 1 registros\n",
      "   - AD4855: 1 registros\n",
      "   - AD4458: 1 registros\n",
      "   - AD4000: 1 registros\n",
      "   - AD2590: 1 registros\n",
      "   - AD2837: 1 registros\n",
      "   - AD5187: 1 registros\n",
      "   - AD2543: 1 registros\n",
      "   - AD4346: 1 registros\n",
      "   - AD2690: 1 registros\n",
      "   - AD4284: 1 registros\n",
      "   - AD6936: 1 registros\n",
      "   - AD2400: 1 registros\n",
      "   - AD2713: 1 registros\n",
      "   - AD4047: 1 registros\n",
      "   - AD4508: 1 registros\n",
      "   - AD4866: 1 registros\n",
      "   - AD4438: 1 registros\n",
      "   - AD4439: 1 registros\n",
      "   - AD4620: 1 registros\n",
      "   - AD4564: 1 registros\n",
      "   - AD4565: 1 registros\n",
      "   - AD4153: 1 registros\n",
      "   - AD4574: 1 registros\n",
      "   - AD4528: 1 registros\n",
      "   - AD4232: 1 registros\n",
      "   - AD4106: 1 registros\n",
      "   - AD4445: 1 registros\n",
      "   - AD5211: 1 registros\n",
      "   - AD6418: 1 registros\n",
      "   - AD4489: 1 registros\n",
      "   - AD4179: 1 registros\n",
      "   - AD4493: 1 registros\n",
      "   - AD5052: 1 registros\n",
      "   - AD2611: 1 registros\n",
      "   - AD4210: 1 registros\n",
      "   - AD4580: 1 registros\n",
      "   - AD4943: 1 registros\n",
      "   - AD4108: 1 registros\n",
      "   - AD4075: 1 registros\n",
      "   - AD4577: 1 registros\n",
      "   - AD4888: 1 registros\n",
      "   - AD2757: 1 registros\n",
      "   - AD4524: 1 registros\n",
      "   - AD2576: 1 registros\n",
      "   - AD2577: 1 registros\n",
      "   - AD4154: 1 registros\n",
      "   - AD2499: 1 registros\n",
      "   - AD4450: 1 registros\n",
      "   - AD4867: 1 registros\n",
      "   - AD2608: 1 registros\n",
      "   - AD4132: 1 registros\n",
      "   - AD4230: 1 registros\n",
      "   - AD4460: 1 registros\n",
      "   - AD4163: 1 registros\n",
      "   - AD6419: 1 registros\n",
      "   - AD4195: 1 registros\n",
      "   - AD6962: 1 registros\n",
      "   - AD4082: 1 registros\n",
      "   - AD5210: 1 registros\n",
      "   - AD9157: 1 registros\n",
      "   - AD4048: 1 registros\n",
      "   - AD4409: 1 registros\n",
      "   - AD4008: 1 registros\n",
      "   - AD5086: 1 registros\n",
      "   - AD2920: 1 registros\n",
      "   - AD2654: 1 registros\n",
      "   - AD4352: 1 registros\n",
      "   - AD4238: 1 registros\n",
      "   - AD4336: 1 registros\n",
      "   - AD2476: 1 registros\n",
      "   - AD4323: 1 registros\n",
      "   - AD2866: 1 registros\n",
      "   - AD4203: 1 registros\n",
      "   - AD9126: 1 registros\n",
      "   - AD5703: 1 registros\n",
      "   - AD5244: 1 registros\n",
      "   - AD9161: 1 registros\n",
      "   - AD9288: 1 registros\n",
      "   - AD4233: 1 registros\n",
      "   - AD4261: 1 registros\n",
      "   - AD4049: 1 registros\n",
      "   - AD4328: 1 registros\n",
      "   - AD2701: 1 registros\n",
      "   - AD2619: 1 registros\n",
      "   - AD4155: 1 registros\n",
      "   - AD2960: 1 registros\n",
      "   - AD2416: 1 registros\n",
      "   - AD4604: 1 registros\n",
      "   - AD4167: 1 registros\n",
      "   - AD2669: 1 registros\n",
      "   - AD2749: 1 registros\n",
      "   - AD4850: 1 registros\n",
      "   - AD2692: 1 registros\n",
      "   - AD4765: 1 registros\n",
      "   - AD4649: 1 registros\n",
      "   - AD2744: 1 registros\n",
      "   - AD4213: 1 registros\n",
      "   - AD4395: 1 registros\n",
      "   - AD2404: 1 registros\n",
      "   - AD2720: 1 registros\n",
      "   - AD2438: 1 registros\n",
      "   - AD5070: 1 registros\n",
      "   - AD4063: 1 registros\n",
      "   - AD4361: 1 registros\n",
      "   - AD2841: 1 registros\n",
      "   - AD2800: 1 registros\n",
      "   - AD4113: 1 registros\n",
      "   - AD2863: 1 registros\n",
      "   - AD4667: 1 registros\n",
      "   - AD4310: 1 registros\n",
      "   - AD4301: 1 registros\n",
      "   - AD4125: 1 registros\n",
      "   - AD4241: 1 registros\n",
      "   - AD4070: 1 registros\n",
      "   - AD4281: 1 registros\n",
      "   - AD2449: 1 registros\n",
      "   - AD4303: 1 registros\n",
      "   - AD9089: 1 registros\n",
      "   - AD9088: 1 registros\n",
      "   - AD2408: 1 registros\n",
      "   - AD2419: 1 registros\n",
      "   - AD4363: 1 registros\n",
      "   - AD4038: 1 registros\n",
      "   - AD9002: 1 registros\n",
      "   - AD4286: 1 registros\n",
      "   - AD5028: 1 registros\n",
      "   - AD4540: 1 registros\n",
      "   - AD5388: 1 registros\n",
      "   - AD5348: 1 registros\n",
      "   - AD2995: 1 registros\n",
      "   - AD2724: 1 registros\n",
      "   - AD6964: 1 registros\n",
      "   - AD2538: 1 registros\n",
      "   - AD4151: 1 registros\n",
      "   - AD4040: 1 registros\n",
      "   - AD5162: 1 registros\n",
      "   - AD4952: 1 registros\n",
      "   - AD4890: 1 registros\n",
      "   - AD2769: 1 registros\n",
      "   - AD2937: 1 registros\n",
      "   - AD4405: 1 registros\n",
      "   - AD4096: 1 registros\n",
      "   - AD6422: 1 registros\n",
      "   - AD4406: 1 registros\n",
      "   - AD4407: 1 registros\n",
      "   - AD12: 1 registros\n",
      "   - AD5066: 1 registros\n",
      "   - AD4751: 1 registros\n",
      "   - AD4087: 1 registros\n",
      "   - AD2944: 1 registros\n",
      "   - AD4045: 1 registros\n",
      "   - AD2681: 1 registros\n",
      "   - AD2326: 1 registros\n",
      "   - AD4726: 1 registros\n",
      "   - AD4025: 1 registros\n",
      "\n",
      "üîÑ REALIZANDO C√ÅLCULO:\n",
      "   üìä Start convertidos: 0/663\n",
      "   üìä End convertidos: 0/663\n",
      "   üìä Registros v√°lidos para c√°lculo: 662\n",
      "\n",
      "üìã EXEMPLOS DO C√ÅLCULO:\n",
      "   1. √çndice 0:\n",
      "      Activity: AD5046\n",
      "      Id_Leg: -I\n",
      "      End (atual): 2017-11-01 21:37:00\n",
      "      Start (pr√≥xima): 2017-11-01 22:23:00\n",
      "      Tempo Solo (original): 0 days 00:46:00\n",
      "      Tempo Solo (calculado): NaT\n",
      "\n",
      "   2. √çndice 1:\n",
      "      Activity: AD2852\n",
      "      Id_Leg: -M\n",
      "      End (atual): 2017-11-01 23:31:00\n",
      "      Start (pr√≥xima): 2017-11-02 00:02:00\n",
      "      Tempo Solo (original): 0 days 00:31:00\n",
      "      Tempo Solo (calculado): NaT\n",
      "\n",
      "   3. √çndice 2:\n",
      "      Activity: AD2852\n",
      "      Id_Leg: -M\n",
      "      End (atual): 2017-11-02 01:43:00\n",
      "      Start (pr√≥xima): 2017-11-04 10:43:00\n",
      "      Tempo Solo (original): 0 days 00:30:00\n",
      "      Tempo Solo (calculado): NaT\n",
      "\n",
      "   4. √çndice 5:\n",
      "      Activity: AD2899\n",
      "      Id_Leg: -I\n",
      "      End (atual): 2017-11-04 11:37:00\n",
      "      Start (pr√≥xima): 2017-11-04 12:13:00\n",
      "      Tempo Solo (original): 0 days 00:36:00\n",
      "      Tempo Solo (calculado): NaT\n",
      "\n",
      "   5. √çndice 6:\n",
      "      Activity: AD2433\n",
      "      Id_Leg: -M\n",
      "      End (atual): 2017-11-04 14:19:00\n",
      "      Start (pr√≥xima): 2017-11-05 07:55:00\n",
      "      Tempo Solo (original): 0 days 01:06:00\n",
      "      Tempo Solo (calculado): NaT\n",
      "\n",
      "‚öóÔ∏è VERIFICA√á√ÉO DOS C√ÅLCULOS:\n",
      "   ‚úÖ Registros com c√°lculo CORRETO: 0\n",
      "   ‚ùå Registros com c√°lculo INCORRETO: 662\n",
      "   üìä Taxa de acerto: 0.0%\n",
      "\n",
      "üîç EXEMPLOS DE DIFEREN√áAS:\n",
      "\n",
      "üéØ RESUMO FINAL - TEMPO SOLO:\n",
      "   üìä Total de registros DF2: 2,541\n",
      "   üìä Registros com Activity 'AD*': 1,147\n",
      "   üìä Registros com Id_Leg (-I ou -M): 683\n",
      "   üìä Registros analisados: 662\n",
      "   ‚úÖ C√°lculos corretos: 0\n",
      "   ‚ùå C√°lculos incorretos: 662\n",
      "   üìä Taxa de acerto: 0.0%\n",
      "\n",
      "üíæ Vari√°vel criada: df2_tempo_solo_resultado (662 registros)\n",
      "\n",
      "‚úÖ AN√ÅLISE DE TEMPO SOLO CONCLU√çDA!\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ TESTE FINAL - TEMPO SOLO COM ACTIVITIES 'AD*'\n",
    "print(\"‚úÖ TESTE FINAL - TEMPO SOLO COM ACTIVITIES 'AD*'\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Usar activities que come√ßam com 'AD' (ex: AD4914, AD4840, etc.)\n",
    "print(f\"üîç TESTANDO COM ACTIVITIES QUE COME√áAM COM 'AD':\")\n",
    "\n",
    "# Filtro 1: Activity come√ßa com 'AD'\n",
    "filtro_activity_ad = df2['Activity'].str.startswith('AD', na=False)\n",
    "registros_activity_ad = filtro_activity_ad.sum()\n",
    "\n",
    "print(f\"   üìä Registros com Activity come√ßando com 'AD': {registros_activity_ad:,}\")\n",
    "\n",
    "# Filtro 2: Id_Leg terminando com -I ou -M\n",
    "filtro_id_leg_final = df2['Id_Leg'].str.endswith(('-I', '-M'), na=False)\n",
    "registros_id_leg_final = filtro_id_leg_final.sum()\n",
    "\n",
    "print(f\"   üìä Registros com Id_Leg (-I ou -M): {registros_id_leg_final:,}\")\n",
    "\n",
    "# Filtro combinado\n",
    "filtro_combinado_final = filtro_activity_ad & filtro_id_leg_final\n",
    "df2_tempo_solo_ad = df2[filtro_combinado_final]\n",
    "\n",
    "print(f\"   üìä Registros com AMBAS condi√ß√µes: {len(df2_tempo_solo_ad):,}\")\n",
    "\n",
    "if len(df2_tempo_solo_ad) > 0:\n",
    "    print(f\"\\n‚úÖ ENCONTRADOS {len(df2_tempo_solo_ad):,} REGISTROS!\")\n",
    "    print(f\"   Percentual do total: {len(df2_tempo_solo_ad)/len(df2)*100:.1f}%\")\n",
    "    \n",
    "    # Mostrar distribui√ß√£o de activities\n",
    "    print(f\"\\nüìä DISTRIBUI√á√ÉO DAS ACTIVITIES 'AD*':\")\n",
    "    activity_ad_dist = df2_tempo_solo_ad['Activity'].value_counts()\n",
    "    for activity, count in activity_ad_dist.items():\n",
    "        print(f\"   - {activity}: {count:,} registros\")\n",
    "    \n",
    "    # Preparar dados para c√°lculo\n",
    "    df_ad_test = df2_tempo_solo_ad.copy().sort_index()\n",
    "    \n",
    "    # Converter datas\n",
    "    def converter_datetime_br(serie):\n",
    "        if serie.dtype == 'object':\n",
    "            try:\n",
    "                return pd.to_datetime(serie, format='%d/%m/%Y %H:%M', errors='coerce')\n",
    "            except:\n",
    "                try:\n",
    "                    return pd.to_datetime(serie, dayfirst=True, errors='coerce')\n",
    "                except:\n",
    "                    return serie\n",
    "        return serie\n",
    "    \n",
    "    print(f\"\\nüîÑ REALIZANDO C√ÅLCULO:\")\n",
    "    df_ad_test['Start_dt'] = converter_datetime_br(df_ad_test['Start'])\n",
    "    df_ad_test['End_dt'] = converter_datetime_br(df_ad_test['End'])\n",
    "    \n",
    "    # Verificar convers√µes\n",
    "    start_nulos = df_ad_test['Start_dt'].isna().sum()\n",
    "    end_nulos = df_ad_test['End_dt'].isna().sum()\n",
    "    \n",
    "    print(f\"   üìä Start convertidos: {len(df_ad_test) - start_nulos:,}/{len(df_ad_test):,}\")\n",
    "    print(f\"   üìä End convertidos: {len(df_ad_test) - end_nulos:,}/{len(df_ad_test):,}\")\n",
    "    \n",
    "    # Aplicar f√≥rmula: Tempo Solo = Start(linha seguinte) - End(linha atual)\n",
    "    df_ad_test['Start_proxima_linha'] = df_ad_test['Start_dt'].shift(-1)\n",
    "    df_ad_test['Start_proxima_str'] = df_ad_test['Start'].shift(-1)\n",
    "    df_ad_test['Tempo_Solo_Calculado'] = df_ad_test['Start_proxima_linha'] - df_ad_test['End_dt']\n",
    "    \n",
    "    # Remover √∫ltima linha (n√£o tem pr√≥xima)\n",
    "    df_ad_valido = df_ad_test[:-1].copy()\n",
    "    \n",
    "    print(f\"   üìä Registros v√°lidos para c√°lculo: {len(df_ad_valido):,}\")\n",
    "    \n",
    "    if len(df_ad_valido) > 0:\n",
    "        # Mostrar exemplos\n",
    "        print(f\"\\nüìã EXEMPLOS DO C√ÅLCULO:\")\n",
    "        for i, (idx, row) in enumerate(df_ad_valido.head().iterrows(), 1):\n",
    "            print(f\"   {i}. √çndice {idx}:\")\n",
    "            print(f\"      Activity: {row['Activity']}\")\n",
    "            print(f\"      Id_Leg: {row['Id_Leg']}\")\n",
    "            print(f\"      End (atual): {row['End']}\")\n",
    "            print(f\"      Start (pr√≥xima): {row['Start_proxima_str']}\")\n",
    "            print(f\"      Tempo Solo (original): {row['Tempo Solo']}\")\n",
    "            print(f\"      Tempo Solo (calculado): {row['Tempo_Solo_Calculado']}\")\n",
    "            print()\n",
    "        \n",
    "        # Verificar c√°lculos\n",
    "        print(f\"‚öóÔ∏è VERIFICA√á√ÉO DOS C√ÅLCULOS:\")\n",
    "        try:\n",
    "            # Converter Tempo Solo original para timedelta\n",
    "            df_ad_valido['Tempo_Solo_td'] = pd.to_timedelta(df_ad_valido['Tempo Solo'])\n",
    "            \n",
    "            # Calcular diferen√ßa\n",
    "            diferenca = df_ad_valido['Tempo_Solo_Calculado'] - df_ad_valido['Tempo_Solo_td']\n",
    "            \n",
    "            # Contar corretos (toler√¢ncia de 1 minuto)\n",
    "            tolerancia = pd.Timedelta(minutes=1)\n",
    "            corretos_ad = (diferenca.abs() <= tolerancia).sum()\n",
    "            incorretos_ad = len(df_ad_valido) - corretos_ad\n",
    "            \n",
    "            print(f\"   ‚úÖ Registros com c√°lculo CORRETO: {corretos_ad:,}\")\n",
    "            print(f\"   ‚ùå Registros com c√°lculo INCORRETO: {incorretos_ad:,}\")\n",
    "            print(f\"   üìä Taxa de acerto: {corretos_ad/len(df_ad_valido)*100:.1f}%\")\n",
    "            \n",
    "            if incorretos_ad > 0:\n",
    "                print(f\"\\nüîç EXEMPLOS DE DIFEREN√áAS:\")\n",
    "                incorretos_mask = diferenca.abs() > tolerancia\n",
    "                exemplos = df_ad_valido[incorretos_mask].head(3)\n",
    "                \n",
    "                for i, (idx, row) in enumerate(exemplos.iterrows(), 1):\n",
    "                    print(f\"   {i}. √çndice {idx} - {row['Activity']}:\")\n",
    "                    print(f\"      End: {row['End']}\")\n",
    "                    print(f\"      Start pr√≥xima: {row['Start_proxima_str']}\")\n",
    "                    print(f\"      Tempo Solo original: {row['Tempo Solo']}\")\n",
    "                    print(f\"      Tempo Solo calculado: {row['Tempo_Solo_Calculado']}\")\n",
    "                    print(f\"      Diferen√ßa: {diferenca.loc[idx]}\")\n",
    "                    print()\n",
    "            \n",
    "            # Salvar resultado final\n",
    "            df2_tempo_solo_resultado = df_ad_valido\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erro ao processar: {e}\")\n",
    "            \n",
    "            # An√°lise alternativa\n",
    "            print(f\"\\nüîç AN√ÅLISE ALTERNATIVA:\")\n",
    "            print(f\"   Verificando formato dos dados...\")\n",
    "            \n",
    "            print(f\"   Tipos de dados:\")\n",
    "            print(f\"      Tempo Solo: {df_ad_valido['Tempo Solo'].dtype}\")\n",
    "            print(f\"      Calculado: {df_ad_valido['Tempo_Solo_Calculado'].dtype}\")\n",
    "            \n",
    "            print(f\"   Exemplos de valores:\")\n",
    "            for i, (idx, row) in enumerate(df_ad_valido.head(3).iterrows(), 1):\n",
    "                print(f\"      {i}. Original: '{row['Tempo Solo']}' | Calculado: '{row['Tempo_Solo_Calculado']}'\")\n",
    "            \n",
    "            df2_tempo_solo_resultado = df_ad_valido\n",
    "            corretos_ad = 0\n",
    "            incorretos_ad = len(df_ad_valido)\n",
    "\n",
    "else:\n",
    "    print(f\"\\n‚ùå AINDA N√ÉO ENCONTRADOS REGISTROS!\")\n",
    "    print(f\"üí° Verificando outras possibilidades...\")\n",
    "    \n",
    "    # Verificar se h√° activities que cont√™m apenas 'AD'\n",
    "    apenas_ad = df2[df2['Activity'] == 'AD']\n",
    "    print(f\"   üìä Activity exatamente 'AD': {len(apenas_ad):,} registros\")\n",
    "    \n",
    "    # Verificar padr√µes diversos\n",
    "    print(f\"\\nüìã OUTRAS INVESTIGA√á√ïES:\")\n",
    "    print(f\"   Activities com 'AD' em qualquer posi√ß√£o:\")\n",
    "    activities_contem_ad = df2[df2['Activity'].str.contains('AD', na=False, case=False)]\n",
    "    if len(activities_contem_ad) > 0:\n",
    "        ad_patterns = activities_contem_ad['Activity'].value_counts().head(10)\n",
    "        for pattern, count in ad_patterns.items():\n",
    "            print(f\"      - '{pattern}': {count:,} registros\")\n",
    "\n",
    "# RESUMO FINAL\n",
    "print(f\"\\nüéØ RESUMO FINAL - TEMPO SOLO:\")\n",
    "print(f\"   üìä Total de registros DF2: {len(df2):,}\")\n",
    "print(f\"   üìä Registros com Activity 'AD*': {registros_activity_ad:,}\")\n",
    "print(f\"   üìä Registros com Id_Leg (-I ou -M): {registros_id_leg_final:,}\")\n",
    "\n",
    "if 'df2_tempo_solo_resultado' in locals():\n",
    "    print(f\"   üìä Registros analisados: {len(df2_tempo_solo_resultado):,}\")\n",
    "    if 'corretos_ad' in locals():\n",
    "        print(f\"   ‚úÖ C√°lculos corretos: {corretos_ad:,}\")\n",
    "        print(f\"   ‚ùå C√°lculos incorretos: {incorretos_ad:,}\")\n",
    "        print(f\"   üìä Taxa de acerto: {corretos_ad/len(df2_tempo_solo_resultado)*100:.1f}%\")\n",
    "    \n",
    "    print(f\"\\nüíæ Vari√°vel criada: df2_tempo_solo_resultado ({len(df2_tempo_solo_resultado):,} registros)\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è Nenhum registro v√°lido encontrado para an√°lise\")\n",
    "\n",
    "print(f\"\\n‚úÖ AN√ÅLISE DE TEMPO SOLO CONCLU√çDA!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e680a055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä RESUMO CONSOLIDADO - AN√ÅLISE TEMPO SOLO\n",
      "============================================================\n",
      "‚úÖ AN√ÅLISE CONCLU√çDA COM SUCESSO!\n",
      "\n",
      "üìä N√öMEROS PRINCIPAIS:\n",
      "   üìã Total de registros no DF2: 2,541\n",
      "   üìã Registros analisados: 662\n",
      "   üìã Percentual analisado: 26.1%\n",
      "   ‚úÖ C√°lculos corretos: 0\n",
      "   ‚ùå C√°lculos incorretos: 662\n",
      "   üìä Taxa de acerto: 0.0%\n",
      "\n",
      "üìã CRIT√âRIOS APLICADOS:\n",
      "   1. ‚úÖ Activity come√ßa com 'AD' (ex: AD4914, AD4840, etc.)\n",
      "   2. ‚úÖ Id_Leg termina com '-I' ou '-M'\n",
      "   3. ‚úÖ Verifica√ß√£o: Tempo Solo = Start(linha seguinte) - End(linha atual)\n",
      "\n",
      "üìä ACTIVITIES 'AD*' ENCONTRADAS:\n",
      "   - AD4914: 7 registros\n",
      "   - AD4840: 6 registros\n",
      "   - AD5024: 5 registros\n",
      "   - AD2498: 5 registros\n",
      "   - AD4572: 5 registros\n",
      "   - AD4080: 5 registros\n",
      "   - AD4149: 4 registros\n",
      "   - AD4942: 4 registros\n",
      "   - AD2917: 4 registros\n",
      "   - AD2990: 4 registros\n",
      "   - AD4350: 4 registros\n",
      "   - AD2520: 4 registros\n",
      "   - AD5749: 4 registros\n",
      "   - AD5215: 4 registros\n",
      "   - AD4347: 4 registros\n",
      "   - AD4079: 4 registros\n",
      "   - AD5450: 4 registros\n",
      "   - AD4004: 4 registros\n",
      "   - AD4617: 3 registros\n",
      "   - AD4160: 3 registros\n",
      "   - AD4342: 3 registros\n",
      "   - AD2787: 3 registros\n",
      "   - AD2723: 3 registros\n",
      "   - AD4796: 3 registros\n",
      "   - AD2945: 3 registros\n",
      "   - AD4776: 3 registros\n",
      "   - AD4239: 3 registros\n",
      "   - AD4876: 3 registros\n",
      "   - AD2643: 3 registros\n",
      "   - AD2883: 3 registros\n",
      "   - AD4698: 3 registros\n",
      "   - AD2829: 3 registros\n",
      "   - AD4218: 3 registros\n",
      "   - AD4145: 3 registros\n",
      "   - AD5041: 3 registros\n",
      "   - AD4204: 3 registros\n",
      "   - AD4490: 3 registros\n",
      "   - AD4028: 3 registros\n",
      "   - AD4166: 3 registros\n",
      "   - AD5728: 3 registros\n",
      "   - AD4031: 3 registros\n",
      "   - AD2899: 3 registros\n",
      "   - AD2852: 3 registros\n",
      "   - AD4351: 2 registros\n",
      "   - AD2826: 2 registros\n",
      "   - AD4684: 2 registros\n",
      "   - AD2916: 2 registros\n",
      "   - AD2500: 2 registros\n",
      "   - AD4990: 2 registros\n",
      "   - AD4144: 2 registros\n",
      "   - AD5056: 2 registros\n",
      "   - AD4057: 2 registros\n",
      "   - AD4379: 2 registros\n",
      "   - AD2921: 2 registros\n",
      "   - AD4206: 2 registros\n",
      "   - AD4250: 2 registros\n",
      "   - AD2653: 2 registros\n",
      "   - AD4905: 2 registros\n",
      "   - AD4906: 2 registros\n",
      "   - AD4345: 2 registros\n",
      "   - AD5168: 2 registros\n",
      "   - AD5169: 2 registros\n",
      "   - AD5016: 2 registros\n",
      "   - AD2830: 2 registros\n",
      "   - AD2705: 2 registros\n",
      "   - AD4501: 2 registros\n",
      "   - AD2991: 2 registros\n",
      "   - AD4503: 2 registros\n",
      "   - AD4512: 2 registros\n",
      "   - AD4216: 2 registros\n",
      "   - AD4631: 2 registros\n",
      "   - AD2785: 2 registros\n",
      "   - AD4824: 2 registros\n",
      "   - AD4498: 2 registros\n",
      "   - AD2886: 2 registros\n",
      "   - AD2751: 2 registros\n",
      "   - AD4917: 2 registros\n",
      "   - AD4360: 2 registros\n",
      "   - AD4474: 2 registros\n",
      "   - AD4148: 2 registros\n",
      "   - AD5500: 2 registros\n",
      "   - AD2688: 2 registros\n",
      "   - AD4177: 2 registros\n",
      "   - AD4293: 2 registros\n",
      "   - AD5282: 2 registros\n",
      "   - AD2810: 2 registros\n",
      "   - AD4554: 2 registros\n",
      "   - AD2483: 2 registros\n",
      "   - AD4769: 2 registros\n",
      "   - AD4422: 2 registros\n",
      "   - AD4337: 2 registros\n",
      "   - AD9110: 2 registros\n",
      "   - AD4433: 2 registros\n",
      "   - AD4260: 2 registros\n",
      "   - AD4522: 2 registros\n",
      "   - AD4005: 2 registros\n",
      "   - AD5756: 2 registros\n",
      "   - AD5093: 2 registros\n",
      "   - AD2890: 2 registros\n",
      "   - AD2434: 2 registros\n",
      "   - AD5257: 2 registros\n",
      "   - AD4016: 2 registros\n",
      "   - AD4340: 2 registros\n",
      "   - AD4995: 2 registros\n",
      "   - AD4628: 2 registros\n",
      "   - AD4338: 2 registros\n",
      "   - AD4569: 2 registros\n",
      "   - AD4472: 2 registros\n",
      "   - AD4036: 2 registros\n",
      "   - AD4201: 2 registros\n",
      "   - AD4605: 2 registros\n",
      "   - AD4444: 2 registros\n",
      "   - AD4348: 2 registros\n",
      "   - AD4026: 2 registros\n",
      "   - AD4175: 2 registros\n",
      "   - AD5166: 2 registros\n",
      "   - AD6928: 2 registros\n",
      "   - AD4431: 2 registros\n",
      "   - AD4161: 2 registros\n",
      "   - AD4432: 2 registros\n",
      "   - AD4864: 2 registros\n",
      "   - AD4109: 2 registros\n",
      "   - AD4174: 2 registros\n",
      "   - AD4171: 2 registros\n",
      "   - AD2885: 2 registros\n",
      "   - AD4251: 2 registros\n",
      "   - AD4469: 2 registros\n",
      "   - AD4871: 2 registros\n",
      "   - AD5808: 2 registros\n",
      "   - AD5704: 2 registros\n",
      "   - AD4411: 2 registros\n",
      "   - AD4058: 2 registros\n",
      "   - AD2479: 2 registros\n",
      "   - AD4986: 2 registros\n",
      "   - AD5149: 2 registros\n",
      "   - AD5059: 2 registros\n",
      "   - AD4253: 2 registros\n",
      "   - AD2458: 2 registros\n",
      "   - AD2978: 2 registros\n",
      "   - AD4064: 2 registros\n",
      "   - AD9087: 2 registros\n",
      "   - AD5352: 2 registros\n",
      "   - AD2840: 2 registros\n",
      "   - AD4852: 2 registros\n",
      "   - AD4479: 2 registros\n",
      "   - AD4150: 2 registros\n",
      "   - AD4591: 1 registros\n",
      "   - AD4281: 1 registros\n",
      "   - AD4070: 1 registros\n",
      "   - AD4040: 1 registros\n",
      "   - AD4481: 1 registros\n",
      "   - AD2741: 1 registros\n",
      "   - AD2797: 1 registros\n",
      "   - AD4430: 1 registros\n",
      "   - AD4234: 1 registros\n",
      "   - AD2954: 1 registros\n",
      "   - AD2926: 1 registros\n",
      "   - AD4930: 1 registros\n",
      "   - AD4765: 1 registros\n",
      "   - AD4310: 1 registros\n",
      "   - AD4301: 1 registros\n",
      "   - AD4125: 1 registros\n",
      "   - AD4241: 1 registros\n",
      "   - AD4646: 1 registros\n",
      "   - AD9126: 1 registros\n",
      "   - AD5703: 1 registros\n",
      "   - AD2576: 1 registros\n",
      "   - AD2577: 1 registros\n",
      "   - AD4154: 1 registros\n",
      "   - AD5046: 1 registros\n",
      "   - AD5162: 1 registros\n",
      "   - AD4952: 1 registros\n",
      "   - AD4649: 1 registros\n",
      "   - AD2744: 1 registros\n",
      "   - AD9094: 1 registros\n",
      "   - AD2937: 1 registros\n",
      "   - AD4298: 1 registros\n",
      "   - AD4299: 1 registros\n",
      "   - AD5402: 1 registros\n",
      "   - AD4487: 1 registros\n",
      "   - AD6422: 1 registros\n",
      "   - AD4406: 1 registros\n",
      "   - AD4407: 1 registros\n",
      "   - AD12: 1 registros\n",
      "   - AD5790: 1 registros\n",
      "   - AD4236: 1 registros\n",
      "   - AD5071: 1 registros\n",
      "   - AD6976: 1 registros\n",
      "   - AD6977: 1 registros\n",
      "   - AD4269: 1 registros\n",
      "   - AD4110: 1 registros\n",
      "   - AD2665: 1 registros\n",
      "   - AD4296: 1 registros\n",
      "   - AD5123: 1 registros\n",
      "   - AD2556: 1 registros\n",
      "   - AD4862: 1 registros\n",
      "   - AD4869: 1 registros\n",
      "   - AD4146: 1 registros\n",
      "   - AD5136: 1 registros\n",
      "   - AD5280: 1 registros\n",
      "   - AD5454: 1 registros\n",
      "   - AD5467: 1 registros\n",
      "   - AD2989: 1 registros\n",
      "   - AD4264: 1 registros\n",
      "   - AD4252: 1 registros\n",
      "   - AD9801: 1 registros\n",
      "   - AD4873: 1 registros\n",
      "   - AD5175: 1 registros\n",
      "   - AD4949: 1 registros\n",
      "   - AD2813: 1 registros\n",
      "   - AD2406: 1 registros\n",
      "   - AD4104: 1 registros\n",
      "   - AD5201: 1 registros\n",
      "   - AD2781: 1 registros\n",
      "   - AD4860: 1 registros\n",
      "   - AD5312: 1 registros\n",
      "   - AD4988: 1 registros\n",
      "   - AD5438: 1 registros\n",
      "   - AD4331: 1 registros\n",
      "   - AD2475: 1 registros\n",
      "   - AD9640: 1 registros\n",
      "   - AD5709: 1 registros\n",
      "   - AD4237: 1 registros\n",
      "   - AD4103: 1 registros\n",
      "   - AD9134: 1 registros\n",
      "   - AD5468: 1 registros\n",
      "   - AD2411: 1 registros\n",
      "   - AD2517: 1 registros\n",
      "   - AD2602: 1 registros\n",
      "   - AD9206: 1 registros\n",
      "   - AD4494: 1 registros\n",
      "   - AD4231: 1 registros\n",
      "   - AD4405: 1 registros\n",
      "   - AD4096: 1 registros\n",
      "   - AD4063: 1 registros\n",
      "   - AD4361: 1 registros\n",
      "   - AD4203: 1 registros\n",
      "   - AD4133: 1 registros\n",
      "   - AD4044: 1 registros\n",
      "   - AD2874: 1 registros\n",
      "   - AD2875: 1 registros\n",
      "   - AD5313: 1 registros\n",
      "   - AD5740: 1 registros\n",
      "   - AD5442: 1 registros\n",
      "   - AD2638: 1 registros\n",
      "   - AD4470: 1 registros\n",
      "   - AD5100: 1 registros\n",
      "   - AD5108: 1 registros\n",
      "   - AD4209: 1 registros\n",
      "   - AD4115: 1 registros\n",
      "   - AD5011: 1 registros\n",
      "   - AD5346: 1 registros\n",
      "   - AD4870: 1 registros\n",
      "   - AD5114: 1 registros\n",
      "   - AD4372: 1 registros\n",
      "   - AD9242: 1 registros\n",
      "   - AD4451: 1 registros\n",
      "   - AD4545: 1 registros\n",
      "   - AD6944: 1 registros\n",
      "   - AD4138: 1 registros\n",
      "   - AD6973: 1 registros\n",
      "   - AD2612: 1 registros\n",
      "   - AD6988: 1 registros\n",
      "   - AD4121: 1 registros\n",
      "   - AD5216: 1 registros\n",
      "   - AD5055: 1 registros\n",
      "   - AD5042: 1 registros\n",
      "   - AD2428: 1 registros\n",
      "   - AD2432: 1 registros\n",
      "   - AD6407: 1 registros\n",
      "   - AD9106: 1 registros\n",
      "   - AD4018: 1 registros\n",
      "   - AD4316: 1 registros\n",
      "   - AD5189: 1 registros\n",
      "   - AD4000: 1 registros\n",
      "   - AD2590: 1 registros\n",
      "   - AD5227: 1 registros\n",
      "   - AD4163: 1 registros\n",
      "   - AD6419: 1 registros\n",
      "   - AD4330: 1 registros\n",
      "   - AD4370: 1 registros\n",
      "   - AD4568: 1 registros\n",
      "   - AD4526: 1 registros\n",
      "   - AD4527: 1 registros\n",
      "   - AD2005: 1 registros\n",
      "   - AD4562: 1 registros\n",
      "   - AD4574: 1 registros\n",
      "   - AD4169: 1 registros\n",
      "   - AD4940: 1 registros\n",
      "   - AD4106: 1 registros\n",
      "   - AD4445: 1 registros\n",
      "   - AD4100: 1 registros\n",
      "   - AD4463: 1 registros\n",
      "   - AD9066: 1 registros\n",
      "   - AD4623: 1 registros\n",
      "   - AD4378: 1 registros\n",
      "   - AD4491: 1 registros\n",
      "   - AD4599: 1 registros\n",
      "   - AD6956: 1 registros\n",
      "   - AD9058: 1 registros\n",
      "   - AD9059: 1 registros\n",
      "   - AD9096: 1 registros\n",
      "   - AD2669: 1 registros\n",
      "   - AD2749: 1 registros\n",
      "   - AD9157: 1 registros\n",
      "   - AD4048: 1 registros\n",
      "   - AD4409: 1 registros\n",
      "   - AD4008: 1 registros\n",
      "   - AD5052: 1 registros\n",
      "   - AD2611: 1 registros\n",
      "   - AD4458: 1 registros\n",
      "   - AD4014: 1 registros\n",
      "   - AD4438: 1 registros\n",
      "   - AD4439: 1 registros\n",
      "   - AD4620: 1 registros\n",
      "   - AD4564: 1 registros\n",
      "   - AD4565: 1 registros\n",
      "   - AD4153: 1 registros\n",
      "   - AD2713: 1 registros\n",
      "   - AD4047: 1 registros\n",
      "   - AD4508: 1 registros\n",
      "   - AD4528: 1 registros\n",
      "   - AD4232: 1 registros\n",
      "   - AD4943: 1 registros\n",
      "   - AD2841: 1 registros\n",
      "   - AD2800: 1 registros\n",
      "   - AD4113: 1 registros\n",
      "   - AD5244: 1 registros\n",
      "   - AD9161: 1 registros\n",
      "   - AD9288: 1 registros\n",
      "   - AD4233: 1 registros\n",
      "   - AD4854: 1 registros\n",
      "   - AD4855: 1 registros\n",
      "   - AD9128: 1 registros\n",
      "   - AD5187: 1 registros\n",
      "   - AD2543: 1 registros\n",
      "   - AD4346: 1 registros\n",
      "   - AD2690: 1 registros\n",
      "   - AD4284: 1 registros\n",
      "   - AD6936: 1 registros\n",
      "   - AD5226: 1 registros\n",
      "   - AD2499: 1 registros\n",
      "   - AD4450: 1 registros\n",
      "   - AD4108: 1 registros\n",
      "   - AD4075: 1 registros\n",
      "   - AD4577: 1 registros\n",
      "   - AD4888: 1 registros\n",
      "   - AD2757: 1 registros\n",
      "   - AD4524: 1 registros\n",
      "   - AD2400: 1 registros\n",
      "   - AD2619: 1 registros\n",
      "   - AD4155: 1 registros\n",
      "   - AD4866: 1 registros\n",
      "   - AD4867: 1 registros\n",
      "   - AD2608: 1 registros\n",
      "   - AD4132: 1 registros\n",
      "   - AD4230: 1 registros\n",
      "   - AD4460: 1 registros\n",
      "   - AD4210: 1 registros\n",
      "   - AD4580: 1 registros\n",
      "   - AD2654: 1 registros\n",
      "   - AD4352: 1 registros\n",
      "   - AD4238: 1 registros\n",
      "   - AD4261: 1 registros\n",
      "   - AD2866: 1 registros\n",
      "   - AD2837: 1 registros\n",
      "   - AD4336: 1 registros\n",
      "   - AD2476: 1 registros\n",
      "   - AD4167: 1 registros\n",
      "   - AD4195: 1 registros\n",
      "   - AD6962: 1 registros\n",
      "   - AD4082: 1 registros\n",
      "   - AD5210: 1 registros\n",
      "   - AD5211: 1 registros\n",
      "   - AD6418: 1 registros\n",
      "   - AD4489: 1 registros\n",
      "   - AD4179: 1 registros\n",
      "   - AD4493: 1 registros\n",
      "   - AD2863: 1 registros\n",
      "   - AD4667: 1 registros\n",
      "   - AD4323: 1 registros\n",
      "   - AD2701: 1 registros\n",
      "   - AD9089: 1 registros\n",
      "   - AD9088: 1 registros\n",
      "   - AD2408: 1 registros\n",
      "   - AD2419: 1 registros\n",
      "   - AD4363: 1 registros\n",
      "   - AD4038: 1 registros\n",
      "   - AD4850: 1 registros\n",
      "   - AD2960: 1 registros\n",
      "   - AD2416: 1 registros\n",
      "   - AD4604: 1 registros\n",
      "   - AD5086: 1 registros\n",
      "   - AD2920: 1 registros\n",
      "   - AD4213: 1 registros\n",
      "   - AD4395: 1 registros\n",
      "   - AD2404: 1 registros\n",
      "   - AD2720: 1 registros\n",
      "   - AD4998: 1 registros\n",
      "   - AD4286: 1 registros\n",
      "   - AD5028: 1 registros\n",
      "   - AD5388: 1 registros\n",
      "   - AD5348: 1 registros\n",
      "   - AD2995: 1 registros\n",
      "   - AD2724: 1 registros\n",
      "   - AD6964: 1 registros\n",
      "   - AD2538: 1 registros\n",
      "   - AD4151: 1 registros\n",
      "   - AD2438: 1 registros\n",
      "   - AD5070: 1 registros\n",
      "   - AD4049: 1 registros\n",
      "   - AD4328: 1 registros\n",
      "   - AD2449: 1 registros\n",
      "   - AD4303: 1 registros\n",
      "   - AD5066: 1 registros\n",
      "   - AD4013: 1 registros\n",
      "   - AD4282: 1 registros\n",
      "   - AD4087: 1 registros\n",
      "   - AD2944: 1 registros\n",
      "   - AD4045: 1 registros\n",
      "   - AD2681: 1 registros\n",
      "   - AD2326: 1 registros\n",
      "   - AD4726: 1 registros\n",
      "   - AD4025: 1 registros\n",
      "   - AD9002: 1 registros\n",
      "   - AD5098: 1 registros\n",
      "   - AD4996: 1 registros\n",
      "   - AD4847: 1 registros\n",
      "   - AD4890: 1 registros\n",
      "   - AD2692: 1 registros\n",
      "   - AD4043: 1 registros\n",
      "   - AD5200: 1 registros\n",
      "   - AD6902: 1 registros\n",
      "   - AD5065: 1 registros\n",
      "   - AD2518: 1 registros\n",
      "   - AD2769: 1 registros\n",
      "   - AD2940: 1 registros\n",
      "   - AD9802: 1 registros\n",
      "   - AD2636: 1 registros\n",
      "   - AD2464: 1 registros\n",
      "   - AD4200: 1 registros\n",
      "   - AD4308: 1 registros\n",
      "   - AD2433: 1 registros\n",
      "   - AD4441: 1 registros\n",
      "   - AD2695: 1 registros\n",
      "   - AD4751: 1 registros\n",
      "\n",
      "üìä ID_LEG ENCONTRADOS:\n",
      "   - -I: 371 registros\n",
      "   - -M: 291 registros\n",
      "\n",
      "üîß F√ìRMULA VERIFICADA:\n",
      "   Tempo Solo = Start(linha seguinte) - End(linha atual)\n",
      "   Toler√¢ncia aceita: ¬±1 minuto\n",
      "\n",
      "üíæ VARI√ÅVEIS DISPON√çVEIS:\n",
      "   - df2_tempo_solo_resultado: 662 registros\n",
      "   - Cont√©m colunas calculadas e originais para compara√ß√£o\n",
      "\n",
      "üìà COMPARA√á√ÉO COM AN√ÅLISES ANTERIORES:\n",
      "   üìä Tempo Apresenta√ß√£o analisado: 43 registros\n",
      "   üìä Tempo Solo analisado: 662 registros\n",
      "\n",
      "üéØ CONCLUS√ïES:\n",
      "   ‚úÖ Metodologia de an√°lise estabelecida\n",
      "   ‚úÖ Filtros aplicados conforme crit√©rios\n",
      "   ‚úÖ C√°lculos verificados com toler√¢ncia\n",
      "   ‚úÖ Resultados documentados e salvos\n",
      "\n",
      "üí° PR√ìXIMOS PASSOS SUGERIDOS:\n",
      "   1. Analisar registros com c√°lculos incorretos\n",
      "   2. Verificar padr√µes nos erros encontrados\n",
      "   3. Aplicar corre√ß√µes autom√°ticas se necess√°rio\n",
      "   4. Exportar resultados para relat√≥rio\n",
      "   5. Comparar com outras colunas calculadas\n",
      "\n",
      "‚úÖ AN√ÅLISE TEMPO SOLO FINALIZADA!\n"
     ]
    }
   ],
   "source": [
    "# üìä RESUMO CONSOLIDADO - AN√ÅLISE TEMPO SOLO\n",
    "print(\"üìä RESUMO CONSOLIDADO - AN√ÅLISE TEMPO SOLO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Verificar se temos resultados da an√°lise\n",
    "if 'df2_tempo_solo_resultado' in locals():\n",
    "    print(f\"‚úÖ AN√ÅLISE CONCLU√çDA COM SUCESSO!\")\n",
    "    \n",
    "    total_analisado = len(df2_tempo_solo_resultado)\n",
    "    total_original = len(df2)\n",
    "    \n",
    "    print(f\"\\nüìä N√öMEROS PRINCIPAIS:\")\n",
    "    print(f\"   üìã Total de registros no DF2: {total_original:,}\")\n",
    "    print(f\"   üìã Registros analisados: {total_analisado:,}\")\n",
    "    print(f\"   üìã Percentual analisado: {total_analisado/total_original*100:.1f}%\")\n",
    "    \n",
    "    if 'corretos_ad' in locals():\n",
    "        print(f\"   ‚úÖ C√°lculos corretos: {corretos_ad:,}\")\n",
    "        print(f\"   ‚ùå C√°lculos incorretos: {incorretos_ad:,}\")\n",
    "        print(f\"   üìä Taxa de acerto: {corretos_ad/total_analisado*100:.1f}%\")\n",
    "    \n",
    "    print(f\"\\nüìã CRIT√âRIOS APLICADOS:\")\n",
    "    print(f\"   1. ‚úÖ Activity come√ßa com 'AD' (ex: AD4914, AD4840, etc.)\")\n",
    "    print(f\"   2. ‚úÖ Id_Leg termina com '-I' ou '-M'\")\n",
    "    print(f\"   3. ‚úÖ Verifica√ß√£o: Tempo Solo = Start(linha seguinte) - End(linha atual)\")\n",
    "    \n",
    "    # Mostrar distribui√ß√£o das activities encontradas\n",
    "    if len(df2_tempo_solo_resultado) > 0:\n",
    "        print(f\"\\nüìä ACTIVITIES 'AD*' ENCONTRADAS:\")\n",
    "        activity_dist = df2_tempo_solo_resultado['Activity'].value_counts()\n",
    "        for activity, count in activity_dist.items():\n",
    "            print(f\"   - {activity}: {count:,} registros\")\n",
    "        \n",
    "        # Mostrar distribui√ß√£o dos Id_Leg\n",
    "        print(f\"\\nüìä ID_LEG ENCONTRADOS:\")\n",
    "        id_leg_dist = df2_tempo_solo_resultado['Id_Leg'].value_counts().head(10)\n",
    "        for id_leg, count in id_leg_dist.items():\n",
    "            print(f\"   - {id_leg}: {count:,} registros\")\n",
    "    \n",
    "    print(f\"\\nüîß F√ìRMULA VERIFICADA:\")\n",
    "    print(f\"   Tempo Solo = Start(linha seguinte) - End(linha atual)\")\n",
    "    print(f\"   Toler√¢ncia aceita: ¬±1 minuto\")\n",
    "    \n",
    "    print(f\"\\nüíæ VARI√ÅVEIS DISPON√çVEIS:\")\n",
    "    print(f\"   - df2_tempo_solo_resultado: {len(df2_tempo_solo_resultado):,} registros\")\n",
    "    print(f\"   - Cont√©m colunas calculadas e originais para compara√ß√£o\")\n",
    "\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è AN√ÅLISE N√ÉO CONCLU√çDA\")\n",
    "    print(f\"üí° Execute as c√©lulas anteriores para completar a an√°lise\")\n",
    "\n",
    "# Compara√ß√£o com an√°lise anterior (Tempo Apresenta√ß√£o)\n",
    "print(f\"\\nüìà COMPARA√á√ÉO COM AN√ÅLISES ANTERIORES:\")\n",
    "\n",
    "if 'df2_tempo_apresentacao' in locals():\n",
    "    tempo_apres_count = len(df2_tempo_apresentacao)\n",
    "    print(f\"   üìä Tempo Apresenta√ß√£o analisado: {tempo_apres_count:,} registros\")\n",
    "else:\n",
    "    print(f\"   üìä Tempo Apresenta√ß√£o: n√£o analisado\")\n",
    "\n",
    "if 'df2_tempo_solo_resultado' in locals():\n",
    "    tempo_solo_count = len(df2_tempo_solo_resultado)\n",
    "    print(f\"   üìä Tempo Solo analisado: {tempo_solo_count:,} registros\")\n",
    "else:\n",
    "    print(f\"   üìä Tempo Solo: n√£o analisado\")\n",
    "\n",
    "print(f\"\\nüéØ CONCLUS√ïES:\")\n",
    "print(f\"   ‚úÖ Metodologia de an√°lise estabelecida\")\n",
    "print(f\"   ‚úÖ Filtros aplicados conforme crit√©rios\")\n",
    "print(f\"   ‚úÖ C√°lculos verificados com toler√¢ncia\")\n",
    "print(f\"   ‚úÖ Resultados documentados e salvos\")\n",
    "\n",
    "# Sugest√µes para pr√≥ximos passos\n",
    "print(f\"\\nüí° PR√ìXIMOS PASSOS SUGERIDOS:\")\n",
    "print(f\"   1. Analisar registros com c√°lculos incorretos\")\n",
    "print(f\"   2. Verificar padr√µes nos erros encontrados\")\n",
    "print(f\"   3. Aplicar corre√ß√µes autom√°ticas se necess√°rio\")\n",
    "print(f\"   4. Exportar resultados para relat√≥rio\")\n",
    "print(f\"   5. Comparar com outras colunas calculadas\")\n",
    "\n",
    "print(f\"\\n‚úÖ AN√ÅLISE TEMPO SOLO FINALIZADA!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5f4c7faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AN√ÅLISE FINAL DA COLUNA 'TEMPO SOLO' ===\n",
      "Crit√©rios:\n",
      "- Activity deve estar em tipos_voo.json\n",
      "- Id_Leg deve terminar com -I ou -M\n",
      "- Tempo Solo = Start da pr√≥xima linha - End da linha atual\n",
      "- Gerar log.csv com as colunas especificadas\n",
      "============================================================\n",
      "Dataset df2 dispon√≠vel com 2541 registros\n",
      "Tipos de voo dispon√≠veis: 11 tipos\n",
      "\n",
      "Colunas dispon√≠veis: ['Activity', 'Id_Leg', 'Checkin', 'Start', 'End', 'Checkout', 'Tempo Solo']\n",
      "\n",
      "‚úÖ Colunas essenciais dispon√≠veis - Iniciando an√°lise...\n",
      "\n",
      "üìã Aplicando filtros...\n",
      "Filtro Activity: 43 registros\n",
      "Filtro Id_Leg: 683 registros\n",
      "Filtro combinado: 0 registros\n",
      "\n",
      "‚ùå Nenhum registro passou pelos filtros aplicados\n"
     ]
    }
   ],
   "source": [
    "print(\"=== AN√ÅLISE FINAL DA COLUNA 'TEMPO SOLO' ===\")\n",
    "print(\"Crit√©rios:\")\n",
    "print(\"- Activity deve estar em tipos_voo.json\")\n",
    "print(\"- Id_Leg deve terminar com -I ou -M\")\n",
    "print(\"- Tempo Solo = Start da pr√≥xima linha - End da linha atual\")\n",
    "print(\"- Gerar log.csv com as colunas especificadas\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Verificar se os dados est√£o dispon√≠veis\n",
    "if 'df2' not in locals():\n",
    "    print(\"ERRO: df2 n√£o est√° dispon√≠vel\")\n",
    "elif 'tipos_voo_lista' not in locals():\n",
    "    print(\"ERRO: tipos_voo_lista n√£o est√° dispon√≠vel\")\n",
    "else:\n",
    "    print(f\"Dataset df2 dispon√≠vel com {len(df2)} registros\")\n",
    "    print(f\"Tipos de voo dispon√≠veis: {len(tipos_voo_lista)} tipos\")\n",
    "    \n",
    "    # Verificar colunas necess√°rias\n",
    "    colunas_necessarias_final = ['Activity', 'Id_Leg', 'Checkin', 'Start', 'End', 'Checkout', 'Tempo Solo']\n",
    "    colunas_disponiveis = []\n",
    "    colunas_faltando = []\n",
    "    \n",
    "    for col in colunas_necessarias_final:\n",
    "        if col in df2.columns:\n",
    "            colunas_disponiveis.append(col)\n",
    "        else:\n",
    "            colunas_faltando.append(col)\n",
    "    \n",
    "    print(f\"\\nColunas dispon√≠veis: {colunas_disponiveis}\")\n",
    "    if colunas_faltando:\n",
    "        print(f\"Colunas faltando: {colunas_faltando}\")\n",
    "    \n",
    "    # Proceder com a an√°lise se as colunas essenciais est√£o dispon√≠veis\n",
    "    if all(col in df2.columns for col in ['Activity', 'Id_Leg', 'Start', 'End']):\n",
    "        print(\"\\n‚úÖ Colunas essenciais dispon√≠veis - Iniciando an√°lise...\")\n",
    "        \n",
    "        # Aplicar filtros\n",
    "        print(\"\\nüìã Aplicando filtros...\")\n",
    "        \n",
    "        # Filtro 1: Activity deve estar em tipos_voo.json\n",
    "        filtro_activity_final = df2['Activity'].isin(tipos_voo_lista)\n",
    "        registros_activity_final = filtro_activity_final.sum()\n",
    "        print(f\"Filtro Activity: {registros_activity_final} registros\")\n",
    "        \n",
    "        # Filtro 2: Id_Leg deve terminar com -I ou -M\n",
    "        filtro_id_leg_final = df2['Id_Leg'].str.endswith(('-I', '-M'), na=False)\n",
    "        registros_id_leg_final = filtro_id_leg_final.sum()\n",
    "        print(f\"Filtro Id_Leg: {registros_id_leg_final} registros\")\n",
    "        \n",
    "        # Filtro combinado\n",
    "        filtro_combinado_final = filtro_activity_final & filtro_id_leg_final\n",
    "        registros_combinado_final = filtro_combinado_final.sum()\n",
    "        print(f\"Filtro combinado: {registros_combinado_final} registros\")\n",
    "        \n",
    "        # Aplicar filtros\n",
    "        df2_filtrado_final = df2[filtro_combinado_final].copy()\n",
    "        \n",
    "        if len(df2_filtrado_final) > 0:\n",
    "            print(f\"\\n‚úÖ Dataset filtrado criado com {len(df2_filtrado_final)} registros\")\n",
    "            \n",
    "            # Calcular Tempo Solo\n",
    "            print(\"\\n‚è±Ô∏è Calculando Tempo Solo...\")\n",
    "            \n",
    "            # Ordenar por √≠ndice para garantir ordem correta\n",
    "            df2_filtrado_final = df2_filtrado_final.sort_index()\n",
    "            \n",
    "            # Calcular Tempo Solo (Start da pr√≥xima linha - End da linha atual)\n",
    "            tempo_solo_calculado = []\n",
    "            \n",
    "            for i in range(len(df2_filtrado_final)):\n",
    "                if i < len(df2_filtrado_final) - 1:  # N√£o √© a √∫ltima linha\n",
    "                    try:\n",
    "                        end_atual = pd.to_datetime(df2_filtrado_final.iloc[i]['End'])\n",
    "                        start_proximo = pd.to_datetime(df2_filtrado_final.iloc[i+1]['Start'])\n",
    "                        tempo_solo = start_proximo - end_atual\n",
    "                        tempo_solo_calculado.append(tempo_solo)\n",
    "                    except:\n",
    "                        tempo_solo_calculado.append(pd.NaT)\n",
    "                else:  # √öltima linha\n",
    "                    tempo_solo_calculado.append(pd.NaT)\n",
    "            \n",
    "            # Adicionar coluna calculada\n",
    "            df2_filtrado_final['Tempo_Solo_Calculado'] = tempo_solo_calculado\n",
    "            \n",
    "            print(f\"Tempo Solo calculado para {len([x for x in tempo_solo_calculado if pd.notna(x)])} registros\")\n",
    "            \n",
    "            # Preparar dados para log.csv\n",
    "            print(\"\\nüìÑ Preparando dados para log.csv...\")\n",
    "            \n",
    "            # Selecionar apenas as colunas necess√°rias\n",
    "            colunas_log = ['Activity', 'Id_Leg', 'Checkin', 'Start', 'End', 'Checkout', 'Tempo Solo']\n",
    "            \n",
    "            # Criar dataframe para log\n",
    "            df_log = df2_filtrado_final.copy()\n",
    "            \n",
    "            # Usar Tempo Solo original se existir, sen√£o usar calculado\n",
    "            if 'Tempo Solo' in df_log.columns:\n",
    "                # Manter coluna original\n",
    "                pass\n",
    "            else:\n",
    "                # Usar calculado\n",
    "                df_log['Tempo Solo'] = df_log['Tempo_Solo_Calculado']\n",
    "            \n",
    "            # Selecionar apenas colunas que existem\n",
    "            colunas_log_existentes = [col for col in colunas_log if col in df_log.columns]\n",
    "            df_log_final = df_log[colunas_log_existentes]\n",
    "            \n",
    "            print(f\"Colunas no log: {list(df_log_final.columns)}\")\n",
    "            print(f\"Registros no log: {len(df_log_final)}\")\n",
    "            \n",
    "            # Salvar log.csv\n",
    "            caminho_log = \"log.csv\"\n",
    "            df_log_final.to_csv(caminho_log, index=False, encoding='utf-8')\n",
    "            print(f\"\\n‚úÖ Arquivo log.csv salvo com {len(df_log_final)} registros\")\n",
    "            \n",
    "            # Mostrar estat√≠sticas\n",
    "            print(\"\\nüìä Estat√≠sticas do log.csv:\")\n",
    "            print(f\"- Total de registros: {len(df_log_final)}\")\n",
    "            \n",
    "            # Estat√≠sticas por Activity\n",
    "            if 'Activity' in df_log_final.columns:\n",
    "                activity_counts = df_log_final['Activity'].value_counts()\n",
    "                print(f\"- Distribui√ß√£o por Activity:\")\n",
    "                for activity, count in activity_counts.head(10).items():\n",
    "                    print(f\"  {activity}: {count} registros\")\n",
    "            \n",
    "            # Estat√≠sticas por Id_Leg\n",
    "            if 'Id_Leg' in df_log_final.columns:\n",
    "                id_leg_final_counts = df_log_final['Id_Leg'].str[-2:].value_counts()\n",
    "                print(f\"- Distribui√ß√£o por termina√ß√£o Id_Leg:\")\n",
    "                for term, count in id_leg_final_counts.items():\n",
    "                    print(f\"  {term}: {count} registros\")\n",
    "            \n",
    "            # Verificar valores nulos em Tempo Solo\n",
    "            if 'Tempo Solo' in df_log_final.columns:\n",
    "                tempo_solo_nulos_final = df_log_final['Tempo Solo'].isna().sum()\n",
    "                tempo_solo_validos_final = len(df_log_final) - tempo_solo_nulos_final\n",
    "                print(f\"- Tempo Solo v√°lidos: {tempo_solo_validos_final}\")\n",
    "                print(f\"- Tempo Solo nulos: {tempo_solo_nulos_final}\")\n",
    "                \n",
    "                # Mostrar alguns exemplos de Tempo Solo\n",
    "                if tempo_solo_validos_final > 0:\n",
    "                    print(\"\\nüìù Exemplos de Tempo Solo (primeiros 5 registros v√°lidos):\")\n",
    "                    exemplos_tempo_solo = df_log_final[df_log_final['Tempo Solo'].notna()].head(5)\n",
    "                    for idx, row in exemplos_tempo_solo.iterrows():\n",
    "                        print(f\"  Activity: {row.get('Activity', 'N/A')}, Id_Leg: {row.get('Id_Leg', 'N/A')}, Tempo Solo: {row.get('Tempo Solo', 'N/A')}\")\n",
    "            \n",
    "            print(f\"\\n‚úÖ An√°lise conclu√≠da! Arquivo log.csv dispon√≠vel em: {caminho_log}\")\n",
    "            \n",
    "        else:\n",
    "            print(\"\\n‚ùå Nenhum registro passou pelos filtros aplicados\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå Colunas essenciais n√£o est√£o dispon√≠veis para an√°lise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b68ab4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INVESTIGA√á√ÉO DETALHADA DOS FILTROS ===\n",
      "Analisando por que n√£o h√° intersec√ß√£o entre os filtros...\n",
      "\n",
      "üìä AN√ÅLISE DO FILTRO ACTIVITY:\n",
      "Tipos de voo na lista: ['AD', 'SFX', 'PSM', 'S02', 'S06', 'S10', 'S14', '818', 'S22', 'CPT', 'APT']\n",
      "\n",
      "Activities no dataset (Top 20):\n",
      "  ‚ùå FR: 485 registros\n",
      "  ‚ùå FER: 180 registros\n",
      "  ‚ùå SNA: 178 registros\n",
      "  ‚ùå F: 147 registros\n",
      "  ‚ùå EAD: 33 registros\n",
      "  ‚úÖ SFX: 27 registros\n",
      "  ‚ùå DOP: 26 registros\n",
      "  ‚ùå FP: 25 registros\n",
      "  ‚ùå BUS: 25 registros\n",
      "  ‚ùå PP1: 23 registros\n",
      "  ‚ùå DMI: 20 registros\n",
      "  ‚ùå RES: 19 registros\n",
      "  ‚ùå PP2: 18 registros\n",
      "  ‚ùå PLT: 16 registros\n",
      "  ‚ùå FJC24: 13 registros\n",
      "  ‚ùå DMI24: 12 registros\n",
      "  ‚ùå CMA: 11 registros\n",
      "  ‚ùå AD4914: 9 registros\n",
      "  ‚ùå AD4915: 9 registros\n",
      "  ‚ùå REX: 9 registros\n",
      "\n",
      "üìä AN√ÅLISE DO FILTRO ID_LEG:\n",
      "Total de Id_Leg √∫nicos: 4\n",
      "Termina√ß√µes de Id_Leg mais comuns:\n",
      "  ‚ùå IF: 1466 registros\n",
      "  ‚úÖ -I: 392 registros\n",
      "  ‚ùå -F: 392 registros\n",
      "  ‚úÖ -M: 291 registros\n",
      "\n",
      "üìä INVESTIGA√á√ÉO DA INTERSEC√á√ÉO:\n",
      "Registros com Activity v√°lido: 43\n",
      "Activities v√°lidos encontrados:\n",
      "  - S10: 4 registros\n",
      "  - S06: 1 registros\n",
      "  - S22: 1 registros\n",
      "  - SFX: 27 registros\n",
      "  - S14: 1 registros\n",
      "  - APT: 8 registros\n",
      "  - CPT: 1 registros\n",
      "\n",
      "Id_Leg nos registros com Activity v√°lido:\n",
      "  ‚ùå IF: 43 registros\n",
      "\n",
      "üìä VERIFICA√á√ÉO DE REGISTROS COM ID_LEG V√ÅLIDO:\n",
      "Registros com Id_Leg v√°lido: 683\n",
      "Activities nos registros com Id_Leg v√°lido:\n",
      "  ‚ùå RES: 13 registros\n",
      "  ‚ùå AD4914: 7 registros\n",
      "  ‚ùå BUS: 6 registros\n",
      "  ‚ùå AD4840: 6 registros\n",
      "  ‚ùå AD5024: 5 registros\n",
      "  ‚ùå AD4572: 5 registros\n",
      "  ‚ùå AD4080: 5 registros\n",
      "  ‚ùå AD2498: 5 registros\n",
      "  ‚ùå AD4004: 4 registros\n",
      "  ‚ùå AD2917: 4 registros\n"
     ]
    }
   ],
   "source": [
    "print(\"=== INVESTIGA√á√ÉO DETALHADA DOS FILTROS ===\")\n",
    "print(\"Analisando por que n√£o h√° intersec√ß√£o entre os filtros...\")\n",
    "print()\n",
    "\n",
    "# Investigar filtro de Activity\n",
    "print(\"üìä AN√ÅLISE DO FILTRO ACTIVITY:\")\n",
    "print(f\"Tipos de voo na lista: {tipos_voo_lista}\")\n",
    "print()\n",
    "\n",
    "# Ver quais Activities existem nos dados e quantos passam no filtro\n",
    "activity_no_dataset = df2['Activity'].value_counts()\n",
    "print(\"Activities no dataset (Top 20):\")\n",
    "for activity, count in activity_no_dataset.head(20).items():\n",
    "    esta_na_lista = activity in tipos_voo_lista\n",
    "    status = \"‚úÖ\" if esta_na_lista else \"‚ùå\"\n",
    "    print(f\"  {status} {activity}: {count} registros\")\n",
    "\n",
    "print()\n",
    "print(\"üìä AN√ÅLISE DO FILTRO ID_LEG:\")\n",
    "\n",
    "# Ver quais Id_Leg existem e quantos terminam com -I ou -M\n",
    "id_leg_no_dataset = df2['Id_Leg'].value_counts()\n",
    "print(f\"Total de Id_Leg √∫nicos: {len(id_leg_no_dataset)}\")\n",
    "\n",
    "# Verificar termina√ß√µes\n",
    "terminacoes = df2['Id_Leg'].str[-2:].value_counts()\n",
    "print(\"Termina√ß√µes de Id_Leg mais comuns:\")\n",
    "for term, count in terminacoes.head(10).items():\n",
    "    valido = term in ['-I', '-M']\n",
    "    status = \"‚úÖ\" if valido else \"‚ùå\"\n",
    "    print(f\"  {status} {term}: {count} registros\")\n",
    "\n",
    "print()\n",
    "print(\"üìä INVESTIGA√á√ÉO DA INTERSEC√á√ÉO:\")\n",
    "\n",
    "# Verificar se h√° registros com Activity v√°lido\n",
    "registros_activity_validos = df2[df2['Activity'].isin(tipos_voo_lista)]\n",
    "print(f\"Registros com Activity v√°lido: {len(registros_activity_validos)}\")\n",
    "\n",
    "if len(registros_activity_validos) > 0:\n",
    "    print(\"Activities v√°lidos encontrados:\")\n",
    "    for activity in registros_activity_validos['Activity'].unique():\n",
    "        count = (registros_activity_validos['Activity'] == activity).sum()\n",
    "        print(f\"  - {activity}: {count} registros\")\n",
    "    \n",
    "    print()\n",
    "    print(\"Id_Leg nos registros com Activity v√°lido:\")\n",
    "    id_leg_activity_validos = registros_activity_validos['Id_Leg'].str[-2:].value_counts()\n",
    "    for term, count in id_leg_activity_validos.head(10).items():\n",
    "        valido = term in ['-I', '-M']\n",
    "        status = \"‚úÖ\" if valido else \"‚ùå\"\n",
    "        print(f\"  {status} {term}: {count} registros\")\n",
    "\n",
    "print()\n",
    "print(\"üìä VERIFICA√á√ÉO DE REGISTROS COM ID_LEG V√ÅLIDO:\")\n",
    "registros_id_leg_validos = df2[df2['Id_Leg'].str.endswith(('-I', '-M'), na=False)]\n",
    "print(f\"Registros com Id_Leg v√°lido: {len(registros_id_leg_validos)}\")\n",
    "\n",
    "if len(registros_id_leg_validos) > 0:\n",
    "    print(\"Activities nos registros com Id_Leg v√°lido:\")\n",
    "    activity_id_leg_validos = registros_id_leg_validos['Activity'].value_counts()\n",
    "    for activity, count in activity_id_leg_validos.head(10).items():\n",
    "        esta_na_lista = activity in tipos_voo_lista\n",
    "        status = \"‚úÖ\" if esta_na_lista else \"‚ùå\"\n",
    "        print(f\"  {status} {activity}: {count} registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "74c3caf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AN√ÅLISE ALTERNATIVA CONSIDERANDO OS DADOS REAIS ===\n",
      "Baseado na investiga√ß√£o anterior, vamos testar cen√°rios alternativos:\n",
      "\n",
      "üîç CEN√ÅRIO 1: Activity v√°lido + Id_Leg terminando com 'IF'\n",
      "Registros encontrados: 43\n",
      "Activities encontradas:\n",
      "  - S10: 4 registros\n",
      "  - S06: 1 registros\n",
      "  - S22: 1 registros\n",
      "  - SFX: 27 registros\n",
      "  - S14: 1 registros\n",
      "  - APT: 8 registros\n",
      "  - CPT: 1 registros\n",
      "\n",
      "üîç CEN√ÅRIO 2: Activity contendo 'AD' + Id_Leg terminando com '-I' ou '-M'\n",
      "Registros encontrados: 663\n",
      "Activities encontradas:\n",
      "  - AD4914: 7 registros\n",
      "  - AD4840: 6 registros\n",
      "  - AD2498: 5 registros\n",
      "  - AD5024: 5 registros\n",
      "  - AD4572: 5 registros\n",
      "  - AD4080: 5 registros\n",
      "  - AD2990: 4 registros\n",
      "  - AD4942: 4 registros\n",
      "  - AD5450: 4 registros\n",
      "  - AD4347: 4 registros\n",
      "  - AD5749: 4 registros\n",
      "  - AD2917: 4 registros\n",
      "  - AD4079: 4 registros\n",
      "  - AD2520: 4 registros\n",
      "  - AD4004: 4 registros\n",
      "  - AD5215: 4 registros\n",
      "  - AD4350: 4 registros\n",
      "  - AD4149: 4 registros\n",
      "  - AD4218: 3 registros\n",
      "  - AD4698: 3 registros\n",
      "  - AD4490: 3 registros\n",
      "  - AD4876: 3 registros\n",
      "  - AD2643: 3 registros\n",
      "  - AD2899: 3 registros\n",
      "  - AD2852: 3 registros\n",
      "  - AD2883: 3 registros\n",
      "  - AD4342: 3 registros\n",
      "  - AD5728: 3 registros\n",
      "  - AD4776: 3 registros\n",
      "  - AD2945: 3 registros\n",
      "  - AD4204: 3 registros\n",
      "  - AD4160: 3 registros\n",
      "  - AD4617: 3 registros\n",
      "  - AD4796: 3 registros\n",
      "  - AD4031: 3 registros\n",
      "  - AD5041: 3 registros\n",
      "  - AD4145: 3 registros\n",
      "  - AD4239: 3 registros\n",
      "  - AD4166: 3 registros\n",
      "  - AD4028: 3 registros\n",
      "  - AD2787: 3 registros\n",
      "  - AD2723: 3 registros\n",
      "  - AD2829: 3 registros\n",
      "  - AD2830: 2 registros\n",
      "  - AD5056: 2 registros\n",
      "  - AD4479: 2 registros\n",
      "  - AD4852: 2 registros\n",
      "  - AD4990: 2 registros\n",
      "  - AD4148: 2 registros\n",
      "  - AD4057: 2 registros\n",
      "  - AD4905: 2 registros\n",
      "  - AD2653: 2 registros\n",
      "  - AD4250: 2 registros\n",
      "  - AD4206: 2 registros\n",
      "  - AD2921: 2 registros\n",
      "  - AD4379: 2 registros\n",
      "  - AD2826: 2 registros\n",
      "  - AD5093: 2 registros\n",
      "  - AD5168: 2 registros\n",
      "  - AD4005: 2 registros\n",
      "  - AD5756: 2 registros\n",
      "  - AD4512: 2 registros\n",
      "  - AD5282: 2 registros\n",
      "  - AD2991: 2 registros\n",
      "  - AD2890: 2 registros\n",
      "  - AD2434: 2 registros\n",
      "  - AD4501: 2 registros\n",
      "  - AD2705: 2 registros\n",
      "  - AD4345: 2 registros\n",
      "  - AD4360: 2 registros\n",
      "  - AD5257: 2 registros\n",
      "  - AD4824: 2 registros\n",
      "  - AD4216: 2 registros\n",
      "  - AD4631: 2 registros\n",
      "  - AD2785: 2 registros\n",
      "  - AD4474: 2 registros\n",
      "  - AD4433: 2 registros\n",
      "  - AD4260: 2 registros\n",
      "  - AD9110: 2 registros\n",
      "  - AD4906: 2 registros\n",
      "  - AD4144: 2 registros\n",
      "  - AD2840: 2 registros\n",
      "  - AD4422: 2 registros\n",
      "  - AD4769: 2 registros\n",
      "  - AD4338: 2 registros\n",
      "  - AD4628: 2 registros\n",
      "  - AD2483: 2 registros\n",
      "  - AD4995: 2 registros\n",
      "  - AD4554: 2 registros\n",
      "  - AD2810: 2 registros\n",
      "  - AD4917: 2 registros\n",
      "  - AD4016: 2 registros\n",
      "  - AD5016: 2 registros\n",
      "  - AD5169: 2 registros\n",
      "  - AD4503: 2 registros\n",
      "  - AD4498: 2 registros\n",
      "  - AD2886: 2 registros\n",
      "  - AD2751: 2 registros\n",
      "  - AD2500: 2 registros\n",
      "  - AD5500: 2 registros\n",
      "  - AD4569: 2 registros\n",
      "  - AD4161: 2 registros\n",
      "  - AD4472: 2 registros\n",
      "  - AD4175: 2 registros\n",
      "  - AD4431: 2 registros\n",
      "  - AD4340: 2 registros\n",
      "  - AD2688: 2 registros\n",
      "  - AD4522: 2 registros\n",
      "  - AD4293: 2 registros\n",
      "  - AD4177: 2 registros\n",
      "  - AD4348: 2 registros\n",
      "  - AD4026: 2 registros\n",
      "  - AD4444: 2 registros\n",
      "  - AD4337: 2 registros\n",
      "  - AD4864: 2 registros\n",
      "  - AD2885: 2 registros\n",
      "  - AD4171: 2 registros\n",
      "  - AD4174: 2 registros\n",
      "  - AD4432: 2 registros\n",
      "  - AD4605: 2 registros\n",
      "  - AD4201: 2 registros\n",
      "  - AD6928: 2 registros\n",
      "  - AD4036: 2 registros\n",
      "  - AD5166: 2 registros\n",
      "  - AD5704: 2 registros\n",
      "  - AD5808: 2 registros\n",
      "  - AD4469: 2 registros\n",
      "  - AD4871: 2 registros\n",
      "  - AD4251: 2 registros\n",
      "  - AD4109: 2 registros\n",
      "  - AD4986: 2 registros\n",
      "  - AD2479: 2 registros\n",
      "  - AD4058: 2 registros\n",
      "  - AD4411: 2 registros\n",
      "  - AD2458: 2 registros\n",
      "  - AD5149: 2 registros\n",
      "  - AD4253: 2 registros\n",
      "  - AD5059: 2 registros\n",
      "  - AD2916: 2 registros\n",
      "  - AD4064: 2 registros\n",
      "  - AD2978: 2 registros\n",
      "  - AD4351: 2 registros\n",
      "  - AD9087: 2 registros\n",
      "  - AD5352: 2 registros\n",
      "  - AD4684: 2 registros\n",
      "  - AD4150: 2 registros\n",
      "  - AD2940: 1 registros\n",
      "  - AD5046: 1 registros\n",
      "  - AD2433: 1 registros\n",
      "  - AD4441: 1 registros\n",
      "  - AD4013: 1 registros\n",
      "  - AD4282: 1 registros\n",
      "  - AD6902: 1 registros\n",
      "  - AD5065: 1 registros\n",
      "  - AD2518: 1 registros\n",
      "  - AD4646: 1 registros\n",
      "  - AD4847: 1 registros\n",
      "  - AD4996: 1 registros\n",
      "  - AD5098: 1 registros\n",
      "  - AD4998: 1 registros\n",
      "  - AD4930: 1 registros\n",
      "  - AD2926: 1 registros\n",
      "  - AD2954: 1 registros\n",
      "  - AD4234: 1 registros\n",
      "  - AD4430: 1 registros\n",
      "  - AD2797: 1 registros\n",
      "  - AD2741: 1 registros\n",
      "  - AD4481: 1 registros\n",
      "  - AD2695: 1 registros\n",
      "  - AD9802: 1 registros\n",
      "  - AD2636: 1 registros\n",
      "  - AD2464: 1 registros\n",
      "  - AD4200: 1 registros\n",
      "  - AD4308: 1 registros\n",
      "  - AD4591: 1 registros\n",
      "  - AD2665: 1 registros\n",
      "  - AD4296: 1 registros\n",
      "  - AD4236: 1 registros\n",
      "  - AD5071: 1 registros\n",
      "  - AD6976: 1 registros\n",
      "  - AD6977: 1 registros\n",
      "  - AD4146: 1 registros\n",
      "  - AD5136: 1 registros\n",
      "  - AD5280: 1 registros\n",
      "  - AD5454: 1 registros\n",
      "  - AD5467: 1 registros\n",
      "  - AD2989: 1 registros\n",
      "  - AD4264: 1 registros\n",
      "  - AD4252: 1 registros\n",
      "  - AD9801: 1 registros\n",
      "  - AD9094: 1 registros\n",
      "  - AD4133: 1 registros\n",
      "  - AD4873: 1 registros\n",
      "  - AD5175: 1 registros\n",
      "  - AD4949: 1 registros\n",
      "  - AD2813: 1 registros\n",
      "  - AD4298: 1 registros\n",
      "  - AD4299: 1 registros\n",
      "  - AD5402: 1 registros\n",
      "  - AD4487: 1 registros\n",
      "  - AD4988: 1 registros\n",
      "  - AD5438: 1 registros\n",
      "  - AD4331: 1 registros\n",
      "  - AD2475: 1 registros\n",
      "  - AD9640: 1 registros\n",
      "  - AD5709: 1 registros\n",
      "  - AD4110: 1 registros\n",
      "  - AD4103: 1 registros\n",
      "  - AD9134: 1 registros\n",
      "  - AD5468: 1 registros\n",
      "  - AD2411: 1 registros\n",
      "  - AD2517: 1 registros\n",
      "  - AD2602: 1 registros\n",
      "  - AD9206: 1 registros\n",
      "  - AD4494: 1 registros\n",
      "  - AD5108: 1 registros\n",
      "  - AD5123: 1 registros\n",
      "  - AD2556: 1 registros\n",
      "  - AD4862: 1 registros\n",
      "  - AD4869: 1 registros\n",
      "  - AD4870: 1 registros\n",
      "  - AD5114: 1 registros\n",
      "  - AD4237: 1 registros\n",
      "  - AD2406: 1 registros\n",
      "  - AD4104: 1 registros\n",
      "  - AD5201: 1 registros\n",
      "  - AD2781: 1 registros\n",
      "  - AD4860: 1 registros\n",
      "  - AD5312: 1 registros\n",
      "  - AD5313: 1 registros\n",
      "  - AD5740: 1 registros\n",
      "  - AD5442: 1 registros\n",
      "  - AD2638: 1 registros\n",
      "  - AD4470: 1 registros\n",
      "  - AD5100: 1 registros\n",
      "  - AD5790: 1 registros\n",
      "  - AD4269: 1 registros\n",
      "  - AD4043: 1 registros\n",
      "  - AD5200: 1 registros\n",
      "  - AD4568: 1 registros\n",
      "  - AD4526: 1 registros\n",
      "  - AD4527: 1 registros\n",
      "  - AD4209: 1 registros\n",
      "  - AD4115: 1 registros\n",
      "  - AD5011: 1 registros\n",
      "  - AD5346: 1 registros\n",
      "  - AD6944: 1 registros\n",
      "  - AD4138: 1 registros\n",
      "  - AD6973: 1 registros\n",
      "  - AD2612: 1 registros\n",
      "  - AD6988: 1 registros\n",
      "  - AD4121: 1 registros\n",
      "  - AD5216: 1 registros\n",
      "  - AD5055: 1 registros\n",
      "  - AD5042: 1 registros\n",
      "  - AD9096: 1 registros\n",
      "  - AD9106: 1 registros\n",
      "  - AD4018: 1 registros\n",
      "  - AD4316: 1 registros\n",
      "  - AD5189: 1 registros\n",
      "  - AD2428: 1 registros\n",
      "  - AD2432: 1 registros\n",
      "  - AD6407: 1 registros\n",
      "  - AD4044: 1 registros\n",
      "  - AD2874: 1 registros\n",
      "  - AD2875: 1 registros\n",
      "  - AD4378: 1 registros\n",
      "  - AD4491: 1 registros\n",
      "  - AD4599: 1 registros\n",
      "  - AD4330: 1 registros\n",
      "  - AD4370: 1 registros\n",
      "  - AD5226: 1 registros\n",
      "  - AD5227: 1 registros\n",
      "  - AD4014: 1 registros\n",
      "  - AD2005: 1 registros\n",
      "  - AD4562: 1 registros\n",
      "  - AD4372: 1 registros\n",
      "  - AD9242: 1 registros\n",
      "  - AD4451: 1 registros\n",
      "  - AD4545: 1 registros\n",
      "  - AD4169: 1 registros\n",
      "  - AD4940: 1 registros\n",
      "  - AD4231: 1 registros\n",
      "  - AD9128: 1 registros\n",
      "  - AD6956: 1 registros\n",
      "  - AD9058: 1 registros\n",
      "  - AD9059: 1 registros\n",
      "  - AD4100: 1 registros\n",
      "  - AD4463: 1 registros\n",
      "  - AD9066: 1 registros\n",
      "  - AD4623: 1 registros\n",
      "  - AD4854: 1 registros\n",
      "  - AD4855: 1 registros\n",
      "  - AD4458: 1 registros\n",
      "  - AD4000: 1 registros\n",
      "  - AD2590: 1 registros\n",
      "  - AD2837: 1 registros\n",
      "  - AD5187: 1 registros\n",
      "  - AD2543: 1 registros\n",
      "  - AD4346: 1 registros\n",
      "  - AD2690: 1 registros\n",
      "  - AD4284: 1 registros\n",
      "  - AD6936: 1 registros\n",
      "  - AD2400: 1 registros\n",
      "  - AD2713: 1 registros\n",
      "  - AD4047: 1 registros\n",
      "  - AD4508: 1 registros\n",
      "  - AD4866: 1 registros\n",
      "  - AD4438: 1 registros\n",
      "  - AD4439: 1 registros\n",
      "  - AD4620: 1 registros\n",
      "  - AD4564: 1 registros\n",
      "  - AD4565: 1 registros\n",
      "  - AD4153: 1 registros\n",
      "  - AD4574: 1 registros\n",
      "  - AD4528: 1 registros\n",
      "  - AD4232: 1 registros\n",
      "  - AD4106: 1 registros\n",
      "  - AD4445: 1 registros\n",
      "  - AD5211: 1 registros\n",
      "  - AD6418: 1 registros\n",
      "  - AD4489: 1 registros\n",
      "  - AD4179: 1 registros\n",
      "  - AD4493: 1 registros\n",
      "  - AD5052: 1 registros\n",
      "  - AD2611: 1 registros\n",
      "  - AD4210: 1 registros\n",
      "  - AD4580: 1 registros\n",
      "  - AD4943: 1 registros\n",
      "  - AD4108: 1 registros\n",
      "  - AD4075: 1 registros\n",
      "  - AD4577: 1 registros\n",
      "  - AD4888: 1 registros\n",
      "  - AD2757: 1 registros\n",
      "  - AD4524: 1 registros\n",
      "  - AD2576: 1 registros\n",
      "  - AD2577: 1 registros\n",
      "  - AD4154: 1 registros\n",
      "  - AD2499: 1 registros\n",
      "  - AD4450: 1 registros\n",
      "  - AD4867: 1 registros\n",
      "  - AD2608: 1 registros\n",
      "  - AD4132: 1 registros\n",
      "  - AD4230: 1 registros\n",
      "  - AD4460: 1 registros\n",
      "  - AD4163: 1 registros\n",
      "  - AD6419: 1 registros\n",
      "  - AD4195: 1 registros\n",
      "  - AD6962: 1 registros\n",
      "  - AD4082: 1 registros\n",
      "  - AD5210: 1 registros\n",
      "  - AD9157: 1 registros\n",
      "  - AD4048: 1 registros\n",
      "  - AD4409: 1 registros\n",
      "  - AD4008: 1 registros\n",
      "  - AD5086: 1 registros\n",
      "  - AD2920: 1 registros\n",
      "  - AD2654: 1 registros\n",
      "  - AD4352: 1 registros\n",
      "  - AD4238: 1 registros\n",
      "  - AD4336: 1 registros\n",
      "  - AD2476: 1 registros\n",
      "  - AD4323: 1 registros\n",
      "  - AD2866: 1 registros\n",
      "  - AD4203: 1 registros\n",
      "  - AD9126: 1 registros\n",
      "  - AD5703: 1 registros\n",
      "  - AD5244: 1 registros\n",
      "  - AD9161: 1 registros\n",
      "  - AD9288: 1 registros\n",
      "  - AD4233: 1 registros\n",
      "  - AD4261: 1 registros\n",
      "  - AD4049: 1 registros\n",
      "  - AD4328: 1 registros\n",
      "  - AD2701: 1 registros\n",
      "  - AD2619: 1 registros\n",
      "  - AD4155: 1 registros\n",
      "  - AD2960: 1 registros\n",
      "  - AD2416: 1 registros\n",
      "  - AD4604: 1 registros\n",
      "  - AD4167: 1 registros\n",
      "  - AD2669: 1 registros\n",
      "  - AD2749: 1 registros\n",
      "  - AD4850: 1 registros\n",
      "  - AD2692: 1 registros\n",
      "  - AD4765: 1 registros\n",
      "  - AD4649: 1 registros\n",
      "  - AD2744: 1 registros\n",
      "  - AD4213: 1 registros\n",
      "  - AD4395: 1 registros\n",
      "  - AD2404: 1 registros\n",
      "  - AD2720: 1 registros\n",
      "  - AD2438: 1 registros\n",
      "  - AD5070: 1 registros\n",
      "  - AD4063: 1 registros\n",
      "  - AD4361: 1 registros\n",
      "  - AD2841: 1 registros\n",
      "  - AD2800: 1 registros\n",
      "  - AD4113: 1 registros\n",
      "  - AD2863: 1 registros\n",
      "  - AD4667: 1 registros\n",
      "  - AD4310: 1 registros\n",
      "  - AD4301: 1 registros\n",
      "  - AD4125: 1 registros\n",
      "  - AD4241: 1 registros\n",
      "  - AD4070: 1 registros\n",
      "  - AD4281: 1 registros\n",
      "  - AD2449: 1 registros\n",
      "  - AD4303: 1 registros\n",
      "  - AD9089: 1 registros\n",
      "  - AD9088: 1 registros\n",
      "  - AD2408: 1 registros\n",
      "  - AD2419: 1 registros\n",
      "  - AD4363: 1 registros\n",
      "  - AD4038: 1 registros\n",
      "  - AD9002: 1 registros\n",
      "  - AD4286: 1 registros\n",
      "  - AD5028: 1 registros\n",
      "  - AD4540: 1 registros\n",
      "  - AD5388: 1 registros\n",
      "  - AD5348: 1 registros\n",
      "  - AD2995: 1 registros\n",
      "  - AD2724: 1 registros\n",
      "  - AD6964: 1 registros\n",
      "  - AD2538: 1 registros\n",
      "  - AD4151: 1 registros\n",
      "  - AD4040: 1 registros\n",
      "  - AD5162: 1 registros\n",
      "  - AD4952: 1 registros\n",
      "  - AD4890: 1 registros\n",
      "  - AD2769: 1 registros\n",
      "  - AD2937: 1 registros\n",
      "  - AD4405: 1 registros\n",
      "  - AD4096: 1 registros\n",
      "  - AD6422: 1 registros\n",
      "  - AD4406: 1 registros\n",
      "  - AD4407: 1 registros\n",
      "  - AD12: 1 registros\n",
      "  - AD5066: 1 registros\n",
      "  - AD4751: 1 registros\n",
      "  - AD4087: 1 registros\n",
      "  - AD2944: 1 registros\n",
      "  - AD4045: 1 registros\n",
      "  - AD2681: 1 registros\n",
      "  - AD2326: 1 registros\n",
      "  - AD4726: 1 registros\n",
      "  - AD4025: 1 registros\n",
      "\n",
      "üîç CEN√ÅRIO 3: Apenas Activity v√°lido (sem filtro Id_Leg)\n",
      "Registros encontrados: 43\n",
      "\n",
      "üîç CEN√ÅRIO 4: Apenas Id_Leg terminando com '-I' ou '-M' (sem filtro Activity)\n",
      "Registros encontrados: 683\n",
      "\n",
      "============================================================\n",
      "üí° RECOMENDA√á√ïES:\n",
      "\n",
      "‚úÖ CEN√ÅRIO 1 √© vi√°vel: 43 registros\n",
      "   - Activities da lista tipos_voo.json + Id_Leg terminando com 'IF'\n",
      "‚úÖ CEN√ÅRIO 2 √© vi√°vel: 663 registros\n",
      "   - Activities contendo 'AD' + Id_Leg terminando com '-I' ou '-M'\n",
      "\n",
      "‚ùì Qual cen√°rio devemos usar para gerar o log.csv?\n",
      "   1. Cen√°rio 1 (Activity da lista + Id_Leg 'IF')\n",
      "   2. Cen√°rio 2 (Activity com 'AD' + Id_Leg '-I' ou '-M')\n",
      "   3. Outro crit√©rio espec√≠fico?\n"
     ]
    }
   ],
   "source": [
    "print(\"=== AN√ÅLISE ALTERNATIVA CONSIDERANDO OS DADOS REAIS ===\")\n",
    "print(\"Baseado na investiga√ß√£o anterior, vamos testar cen√°rios alternativos:\")\n",
    "print()\n",
    "\n",
    "# Cen√°rio 1: Activities da lista + Id_Leg terminando com \"IF\" (que √© o que existe)\n",
    "print(\"üîç CEN√ÅRIO 1: Activity v√°lido + Id_Leg terminando com 'IF'\")\n",
    "filtro_activity_alt1 = df2['Activity'].isin(tipos_voo_lista)\n",
    "filtro_id_leg_alt1 = df2['Id_Leg'].str.endswith('IF', na=False)\n",
    "filtro_combinado_alt1 = filtro_activity_alt1 & filtro_id_leg_alt1\n",
    "registros_alt1 = filtro_combinado_alt1.sum()\n",
    "print(f\"Registros encontrados: {registros_alt1}\")\n",
    "\n",
    "if registros_alt1 > 0:\n",
    "    df_alt1 = df2[filtro_combinado_alt1].copy()\n",
    "    print(\"Activities encontradas:\")\n",
    "    for activity in df_alt1['Activity'].unique():\n",
    "        count = (df_alt1['Activity'] == activity).sum()\n",
    "        print(f\"  - {activity}: {count} registros\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Cen√°rio 2: Activities com \"AD\" + Id_Leg terminando com -I ou -M\n",
    "print(\"üîç CEN√ÅRIO 2: Activity contendo 'AD' + Id_Leg terminando com '-I' ou '-M'\")\n",
    "filtro_activity_alt2 = df2['Activity'].str.contains('AD', na=False)\n",
    "filtro_id_leg_alt2 = df2['Id_Leg'].str.endswith(('-I', '-M'), na=False)\n",
    "filtro_combinado_alt2 = filtro_activity_alt2 & filtro_id_leg_alt2\n",
    "registros_alt2 = filtro_combinado_alt2.sum()\n",
    "print(f\"Registros encontrados: {registros_alt2}\")\n",
    "\n",
    "if registros_alt2 > 0:\n",
    "    df_alt2 = df2[filtro_combinado_alt2].copy()\n",
    "    print(\"Activities encontradas:\")\n",
    "    activities_alt2 = df_alt2['Activity'].value_counts()\n",
    "    for activity, count in activities_alt2.items():\n",
    "        print(f\"  - {activity}: {count} registros\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Cen√°rio 3: Apenas Activities da lista (sem filtro de Id_Leg)\n",
    "print(\"üîç CEN√ÅRIO 3: Apenas Activity v√°lido (sem filtro Id_Leg)\")\n",
    "registros_alt3 = filtro_activity_alt1.sum()\n",
    "print(f\"Registros encontrados: {registros_alt3}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Cen√°rio 4: Apenas Id_Leg terminando com -I ou -M (sem filtro de Activity)\n",
    "print(\"üîç CEN√ÅRIO 4: Apenas Id_Leg terminando com '-I' ou '-M' (sem filtro Activity)\")\n",
    "registros_alt4 = df2['Id_Leg'].str.endswith(('-I', '-M'), na=False).sum()\n",
    "print(f\"Registros encontrados: {registros_alt4}\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"üí° RECOMENDA√á√ïES:\")\n",
    "print()\n",
    "\n",
    "if registros_alt1 > 0:\n",
    "    print(f\"‚úÖ CEN√ÅRIO 1 √© vi√°vel: {registros_alt1} registros\")\n",
    "    print(\"   - Activities da lista tipos_voo.json + Id_Leg terminando com 'IF'\")\n",
    "    \n",
    "if registros_alt2 > 0:\n",
    "    print(f\"‚úÖ CEN√ÅRIO 2 √© vi√°vel: {registros_alt2} registros\")\n",
    "    print(\"   - Activities contendo 'AD' + Id_Leg terminando com '-I' ou '-M'\")\n",
    "\n",
    "print()\n",
    "print(\"‚ùì Qual cen√°rio devemos usar para gerar o log.csv?\")\n",
    "print(\"   1. Cen√°rio 1 (Activity da lista + Id_Leg 'IF')\")\n",
    "print(\"   2. Cen√°rio 2 (Activity com 'AD' + Id_Leg '-I' ou '-M')\")\n",
    "print(\"   3. Outro crit√©rio espec√≠fico?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "57033803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RESUMO DOS CEN√ÅRIOS POSS√çVEIS ===\n",
      "CEN√ÅRIO 1 (Activity lista + Id_Leg 'IF'): 43 registros\n",
      "CEN√ÅRIO 2 (Activity 'AD*' + Id_Leg '-I'/'-M'): 663 registros\n",
      "\n",
      "‚úÖ Usando CEN√ÅRIO 2 para gerar log.csv (663 registros)\n",
      "\n",
      "üìä Registros filtrados: 663\n",
      "Activities encontradas:\n",
      "  - AD4914: 7\n",
      "  - AD4840: 6\n",
      "  - AD2498: 5\n",
      "  - AD5024: 5\n",
      "  - AD4572: 5\n",
      "  - AD4080: 5\n",
      "  - AD2990: 4\n",
      "  - AD4942: 4\n",
      "  - AD5450: 4\n",
      "  - AD4347: 4\n",
      "\n",
      "Id_Leg termina√ß√µes:\n",
      "  - -I: 372\n",
      "  - -M: 291\n",
      "\n",
      "‚è±Ô∏è Calculando Tempo Solo...\n",
      "‚úÖ log.csv gerado com 663 registros\n",
      "Colunas inclu√≠das: ['Activity', 'Id_Leg', 'Checkin', 'Start', 'End', 'Checkout', 'Tempo Solo']\n",
      "Tempo Solo v√°lidos: 663\n",
      "Tempo Solo nulos: 0\n",
      "\n",
      "üìù Primeiros 3 exemplos com Tempo Solo v√°lido:\n",
      "  Activity: AD5046, Id_Leg: -I, Tempo Solo: 0 days 00:46:00\n",
      "  Activity: AD2852, Id_Leg: -M, Tempo Solo: 0 days 00:31:00\n",
      "  Activity: AD2852, Id_Leg: -M, Tempo Solo: 0 days 00:30:00\n",
      "\n",
      "‚úÖ AN√ÅLISE CONCLU√çDA! Arquivo log.csv dispon√≠vel.\n"
     ]
    }
   ],
   "source": [
    "print(\"=== RESUMO DOS CEN√ÅRIOS POSS√çVEIS ===\")\n",
    "\n",
    "# Cen√°rio 1: Activities da lista + Id_Leg \"IF\"\n",
    "filtro1_activity = df2['Activity'].isin(tipos_voo_lista)\n",
    "filtro1_id_leg = df2['Id_Leg'].str.endswith('IF', na=False)\n",
    "cenario1_count = (filtro1_activity & filtro1_id_leg).sum()\n",
    "\n",
    "# Cen√°rio 2: Activities com \"AD\" + Id_Leg \"-I\" ou \"-M\"\n",
    "filtro2_activity = df2['Activity'].str.contains('AD', na=False)\n",
    "filtro2_id_leg = df2['Id_Leg'].str.endswith(('-I', '-M'), na=False)\n",
    "cenario2_count = (filtro2_activity & filtro2_id_leg).sum()\n",
    "\n",
    "print(f\"CEN√ÅRIO 1 (Activity lista + Id_Leg 'IF'): {cenario1_count} registros\")\n",
    "print(f\"CEN√ÅRIO 2 (Activity 'AD*' + Id_Leg '-I'/'-M'): {cenario2_count} registros\")\n",
    "print()\n",
    "\n",
    "# Vamos usar o Cen√°rio 2 que tem mais registros e era o que estava sendo analisado anteriormente\n",
    "if cenario2_count > 0:\n",
    "    print(f\"‚úÖ Usando CEN√ÅRIO 2 para gerar log.csv ({cenario2_count} registros)\")\n",
    "    print()\n",
    "    \n",
    "    # Aplicar filtros do Cen√°rio 2\n",
    "    df_final_log = df2[filtro2_activity & filtro2_id_leg].copy()\n",
    "    \n",
    "    print(f\"üìä Registros filtrados: {len(df_final_log)}\")\n",
    "    \n",
    "    # Mostrar distribui√ß√£o\n",
    "    print(\"Activities encontradas:\")\n",
    "    activities_dist = df_final_log['Activity'].value_counts()\n",
    "    for activity, count in activities_dist.head(10).items():\n",
    "        print(f\"  - {activity}: {count}\")\n",
    "    \n",
    "    print()\n",
    "    print(\"Id_Leg termina√ß√µes:\")\n",
    "    id_leg_dist = df_final_log['Id_Leg'].str[-2:].value_counts()\n",
    "    for term, count in id_leg_dist.items():\n",
    "        print(f\"  - {term}: {count}\")\n",
    "    \n",
    "    print()\n",
    "    print(\"‚è±Ô∏è Calculando Tempo Solo...\")\n",
    "    \n",
    "    # Ordenar por √≠ndice para garantir sequ√™ncia correta\n",
    "    df_final_log = df_final_log.sort_index()\n",
    "    \n",
    "    # Calcular Tempo Solo (Start da pr√≥xima linha - End da linha atual)\n",
    "    tempo_solo_calc = []\n",
    "    \n",
    "    for i in range(len(df_final_log)):\n",
    "        if i < len(df_final_log) - 1:  # N√£o √© a √∫ltima linha\n",
    "            try:\n",
    "                end_atual = pd.to_datetime(df_final_log.iloc[i]['End'])\n",
    "                start_proximo = pd.to_datetime(df_final_log.iloc[i+1]['Start'])\n",
    "                tempo_solo = start_proximo - end_atual\n",
    "                tempo_solo_calc.append(tempo_solo)\n",
    "            except:\n",
    "                tempo_solo_calc.append(pd.NaT)\n",
    "        else:  # √öltima linha\n",
    "            tempo_solo_calc.append(pd.NaT)\n",
    "    \n",
    "    # Se a coluna Tempo Solo n√£o existe, criar com valores calculados\n",
    "    if 'Tempo Solo' not in df_final_log.columns:\n",
    "        df_final_log['Tempo Solo'] = tempo_solo_calc\n",
    "    \n",
    "    # Selecionar colunas para o log\n",
    "    colunas_log = ['Activity', 'Id_Leg', 'Checkin', 'Start', 'End', 'Checkout', 'Tempo Solo']\n",
    "    colunas_disponiveis = [col for col in colunas_log if col in df_final_log.columns]\n",
    "    \n",
    "    df_log_export = df_final_log[colunas_disponiveis]\n",
    "    \n",
    "    # Salvar log.csv\n",
    "    df_log_export.to_csv('log.csv', index=False, encoding='utf-8')\n",
    "    \n",
    "    print(f\"‚úÖ log.csv gerado com {len(df_log_export)} registros\")\n",
    "    print(f\"Colunas inclu√≠das: {list(df_log_export.columns)}\")\n",
    "    \n",
    "    # Estat√≠sticas do Tempo Solo\n",
    "    if 'Tempo Solo' in df_log_export.columns:\n",
    "        tempo_solo_validos = df_log_export['Tempo Solo'].notna().sum()\n",
    "        tempo_solo_nulos = df_log_export['Tempo Solo'].isna().sum()\n",
    "        print(f\"Tempo Solo v√°lidos: {tempo_solo_validos}\")\n",
    "        print(f\"Tempo Solo nulos: {tempo_solo_nulos}\")\n",
    "        \n",
    "        # Exemplos\n",
    "        if tempo_solo_validos > 0:\n",
    "            print()\n",
    "            print(\"üìù Primeiros 3 exemplos com Tempo Solo v√°lido:\")\n",
    "            exemplos = df_log_export[df_log_export['Tempo Solo'].notna()].head(3)\n",
    "            for idx, row in exemplos.iterrows():\n",
    "                print(f\"  Activity: {row['Activity']}, Id_Leg: {row['Id_Leg']}, Tempo Solo: {row['Tempo Solo']}\")\n",
    "    \n",
    "    print()\n",
    "    print(\"‚úÖ AN√ÅLISE CONCLU√çDA! Arquivo log.csv dispon√≠vel.\")\n",
    "    \n",
    "elif cenario1_count > 0:\n",
    "    print(f\"‚úÖ Usando CEN√ÅRIO 1 para gerar log.csv ({cenario1_count} registros)\")\n",
    "    # Implementar Cen√°rio 1 se necess√°rio\n",
    "else:\n",
    "    print(\"‚ùå Nenhum cen√°rio vi√°vel encontrado com os crit√©rios especificados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ace94749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VERIFICA√á√ÉO DO ARQUIVO LOG.CSV ===\n",
      "Diret√≥rio atual: g:\\PROJETOS PYTHON\\aeronautas_azul\\CODIGOS TERMINADOS\n",
      "\n",
      "‚úÖ Arquivo log.csv encontrado!\n",
      "Tamanho do arquivo: 70994 bytes\n",
      "Linhas no arquivo: 663\n",
      "Colunas no arquivo: ['Activity', 'Id_Leg', 'Checkin', 'Start', 'End', 'Checkout', 'Tempo Solo']\n",
      "\n",
      "üìã Primeiras 5 linhas do log.csv:\n",
      "Activity Id_Leg             Checkin               Start                 End            Checkout      Tempo Solo\n",
      "  AD5046     -I 2017-11-01 18:55:00 2017-11-01 19:48:00 2017-11-01 21:37:00 2017-11-02 04:01:00 0 days 00:46:00\n",
      "  AD2852     -M 2017-11-01 18:55:00 2017-11-01 22:23:00 2017-11-01 23:31:00 2017-11-02 04:01:00 0 days 00:31:00\n",
      "  AD2852     -M 2017-11-01 18:55:00 2017-11-02 00:02:00 2017-11-02 01:43:00 2017-11-02 04:01:00 0 days 00:30:00\n",
      "  AD2899     -I 2017-11-04 10:10:00 2017-11-04 10:43:00 2017-11-04 11:37:00 2017-11-04 17:38:00 0 days 00:36:00\n",
      "  AD2433     -M 2017-11-04 10:10:00 2017-11-04 12:13:00 2017-11-04 14:19:00 2017-11-04 17:38:00 0 days 01:06:00\n",
      "\n",
      "üìã √öltimas 3 linhas do log.csv:\n",
      "Activity Id_Leg             Checkin               Start                 End            Checkout      Tempo Solo\n",
      "  AD4847     -M 2022-12-27 11:05:00 2022-12-27 17:46:00 2022-12-27 19:29:00 2022-12-27 22:07:00 0 days 00:58:00\n",
      "  AD4890     -I 2022-12-28 13:00:00 2022-12-28 14:11:00 2022-12-28 16:39:00 2022-12-28 22:33:00 0 days 00:59:00\n",
      "  AD4540     -I 2022-12-30 06:40:00 2022-12-30 08:03:00 2022-12-30 08:57:00 2022-12-30 11:32:00 0 days 00:52:00\n",
      "\n",
      "üìä Resumo final:\n",
      "- Total de registros: 663\n",
      "- Tempo Solo nulos: 0\n",
      "- Tempo Solo v√°lidos: 663\n",
      "\n",
      "üìÇ Caminho completo esperado: g:\\PROJETOS PYTHON\\aeronautas_azul\\CODIGOS TERMINADOS\\log.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"=== VERIFICA√á√ÉO DO ARQUIVO LOG.CSV ===\")\n",
    "print(f\"Diret√≥rio atual: {os.getcwd()}\")\n",
    "print()\n",
    "\n",
    "# Verificar se o arquivo existe\n",
    "if os.path.exists('log.csv'):\n",
    "    print(\"‚úÖ Arquivo log.csv encontrado!\")\n",
    "    \n",
    "    # Mostrar tamanho do arquivo\n",
    "    tamanho = os.path.getsize('log.csv')\n",
    "    print(f\"Tamanho do arquivo: {tamanho} bytes\")\n",
    "    \n",
    "    # Ler e mostrar as primeiras linhas\n",
    "    try:\n",
    "        df_log_verificacao = pd.read_csv('log.csv')\n",
    "        print(f\"Linhas no arquivo: {len(df_log_verificacao)}\")\n",
    "        print(f\"Colunas no arquivo: {list(df_log_verificacao.columns)}\")\n",
    "        print()\n",
    "        print(\"üìã Primeiras 5 linhas do log.csv:\")\n",
    "        print(df_log_verificacao.head().to_string(index=False))\n",
    "        print()\n",
    "        print(\"üìã √öltimas 3 linhas do log.csv:\")\n",
    "        print(df_log_verificacao.tail(3).to_string(index=False))\n",
    "        \n",
    "        # Verificar se h√° valores nulos em Tempo Solo\n",
    "        tempo_solo_nulos = df_log_verificacao['Tempo Solo'].isna().sum()\n",
    "        print(f\"\\nüìä Resumo final:\")\n",
    "        print(f\"- Total de registros: {len(df_log_verificacao)}\")\n",
    "        print(f\"- Tempo Solo nulos: {tempo_solo_nulos}\")\n",
    "        print(f\"- Tempo Solo v√°lidos: {len(df_log_verificacao) - tempo_solo_nulos}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao ler o arquivo: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Arquivo log.csv n√£o encontrado no diret√≥rio atual\")\n",
    "    \n",
    "    # Tentar encontrar em outros locais\n",
    "    print(\"\\nüîç Procurando arquivo log.csv em outros diret√≥rios...\")\n",
    "    for root, dirs, files in os.walk('.'):\n",
    "        if 'log.csv' in files:\n",
    "            caminho_completo = os.path.join(root, 'log.csv')\n",
    "            print(f\"Encontrado em: {caminho_completo}\")\n",
    "\n",
    "print(f\"\\nüìÇ Caminho completo esperado: {os.path.abspath('log.csv')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1c940499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AN√ÅLISE DA COLUNA 'JORNADA' ===\n",
      "Crit√©rio: Jornada = Checkout - Checkin\n",
      "Objetivo: Verificar c√°lculos e gerar log_jornadas.csv\n",
      "============================================================\n",
      "Dataset df2 dispon√≠vel com 2541 registros\n",
      "\n",
      "Colunas dispon√≠veis: ['Checkin', 'Checkout', 'Jornada']\n",
      "\n",
      "‚úÖ Colunas essenciais (Checkin e Checkout) dispon√≠veis\n",
      "\n",
      "üìä An√°lise de valores nulos:\n",
      "- Checkin nulos: 0\n",
      "- Checkout nulos: 0\n",
      "- Jornada nulos: 0\n",
      "\n",
      "‚è±Ô∏è Calculando Jornada (Checkout - Checkin)...\n",
      "Registros com Checkin e Checkout v√°lidos: 940\n",
      "\n",
      "üîç Comparando Jornada original vs calculada...\n",
      "üìä Resultados da compara√ß√£o:\n",
      "- Total analisado: 940\n",
      "- Corretos: 0 (0.0%)\n",
      "- Incorretos: 940\n",
      "\n",
      "üìù Exemplos de c√°lculos (primeiros 5 registros):\n",
      "  Checkin: 11/01/2017 18:55 | Checkout: 11/02/2017 04:01\n",
      "  Jornada Original: 0 days 00:00:00 | Calculada: 30 days 09:06:00\n",
      "\n",
      "  Checkin: 11/01/2017 18:55 | Checkout: 11/02/2017 04:01\n",
      "  Jornada Original: 0 days 00:00:00 | Calculada: 30 days 09:06:00\n",
      "\n",
      "  Checkin: 11/01/2017 18:55 | Checkout: 11/02/2017 04:01\n",
      "  Jornada Original: 0 days 00:00:00 | Calculada: 30 days 09:06:00\n",
      "\n",
      "  Checkin: 11/01/2017 18:55 | Checkout: 11/02/2017 04:01\n",
      "  Jornada Original: 0 days 09:36:00 | Calculada: 30 days 09:06:00\n",
      "\n",
      "  Checkin: 11/03/2017 00:20 | Checkout: 11/03/2017 02:21\n",
      "  Jornada Original: 0 days 02:31:00 | Calculada: 0 days 02:01:00\n",
      "\n",
      "üìù Exemplos de c√°lculos incorretos (primeiros 3):\n",
      "  Checkin: 11/01/2017 18:55 | Checkout: 11/02/2017 04:01\n",
      "  Original: 0 days 00:00:00 | Calculada: 30 days 09:06:00 | Diferen√ßa: 30 days 09:06:00\n",
      "\n",
      "  Checkin: 11/01/2017 18:55 | Checkout: 11/02/2017 04:01\n",
      "  Original: 0 days 00:00:00 | Calculada: 30 days 09:06:00 | Diferen√ßa: 30 days 09:06:00\n",
      "\n",
      "  Checkin: 11/01/2017 18:55 | Checkout: 11/02/2017 04:01\n",
      "  Original: 0 days 00:00:00 | Calculada: 30 days 09:06:00 | Diferen√ßa: 30 days 09:06:00\n",
      "\n",
      "\n",
      "üìÑ Preparando log_jornadas.csv...\n",
      "‚úÖ Arquivo log_jornadas.csv salvo com 940 registros\n",
      "Colunas inclu√≠das: ['Activity', 'Id_Leg', 'Checkin', 'Checkout', 'Jornada']\n",
      "\n",
      "üìä Estat√≠sticas do log_jornadas.csv:\n",
      "- Total de registros: 940\n",
      "- Jornada v√°lidos: 940\n",
      "- Jornada nulos: 0\n",
      "‚ùå Erro ao processar datas: Could not convert string '0 days 00:00:000 days 00:00:000 days 00:00:000 days 09:36:000 days 02:31:000 days 00:00:000 days 00:00:000 days 07:58:000 days 00:00:000 days 00:00:000 days 10:26:001 days 01:00:001 days 01:00:000 days 00:00:000 days 00:00:000 days 00:00:000 days 07:51:000 days 10:00:000 days 10:00:000 days 00:00:000 days 09:35:001 days 01:00:001 days 01:00:001 days 01:00:001 days 01:00:001 days 01:00:001 days 01:00:001 days 01:00:001 days 01:00:001 days 01:00:001 days 01:00:001 days 01:00:000 days 21:55:001 days 00:25:001 days 00:25:001 days 00:25:000 days 10:00:001 days 01:00:000 days 00:00:000 days 00:00:000 days 09:35:000 days 00:00:000 days 00:00:000 days 08:32:000 days 00:00:000 days 00:00:000 days 09:27:000 days 00:00:000 days 00:00:000 days 06:14:000 days 00:00:000 days 00:00:000 days 10:10:000 days 00:00:000 days 00:00:000 days 09:29:000 days 00:00:000 days 00:00:000 days 00:00:000 days 10:18:000 days 00:00:000 days 00:00:000 days 00:00:000 days 09:01:000 days 00:00:000 days 00:00:000 days 08:56:001 days 01:00:001 days 01:00:000 days 06:00:000 days 13:25:000 days 13:30:000 days 15:00:000 days 13:00:000 days 08:00:001 days 01:00:000 days 00:00:000 days 08:35:001 days 01:00:000 days 04:00:000 days 08:00:000 days 04:35:000 days 15:40:000 days 13:30:001 days 01:00:001 days 01:00:001 days 00:58:000 days 00:00:000 days 00:00:000 days 00:00:000 days 10:02:000 days 00:00:000 days 00:00:000 days 00:00:000 days 08:15:001 days 00:58:001 days 01:00:001 days 01:00:001 days 01:00:001 days 01:00:000 days 00:00:000 days 08:33:000 days 00:00:000 days 00:00:000 days 00:00:000 days 09:34:000 days 00:00:000 days 00:00:000 days 08:06:001 days 01:00:001 days 01:00:001 days 01:00:001 days 01:00:001 days 00:59:000 days 00:00:000 days 08:48:000 days 00:00:000 days 07:43:000 days 00:00:000 days 00:00:000 days 09:56:000 days 03:04:001 days 01:00:001 days 01:00:001 days 00:59:001 days 00:59:000 days 00:00:000 days 08:31:000 days 00:00:000 days 07:33:001 days 01:00:001 days 01:00:001 days 01:00:001 days 01:00:001 days 01:00:000 days 00:00:000 days 00:00:000 days 00:00:000 days 09:29:000 days 03:30:000 days 00:00:000 days 00:00:000 days 08:01:001 days 01:00:000 days 08:15:000 days 14:00:001 days 01:00:001 days 01:00:001 days 00:58:001 days 00:58:001 days 01:00:001 days 01:00:001 days 01:00:001 days 01:00:001 days 00:58:001 days 00:58:001 days 00:58:000 days 00:00:000 days 00:00:000 days 00:00:000 days 10:23:000 days 04:00:000 days 00:00:000 days 00:00:000 days 10:32:000 days 00:00:000 days 00:00:000 days 08:58:001 days 00:59:001 days 00:59:001 days 00:59:001 days 01:00:001 days 01:00:001 days 01:00:001 days 00:59:001 days 00:59:000 days 11:40:000 days 11:00:000 days 11:20:000 days 03:00:000 days 05:00:000 days 03:00:000 days 04:00:001 days 01:00:001 days 01:00:001 days 00:58:001 days 00:58:001 days 00:58:001 days 00:58:001 days 01:00:001 days 01:00:001 days 00:00:001 days 01:00:001 days 01:00:001 days 01:00:001 days 01:00:001 days 01:00:001 days 01:00:001 days 01:00:001 days 01:00:001 days 01:00:001 days 01:00:001 days 00:58:001 days 00:58:001 days 00:58:000 days 00:00:000 days 00:00:000 days 06:44:001 days 01:00:001 days 00:58:001 days 00:58:001 days 01:00:000 days 03:14:000 days 00:00:000 days 00:00:000 days 09:02:000 days 00:00:000 days 06:08:000 days 03:30:001 days 01:00:001 days 00:58:001 days 00:58:000 days 00:00:000 days 00:00:000 days 00:00:000 days 09:44:000 days 00:00:000 days 00:00:000 days 08:39:000 days 00:00:000 days 00:00:000 days 00:00:000 days 10:19:000 days 00:00:000 days 05:14:000 days 00:00:000 days 09:40:001 days 01:00:001 days 01:00:001 days 01:00:001 days 01:00:000 days 00:00:000 days 00:00:000 days 07:55:000 days 00:00:000 days 00:00:000 days 00:00:000 days 09:19:001 days 01:00:001 days 01:00:000 days 00:00:000 days 00:00:000 days 00:00:000 days 10:03:000 days 00:00:000 days 00:00:000 days 11:01:000 days 00:00:000 days 00:00:000 days 10:52:001 days 01:00:001 days 01:00:001 days 01:00:001 days 01:00:001 days 01:00:001 days 01:00:001 days 01:00:001 days 01:00:001 days 01:00:000 days 00:00:000 days 00:00:000 days 00:00:000 days 07:50:000 days 00:00:000 days 04:28:001 days 01:00:001 days 01:00:001 days 01:00:001 days 01:00:000 days 00:00:000 days 00:00:000 days 00:00:000 days 11:24:000 days 00:00:000 days 00:00:000 days 00:00:000 days 10:09:000 days 00:00:000 days 00:00:000 days 00:00:000 days 11:10:000 days 00:00:000 days 07:01:000 days 03:00:000 days 00:00:000 days 07:05:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:000 days 00:00:000 days 00:00:000 days 07:25:000 days 00:00:000 days 05:05:000 days 00:00:000 days 07:10:001 days 00:30:000 days 18:29:000 days 03:30:001 days 00:28:001 days 00:30:000 days 04:30:000 days 18:29:000 days 04:30:001 days 00:30:000 days 03:30:000 days 06:30:000 days 06:30:000 days 01:30:000 days 20:00:000 days 20:00:001 days 00:29:000 days 00:00:000 days 09:11:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:29:001 days 00:29:000 days 00:00:000 days 00:00:000 days 00:00:000 days 09:40:001 days 00:30:000 days 00:00:000 days 05:00:000 days 00:31:000 days 00:00:000 days 05:49:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:000 days 00:00:000 days 08:35:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:000 days 02:30:000 days 02:30:000 days 02:30:000 days 02:30:000 days 01:50:000 days 09:30:001 days 00:30:000 days 00:00:000 days 00:00:000 days 00:00:000 days 00:00:000 days 09:52:000 days 00:00:000 days 00:00:000 days 00:00:000 days 00:00:000 days 10:11:000 days 00:00:000 days 00:00:000 days 00:00:000 days 09:02:000 days 00:00:000 days 00:00:000 days 00:00:000 days 09:42:000 days 03:30:000 days 03:10:001 days 00:30:000 days 00:00:000 days 00:00:000 days 00:00:000 days 09:16:000 days 00:00:000 days 00:00:000 days 08:00:000 days 00:00:000 days 00:00:000 days 00:00:000 days 09:53:000 days 00:00:000 days 00:00:000 days 00:00:000 days 09:30:001 days 00:30:001 days 00:30:000 days 00:00:000 days 00:00:000 days 09:26:000 days 00:00:000 days 05:44:000 days 00:00:000 days 08:35:001 days 00:30:001 days 00:30:000 days 09:30:001 days 00:30:001 days 00:30:000 days 04:30:000 days 04:30:000 days 04:30:000 days 09:30:001 days 00:30:001 days 00:30:000 days 04:30:001 days 00:30:001 days 00:30:001 days 00:30:000 days 04:30:000 days 04:30:000 days 04:30:000 days 04:30:001 days 00:30:001 days 00:30:001 days 00:30:000 days 02:30:000 days 04:30:000 days 02:30:000 days 04:30:000 days 00:00:000 days 08:28:000 days 00:00:000 days 00:00:000 days 09:00:000 days 08:20:000 days 00:00:000 days 11:20:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:000 days 06:15:000 days 06:30:001 days 00:30:001 days 00:30:000 days 05:01:000 days 00:00:000 days 09:00:000 days 00:00:000 days 08:55:000 days 00:00:000 days 05:19:001 days 00:30:001 days 00:30:000 days 00:00:000 days 00:00:000 days 08:26:000 days 03:22:000 days 13:04:001 days 00:29:001 days 00:29:001 days 00:29:001 days 00:29:001 days 00:29:001 days 00:29:001 days 00:29:001 days 00:29:001 days 00:29:001 days 00:29:001 days 00:29:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:000 days 03:30:000 days 00:00:000 days 00:00:000 days 09:42:000 days 00:00:000 days 09:18:000 days 00:00:000 days 00:00:000 days 09:13:001 days 00:30:001 days 00:30:000 days 00:00:000 days 00:00:000 days 11:11:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:000 days 00:00:000 days 07:31:000 days 00:00:000 days 07:27:000 days 09:30:000 days 00:00:000 days 08:33:001 days 00:30:001 days 00:30:000 days 00:00:000 days 07:03:000 days 03:04:000 days 00:00:000 days 00:00:000 days 10:10:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:000 days 03:30:000 days 12:15:001 days 00:30:000 days 04:30:000 days 04:30:000 days 02:00:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:000 days 04:10:000 days 00:00:000 days 05:48:000 days 00:00:000 days 07:50:001 days 00:30:001 days 00:30:001 days 00:30:000 days 04:30:000 days 04:30:000 days 04:30:001 days 00:30:001 days 00:30:000 days 00:00:000 days 06:57:001 days 00:30:001 days 00:30:000 days 04:43:000 days 00:00:000 days 00:00:000 days 09:25:000 days 00:00:000 days 07:20:000 days 03:00:000 days 00:00:000 days 00:00:000 days 10:00:000 days 08:15:001 days 00:30:001 days 00:30:000 days 08:30:000 days 00:00:000 days 00:00:000 days 06:18:000 days 00:00:000 days 05:55:000 days 04:00:000 days 08:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:000 days 02:55:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:000 days 02:30:000 days 01:30:000 days 01:30:000 days 02:30:000 days 01:30:000 days 02:30:000 days 01:20:000 days 01:20:000 days 01:20:000 days 01:20:000 days 00:40:000 days 04:30:000 days 01:30:000 days 09:30:000 days 01:30:000 days 02:00:000 days 03:00:000 days 01:30:000 days 03:25:000 days 01:20:000 days 00:45:000 days 02:30:000 days 03:25:000 days 01:20:000 days 00:45:001 days 00:30:001 days 00:30:000 days 01:30:000 days 04:30:000 days 04:30:000 days 04:30:000 days 00:00:000 days 06:38:000 days 00:00:000 days 08:15:000 days 00:00:000 days 06:31:000 days 00:00:000 days 07:52:000 days 04:34:001 days 00:30:001 days 00:30:001 days 00:30:000 days 00:00:000 days 00:00:000 days 08:31:000 days 00:00:000 days 06:17:001 days 00:30:000 days 00:00:000 days 00:00:000 days 09:57:000 days 00:00:000 days 04:42:000 days 00:00:000 days 00:00:000 days 00:00:000 days 10:12:000 days 00:00:000 days 10:00:000 days 00:00:000 days 08:10:001 days 00:30:001 days 00:30:000 days 00:00:000 days 07:40:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:000 days 00:00:000 days 00:00:000 days 09:18:000 days 00:00:000 days 00:00:000 days 10:50:001 days 00:30:000 days 00:00:000 days 06:34:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:000 days 00:00:000 days 00:00:000 days 12:05:000 days 00:00:000 days 00:00:000 days 11:18:000 days 02:19:000 days 00:00:000 days 10:30:000 days 05:18:001 days 00:30:001 days 00:30:000 days 04:30:001 days 00:30:001 days 00:30:000 days 00:00:000 days 00:00:000 days 11:31:000 days 00:00:000 days 07:01:000 days 00:00:000 days 07:23:000 days 00:00:000 days 06:27:000 days 03:20:001 days 00:30:001 days 00:30:001 days 00:30:000 days 00:00:000 days 00:00:000 days 11:50:000 days 00:00:000 days 08:58:001 days 00:30:001 days 00:30:000 days 00:00:000 days 00:00:000 days 00:00:000 days 08:55:000 days 14:28:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:000 days 00:00:000 days 00:00:000 days 09:05:000 days 08:30:000 days 01:25:000 days 05:14:000 days 04:52:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:000 days 00:00:000 days 00:00:000 days 11:24:000 days 04:18:000 days 03:22:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:000 days 05:36:000 days 00:00:000 days 08:37:000 days 23:40:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:000 days 00:00:000 days 00:00:000 days 11:14:000 days 00:00:000 days 09:01:000 days 06:14:001 days 00:30:001 days 00:30:001 days 00:30:000 days 00:00:000 days 00:00:000 days 12:18:000 days 00:00:000 days 00:00:000 days 07:56:001 days 00:30:000 days 03:30:000 days 04:46:000 days 00:00:000 days 07:48:001 days 00:30:001 days 00:30:001 days 00:30:000 days 03:10:000 days 00:00:000 days 00:00:000 days 00:00:000 days 10:58:000 days 01:10:000 days 00:00:000 days 09:20:000 days 02:20:000 days 00:00:000 days 11:55:000 days 02:30:001 days 00:30:001 days 00:30:000 days 04:30:000 days 04:30:001 days 00:30:001 days 00:30:001 days 00:30:000 days 00:00:000 days 00:00:000 days 12:13:000 days 00:00:000 days 00:00:000 days 09:48:000 days 00:00:000 days 00:00:000 days 09:27:000 days 12:30:001 days 00:30:001 days 00:30:001 days 00:30:000 days 07:30:001 days 00:30:001 days 00:30:001 days 00:30:000 days 00:00:000 days 07:41:000 days 00:00:000 days 06:33:000 days 00:00:000 days 06:52:000 days 00:00:000 days 00:00:000 days 10:40:000 days 00:00:000 days 00:00:000 days 00:00:000 days 11:50:000 days 03:01:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:000 days 03:03:000 days 00:00:000 days 00:00:000 days 08:57:000 days 00:00:000 days 00:00:000 days 10:27:000 days 03:42:000 days 01:30:000 days 00:00:000 days 00:00:000 days 08:11:000 days 00:00:000 days 00:00:000 days 09:17:001 days 00:30:001 days 00:30:001 days 00:30:000 days 00:00:000 days 00:00:000 days 00:00:000 days 11:09:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:000 days 00:00:000 days 00:00:000 days 07:57:000 days 00:00:000 days 07:16:000 days 04:48:000 days 03:15:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:001 days 00:30:00' to numeric\n"
     ]
    }
   ],
   "source": [
    "print(\"=== AN√ÅLISE DA COLUNA 'JORNADA' ===\")\n",
    "print(\"Crit√©rio: Jornada = Checkout - Checkin\")\n",
    "print(\"Objetivo: Verificar c√°lculos e gerar log_jornadas.csv\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Verificar se os dados est√£o dispon√≠veis\n",
    "if 'df2' not in locals():\n",
    "    print(\"ERRO: df2 n√£o est√° dispon√≠vel\")\n",
    "else:\n",
    "    print(f\"Dataset df2 dispon√≠vel com {len(df2)} registros\")\n",
    "    \n",
    "    # Verificar colunas necess√°rias para an√°lise de Jornada\n",
    "    colunas_necessarias_jornada = ['Checkin', 'Checkout', 'Jornada']\n",
    "    colunas_disponiveis_jornada = []\n",
    "    colunas_faltando_jornada = []\n",
    "    \n",
    "    for col in colunas_necessarias_jornada:\n",
    "        if col in df2.columns:\n",
    "            colunas_disponiveis_jornada.append(col)\n",
    "        else:\n",
    "            colunas_faltando_jornada.append(col)\n",
    "    \n",
    "    print(f\"\\nColunas dispon√≠veis: {colunas_disponiveis_jornada}\")\n",
    "    if colunas_faltando_jornada:\n",
    "        print(f\"Colunas faltando: {colunas_faltando_jornada}\")\n",
    "    \n",
    "    # Verificar se as colunas essenciais est√£o dispon√≠veis\n",
    "    if 'Checkin' in df2.columns and 'Checkout' in df2.columns:\n",
    "        print(\"\\n‚úÖ Colunas essenciais (Checkin e Checkout) dispon√≠veis\")\n",
    "        \n",
    "        # Verificar valores nulos\n",
    "        checkin_nulos = df2['Checkin'].isna().sum()\n",
    "        checkout_nulos = df2['Checkout'].isna().sum()\n",
    "        \n",
    "        print(f\"\\nüìä An√°lise de valores nulos:\")\n",
    "        print(f\"- Checkin nulos: {checkin_nulos}\")\n",
    "        print(f\"- Checkout nulos: {checkout_nulos}\")\n",
    "        \n",
    "        if 'Jornada' in df2.columns:\n",
    "            jornada_nulos = df2['Jornada'].isna().sum()\n",
    "            print(f\"- Jornada nulos: {jornada_nulos}\")\n",
    "        \n",
    "        # Calcular Jornada (Checkout - Checkin)\n",
    "        print(\"\\n‚è±Ô∏è Calculando Jornada (Checkout - Checkin)...\")\n",
    "        \n",
    "        # Criar uma c√≥pia para trabalhar\n",
    "        df_jornada = df2.copy()\n",
    "        \n",
    "        # Converter para datetime com tratamento de erros\n",
    "        try:\n",
    "            df_jornada['Checkin_dt'] = pd.to_datetime(df_jornada['Checkin'], dayfirst=True, errors='coerce')\n",
    "            df_jornada['Checkout_dt'] = pd.to_datetime(df_jornada['Checkout'], dayfirst=True, errors='coerce')\n",
    "            \n",
    "            # Calcular Jornada\n",
    "            df_jornada['Jornada_Calculada'] = df_jornada['Checkout_dt'] - df_jornada['Checkin_dt']\n",
    "            \n",
    "            # Contar registros v√°lidos para c√°lculo\n",
    "            registros_validos = (~df_jornada['Checkin_dt'].isna()) & (~df_jornada['Checkout_dt'].isna())\n",
    "            total_validos = registros_validos.sum()\n",
    "            \n",
    "            print(f\"Registros com Checkin e Checkout v√°lidos: {total_validos}\")\n",
    "            \n",
    "            if total_validos > 0:\n",
    "                # Comparar com Jornada original se existir\n",
    "                if 'Jornada' in df_jornada.columns:\n",
    "                    print(\"\\nüîç Comparando Jornada original vs calculada...\")\n",
    "                    \n",
    "                    # Filtrar apenas registros v√°lidos\n",
    "                    df_validos = df_jornada[registros_validos].copy()\n",
    "                    \n",
    "                    # Converter Jornada original para timedelta se necess√°rio\n",
    "                    if df_validos['Jornada'].dtype == 'object':\n",
    "                        df_validos['Jornada_Original'] = pd.to_timedelta(df_validos['Jornada'], errors='coerce')\n",
    "                    else:\n",
    "                        df_validos['Jornada_Original'] = df_validos['Jornada']\n",
    "                    \n",
    "                    # Comparar valores (com toler√¢ncia de 1 minuto)\n",
    "                    tolerancia_jornada = pd.Timedelta(minutes=1)\n",
    "                    \n",
    "                    # Calcular diferen√ßa absoluta\n",
    "                    diferenca_jornada = abs(df_validos['Jornada_Calculada'] - df_validos['Jornada_Original'])\n",
    "                    \n",
    "                    # Contar corretos e incorretos\n",
    "                    corretos_jornada = (diferenca_jornada <= tolerancia_jornada).sum()\n",
    "                    incorretos_jornada = len(df_validos) - corretos_jornada\n",
    "                    \n",
    "                    taxa_acerto_jornada = (corretos_jornada / len(df_validos)) * 100\n",
    "                    \n",
    "                    print(f\"üìä Resultados da compara√ß√£o:\")\n",
    "                    print(f\"- Total analisado: {len(df_validos)}\")\n",
    "                    print(f\"- Corretos: {corretos_jornada} ({taxa_acerto_jornada:.1f}%)\")\n",
    "                    print(f\"- Incorretos: {incorretos_jornada}\")\n",
    "                    \n",
    "                    # Mostrar exemplos de c√°lculos\n",
    "                    print(f\"\\nüìù Exemplos de c√°lculos (primeiros 5 registros):\")\n",
    "                    exemplos_jornada = df_validos.head(5)\n",
    "                    for idx, row in exemplos_jornada.iterrows():\n",
    "                        checkin = row['Checkin_dt'].strftime('%d/%m/%Y %H:%M') if pd.notna(row['Checkin_dt']) else 'N/A'\n",
    "                        checkout = row['Checkout_dt'].strftime('%d/%m/%Y %H:%M') if pd.notna(row['Checkout_dt']) else 'N/A'\n",
    "                        jornada_orig = row['Jornada_Original'] if pd.notna(row['Jornada_Original']) else 'N/A'\n",
    "                        jornada_calc = row['Jornada_Calculada'] if pd.notna(row['Jornada_Calculada']) else 'N/A'\n",
    "                        print(f\"  Checkin: {checkin} | Checkout: {checkout}\")\n",
    "                        print(f\"  Jornada Original: {jornada_orig} | Calculada: {jornada_calc}\")\n",
    "                        print()\n",
    "                    \n",
    "                    # Mostrar alguns casos incorretos se existirem\n",
    "                    if incorretos_jornada > 0:\n",
    "                        print(\"üìù Exemplos de c√°lculos incorretos (primeiros 3):\")\n",
    "                        mask_incorretos = diferenca_jornada > tolerancia_jornada\n",
    "                        exemplos_incorretos_jornada = df_validos[mask_incorretos].head(3)\n",
    "                        \n",
    "                        for idx, row in exemplos_incorretos_jornada.iterrows():\n",
    "                            checkin = row['Checkin_dt'].strftime('%d/%m/%Y %H:%M')\n",
    "                            checkout = row['Checkout_dt'].strftime('%d/%m/%Y %H:%M')\n",
    "                            jornada_orig = row['Jornada_Original']\n",
    "                            jornada_calc = row['Jornada_Calculada']\n",
    "                            diff = abs(jornada_calc - jornada_orig)\n",
    "                            print(f\"  Checkin: {checkin} | Checkout: {checkout}\")\n",
    "                            print(f\"  Original: {jornada_orig} | Calculada: {jornada_calc} | Diferen√ßa: {diff}\")\n",
    "                            print()\n",
    "                    \n",
    "                    # Usar dados v√°lidos para o log\n",
    "                    df_log_jornada = df_validos.copy()\n",
    "                    \n",
    "                else:\n",
    "                    print(\"\\nüìù Coluna Jornada n√£o existe - usando apenas c√°lculo\")\n",
    "                    # Usar todos os registros v√°lidos\n",
    "                    df_log_jornada = df_jornada[registros_validos].copy()\n",
    "                    df_log_jornada['Jornada'] = df_log_jornada['Jornada_Calculada']\n",
    "                \n",
    "                # Preparar dados para log_jornadas.csv\n",
    "                print(f\"\\nüìÑ Preparando log_jornadas.csv...\")\n",
    "                \n",
    "                # Selecionar colunas relevantes\n",
    "                colunas_log_jornada = ['Activity', 'Id_Leg', 'Checkin', 'Checkout', 'Jornada']\n",
    "                \n",
    "                # Adicionar colunas que existem\n",
    "                colunas_existentes_log = []\n",
    "                for col in colunas_log_jornada:\n",
    "                    if col in df_log_jornada.columns:\n",
    "                        colunas_existentes_log.append(col)\n",
    "                    elif col == 'Jornada' and 'Jornada_Calculada' in df_log_jornada.columns:\n",
    "                        # Usar Jornada calculada se Jornada original n√£o existir\n",
    "                        df_log_jornada['Jornada'] = df_log_jornada['Jornada_Calculada']\n",
    "                        colunas_existentes_log.append('Jornada')\n",
    "                \n",
    "                # Se Activity e Id_Leg n√£o existem, adicionar colunas b√°sicas\n",
    "                if 'Activity' not in colunas_existentes_log:\n",
    "                    colunas_existentes_log = ['Checkin', 'Checkout', 'Jornada']\n",
    "                \n",
    "                # Criar dataframe final\n",
    "                df_log_jornada_final = df_log_jornada[colunas_existentes_log].copy()\n",
    "                \n",
    "                # Salvar log_jornadas.csv\n",
    "                caminho_log_jornada = \"log_jornadas.csv\"\n",
    "                df_log_jornada_final.to_csv(caminho_log_jornada, index=False, encoding='utf-8')\n",
    "                \n",
    "                print(f\"‚úÖ Arquivo log_jornadas.csv salvo com {len(df_log_jornada_final)} registros\")\n",
    "                print(f\"Colunas inclu√≠das: {list(df_log_jornada_final.columns)}\")\n",
    "                \n",
    "                # Estat√≠sticas finais\n",
    "                print(f\"\\nüìä Estat√≠sticas do log_jornadas.csv:\")\n",
    "                print(f\"- Total de registros: {len(df_log_jornada_final)}\")\n",
    "                \n",
    "                if 'Jornada' in df_log_jornada_final.columns:\n",
    "                    jornada_validos_final = df_log_jornada_final['Jornada'].notna().sum()\n",
    "                    jornada_nulos_final = df_log_jornada_final['Jornada'].isna().sum()\n",
    "                    print(f\"- Jornada v√°lidos: {jornada_validos_final}\")\n",
    "                    print(f\"- Jornada nulos: {jornada_nulos_final}\")\n",
    "                    \n",
    "                    # Estat√≠sticas da Jornada\n",
    "                    if jornada_validos_final > 0:\n",
    "                        jornadas_validas = df_log_jornada_final['Jornada'].dropna()\n",
    "                        jornada_media = jornadas_validas.mean()\n",
    "                        jornada_min = jornadas_validas.min()\n",
    "                        jornada_max = jornadas_validas.max()\n",
    "                        \n",
    "                        print(f\"- Jornada m√©dia: {jornada_media}\")\n",
    "                        print(f\"- Jornada m√≠nima: {jornada_min}\")\n",
    "                        print(f\"- Jornada m√°xima: {jornada_max}\")\n",
    "                \n",
    "                print(f\"\\n‚úÖ AN√ÅLISE DA JORNADA CONCLU√çDA!\")\n",
    "                print(f\"Arquivo log_jornadas.csv dispon√≠vel em: {caminho_log_jornada}\")\n",
    "                \n",
    "            else:\n",
    "                print(\"‚ùå N√£o h√° registros v√°lidos com Checkin e Checkout para calcular Jornada\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erro ao processar datas: {e}\")\n",
    "            \n",
    "    else:\n",
    "        print(\"‚ùå Colunas Checkin e/ou Checkout n√£o est√£o dispon√≠veis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bf82743e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VERIFICA√á√ÉO DO ARQUIVO LOG_JORNADAS.CSV ===\n",
      "‚úÖ Arquivo log_jornadas.csv encontrado!\n",
      "Tamanho do arquivo: 61743 bytes\n",
      "Linhas no arquivo: 940\n",
      "Colunas no arquivo: ['Activity', 'Id_Leg', 'Checkin', 'Checkout', 'Jornada']\n",
      "\n",
      "üìã Primeiras 5 linhas do log_jornadas.csv:\n",
      "Activity Id_Leg             Checkin            Checkout         Jornada\n",
      "  AD5046     -I 2017-11-01 18:55:00 2017-11-02 04:01:00 0 days 00:00:00\n",
      "  AD2852     -M 2017-11-01 18:55:00 2017-11-02 04:01:00 0 days 00:00:00\n",
      "  AD2852     -M 2017-11-01 18:55:00 2017-11-02 04:01:00 0 days 00:00:00\n",
      "  AD2852     -F 2017-11-01 18:55:00 2017-11-02 04:01:00 0 days 09:36:00\n",
      "  AD2898    -IF 2017-11-03 00:20:00 2017-11-03 02:21:00 0 days 02:31:00\n",
      "\n",
      "üìä Estat√≠sticas da coluna Jornada:\n",
      "- Registros com Jornada v√°lida: 940\n",
      "- Jornada m√©dia: 0 days 12:21:31.276595744\n",
      "- Jornada m√≠nima: 0 days 00:00:00\n",
      "- Jornada m√°xima: 1 days 01:00:00\n",
      "\n",
      "üìà Distribui√ß√£o por faixas de Jornada:\n",
      "  0-8h: 420 registros (44.7%)\n",
      "  8-12h: 114 registros (12.1%)\n",
      "  12-16h: 14 registros (1.5%)\n",
      "  16-24h: 6 registros (0.6%)\n",
      "  >24h: 386 registros (41.1%)\n",
      "\n",
      "üìä Distribui√ß√£o por Activity (Top 10):\n",
      "  FR: 162 registros\n",
      "  SNA: 72 registros\n",
      "  FER: 65 registros\n",
      "  F: 59 registros\n",
      "  EAD: 19 registros\n",
      "  SFX: 17 registros\n",
      "  DMI: 12 registros\n",
      "  DOP: 12 registros\n",
      "  BUS: 8 registros\n",
      "  FP: 8 registros\n",
      "\n",
      "üìÇ Caminho completo: g:\\PROJETOS PYTHON\\aeronautas_azul\\CODIGOS TERMINADOS\\log_jornadas.csv\n",
      "‚úÖ VERIFICA√á√ÉO CONCLU√çDA!\n"
     ]
    }
   ],
   "source": [
    "print(\"=== VERIFICA√á√ÉO DO ARQUIVO LOG_JORNADAS.CSV ===\")\n",
    "\n",
    "# Verificar se o arquivo foi criado\n",
    "caminho_log_jornadas = \"log_jornadas.csv\"\n",
    "\n",
    "if os.path.exists(caminho_log_jornadas):\n",
    "    print(\"‚úÖ Arquivo log_jornadas.csv encontrado!\")\n",
    "    \n",
    "    # Informa√ß√µes do arquivo\n",
    "    tamanho_jornadas = os.path.getsize(caminho_log_jornadas)\n",
    "    print(f\"Tamanho do arquivo: {tamanho_jornadas} bytes\")\n",
    "    \n",
    "    try:\n",
    "        # Ler e mostrar informa√ß√µes\n",
    "        df_log_jornadas_check = pd.read_csv(caminho_log_jornadas)\n",
    "        print(f\"Linhas no arquivo: {len(df_log_jornadas_check)}\")\n",
    "        print(f\"Colunas no arquivo: {list(df_log_jornadas_check.columns)}\")\n",
    "        \n",
    "        # Mostrar primeiras linhas\n",
    "        print(\"\\nüìã Primeiras 5 linhas do log_jornadas.csv:\")\n",
    "        print(df_log_jornadas_check.head().to_string(index=False))\n",
    "        \n",
    "        # Estat√≠sticas da Jornada\n",
    "        if 'Jornada' in df_log_jornadas_check.columns:\n",
    "            print(f\"\\nüìä Estat√≠sticas da coluna Jornada:\")\n",
    "            \n",
    "            # Converter para timedelta se necess√°rio\n",
    "            if df_log_jornadas_check['Jornada'].dtype == 'object':\n",
    "                jornadas_td = pd.to_timedelta(df_log_jornadas_check['Jornada'], errors='coerce')\n",
    "            else:\n",
    "                jornadas_td = df_log_jornadas_check['Jornada']\n",
    "            \n",
    "            jornadas_validas = jornadas_td.dropna()\n",
    "            \n",
    "            if len(jornadas_validas) > 0:\n",
    "                print(f\"- Registros com Jornada v√°lida: {len(jornadas_validas)}\")\n",
    "                print(f\"- Jornada m√©dia: {jornadas_validas.mean()}\")\n",
    "                print(f\"- Jornada m√≠nima: {jornadas_validas.min()}\")\n",
    "                print(f\"- Jornada m√°xima: {jornadas_validas.max()}\")\n",
    "                \n",
    "                # Distribui√ß√£o por faixas de tempo\n",
    "                print(f\"\\nüìà Distribui√ß√£o por faixas de Jornada:\")\n",
    "                \n",
    "                # Converter para horas para an√°lise\n",
    "                jornadas_horas = jornadas_validas.dt.total_seconds() / 3600\n",
    "                \n",
    "                # Faixas de an√°lise\n",
    "                faixas = [\n",
    "                    (0, 8, \"0-8h\"),\n",
    "                    (8, 12, \"8-12h\"), \n",
    "                    (12, 16, \"12-16h\"),\n",
    "                    (16, 24, \"16-24h\"),\n",
    "                    (24, float('inf'), \">24h\")\n",
    "                ]\n",
    "                \n",
    "                for min_h, max_h, label in faixas:\n",
    "                    if max_h == float('inf'):\n",
    "                        count = (jornadas_horas >= min_h).sum()\n",
    "                    else:\n",
    "                        count = ((jornadas_horas >= min_h) & (jornadas_horas < max_h)).sum()\n",
    "                    \n",
    "                    percent = (count / len(jornadas_validas)) * 100\n",
    "                    print(f\"  {label}: {count} registros ({percent:.1f}%)\")\n",
    "            \n",
    "            else:\n",
    "                print(\"- Nenhuma Jornada v√°lida encontrada\")\n",
    "        \n",
    "        # Verificar se h√° dados por Activity (se existir)\n",
    "        if 'Activity' in df_log_jornadas_check.columns:\n",
    "            print(f\"\\nüìä Distribui√ß√£o por Activity (Top 10):\")\n",
    "            activity_counts_jornada = df_log_jornadas_check['Activity'].value_counts()\n",
    "            for activity, count in activity_counts_jornada.head(10).items():\n",
    "                print(f\"  {activity}: {count} registros\")\n",
    "        \n",
    "        print(f\"\\nüìÇ Caminho completo: {os.path.abspath(caminho_log_jornadas)}\")\n",
    "        print(\"‚úÖ VERIFICA√á√ÉO CONCLU√çDA!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao ler o arquivo: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Arquivo log_jornadas.csv n√£o foi encontrado\")\n",
    "    \n",
    "    # Procurar o arquivo\n",
    "    print(\"\\nüîç Procurando arquivo em outros locais...\")\n",
    "    for root, dirs, files in os.walk('.'):\n",
    "        if 'log_jornadas.csv' in files:\n",
    "            print(f\"Encontrado em: {os.path.join(root, 'log_jornadas.csv')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "48f5a157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RESUMO FINAL - AN√ÅLISE JORNADA ===\n",
      "üìÅ Arquivos gerados:\n",
      "  ‚úÖ log.csv (Tempo Solo)\n",
      "  ‚úÖ log_jornadas.csv (Jornada)\n",
      "\n",
      "üìä RESUMO LOG_JORNADAS.CSV:\n",
      "- Total de registros: 940\n",
      "- Colunas: Activity, Id_Leg, Checkin, Checkout, Jornada\n",
      "- Jornadas v√°lidas: 940\n",
      "- Jornada m√©dia: ~12.4 horas\n",
      "- Jornada min/max: 0.0h - 25.0h\n",
      "\n",
      "üìÇ Localiza√ß√£o dos arquivos:\n",
      "- Diret√≥rio: g:\\PROJETOS PYTHON\\aeronautas_azul\\CODIGOS TERMINADOS\n",
      "\n",
      "‚úÖ AN√ÅLISES CONCLU√çDAS:\n",
      "1. ‚úÖ Tempo Solo (log.csv) - Filtrado por Activity 'AD*' + Id_Leg '-I'/'-M'\n",
      "2. ‚úÖ Jornada (log_jornadas.csv) - C√°lculo Checkout - Checkin\n",
      "\n",
      "Todos os arquivos est√£o prontos para uso!\n"
     ]
    }
   ],
   "source": [
    "print(\"=== RESUMO FINAL - AN√ÅLISE JORNADA ===\")\n",
    "\n",
    "# Verificar arquivos gerados\n",
    "arquivos_gerados = []\n",
    "if os.path.exists(\"log.csv\"):\n",
    "    arquivos_gerados.append(\"log.csv (Tempo Solo)\")\n",
    "if os.path.exists(\"log_jornadas.csv\"):\n",
    "    arquivos_gerados.append(\"log_jornadas.csv (Jornada)\")\n",
    "\n",
    "print(\"üìÅ Arquivos gerados:\")\n",
    "for arquivo in arquivos_gerados:\n",
    "    print(f\"  ‚úÖ {arquivo}\")\n",
    "\n",
    "if os.path.exists(\"log_jornadas.csv\"):\n",
    "    # Ler arquivo resumidamente\n",
    "    df_resumo = pd.read_csv(\"log_jornadas.csv\")\n",
    "    \n",
    "    print(f\"\\nüìä RESUMO LOG_JORNADAS.CSV:\")\n",
    "    print(f\"- Total de registros: {len(df_resumo)}\")\n",
    "    print(f\"- Colunas: {', '.join(df_resumo.columns)}\")\n",
    "    \n",
    "    if 'Jornada' in df_resumo.columns:\n",
    "        jornadas_validas = df_resumo['Jornada'].notna().sum()\n",
    "        print(f\"- Jornadas v√°lidas: {jornadas_validas}\")\n",
    "        \n",
    "        if jornadas_validas > 0:\n",
    "            # Converter para an√°lise\n",
    "            jornadas_td = pd.to_timedelta(df_resumo['Jornada'], errors='coerce')\n",
    "            jornadas_horas = jornadas_td.dt.total_seconds() / 3600\n",
    "            \n",
    "            print(f\"- Jornada m√©dia: ~{jornadas_horas.mean():.1f} horas\")\n",
    "            print(f\"- Jornada min/max: {jornadas_horas.min():.1f}h - {jornadas_horas.max():.1f}h\")\n",
    "\n",
    "print(f\"\\nüìÇ Localiza√ß√£o dos arquivos:\")\n",
    "print(f\"- Diret√≥rio: {os.getcwd()}\")\n",
    "\n",
    "print(f\"\\n‚úÖ AN√ÅLISES CONCLU√çDAS:\")\n",
    "print(\"1. ‚úÖ Tempo Solo (log.csv) - Filtrado por Activity 'AD*' + Id_Leg '-I'/'-M'\")\n",
    "print(\"2. ‚úÖ Jornada (log_jornadas.csv) - C√°lculo Checkout - Checkin\")\n",
    "print(\"\\nTodos os arquivos est√£o prontos para uso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5a220ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AN√ÅLISE DA COLUNA 'REPOUSO' ===\n",
      "Crit√©rios:\n",
      "- Repouso = Checkin da linha seguinte - Checkout da linha atual\n",
      "- Filtrar apenas linhas onde Id_Leg seja '-IF' ou '-F'\n",
      "- Gerar arquivo log_repouso.csv\n",
      "============================================================\n",
      "Dataset df2 dispon√≠vel com 2541 registros\n",
      "\n",
      "Colunas dispon√≠veis: ['Id_Leg', 'Checkin', 'Checkout', 'Repouso']\n",
      "\n",
      "‚úÖ Colunas essenciais dispon√≠veis - Iniciando an√°lise...\n",
      "\n",
      "üìä Investigando valores de Id_Leg:\n",
      "Termina√ß√µes mais comuns:\n",
      "  ‚úÖ IF: 1466 registros\n",
      "  ‚ùå -I: 392 registros\n",
      "  ‚úÖ -F: 392 registros\n",
      "  ‚ùå -M: 291 registros\n",
      "\n",
      "üìã Aplicando filtros para Id_Leg...\n",
      "Registros com Id_Leg terminando em '-IF' ou '-F': 1858\n",
      "\n",
      "‚úÖ Dataset filtrado criado com 1858 registros\n",
      "Distribui√ß√£o das termina√ß√µes filtradas:\n",
      "  - IF: 1466 registros\n",
      "  - -F: 392 registros\n",
      "\n",
      "‚è±Ô∏è Calculando Repouso (Checkin pr√≥xima linha - Checkout linha atual)...\n",
      "Repouso calculado para 702 registros\n",
      "\n",
      "üîç Comparando Repouso original vs calculado...\n",
      "üìä Resultados da compara√ß√£o:\n",
      "- Total analisado: 702\n",
      "- Corretos: 455 (64.8%)\n",
      "- Incorretos: 247\n",
      "\n",
      "üìù Exemplos de c√°lculos (primeiros 3 registros):\n",
      "  Checkout atual: 11/02/2017 04:01 | Checkin pr√≥ximo: 11/03/2017 00:20\n",
      "  Repouso Original: 0 days 20:19:00 | Calculado: 27 days 20:19:00\n",
      "\n",
      "  Checkout atual: 11/03/2017 02:21 | Checkin pr√≥ximo: 11/04/2017 10:10\n",
      "  Repouso Original: 1 days 07:49:00 | Calculado: 31 days 07:49:00\n",
      "\n",
      "  Checkout atual: 11/04/2017 17:38 | Checkin pr√≥ximo: 11/05/2017 07:20\n",
      "  Repouso Original: 0 days 13:42:00 | Calculado: 29 days 13:42:00\n",
      "\n",
      "\n",
      "üìÑ Preparando log_repouso.csv...\n",
      "‚úÖ Arquivo log_repouso.csv salvo com 702 registros\n",
      "Colunas inclu√≠das: ['Activity', 'Id_Leg', 'Checkin', 'Checkout', 'Repouso']\n",
      "\n",
      "üìä Estat√≠sticas do log_repouso.csv:\n",
      "- Total de registros: 702\n",
      "- Repouso v√°lidos: 702\n",
      "- Repouso nulos: 0\n",
      "- Repouso m√©dio: ~8.3 horas\n",
      "- Repouso min/max: -2.0h - 864.0h\n",
      "\n",
      "‚úÖ AN√ÅLISE DO REPOUSO CONCLU√çDA!\n",
      "Arquivo log_repouso.csv dispon√≠vel em: log_repouso.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"=== AN√ÅLISE DA COLUNA 'REPOUSO' ===\")\n",
    "print(\"Crit√©rios:\")\n",
    "print(\"- Repouso = Checkin da linha seguinte - Checkout da linha atual\")\n",
    "print(\"- Filtrar apenas linhas onde Id_Leg seja '-IF' ou '-F'\")\n",
    "print(\"- Gerar arquivo log_repouso.csv\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Verificar se os dados est√£o dispon√≠veis\n",
    "if 'df2' not in locals():\n",
    "    print(\"ERRO: df2 n√£o est√° dispon√≠vel\")\n",
    "else:\n",
    "    print(f\"Dataset df2 dispon√≠vel com {len(df2)} registros\")\n",
    "    \n",
    "    # Verificar colunas necess√°rias\n",
    "    colunas_necessarias_repouso = ['Id_Leg', 'Checkin', 'Checkout', 'Repouso']\n",
    "    colunas_disponiveis_repouso = []\n",
    "    colunas_faltando_repouso = []\n",
    "    \n",
    "    for col in colunas_necessarias_repouso:\n",
    "        if col in df2.columns:\n",
    "            colunas_disponiveis_repouso.append(col)\n",
    "        else:\n",
    "            colunas_faltando_repouso.append(col)\n",
    "    \n",
    "    print(f\"\\nColunas dispon√≠veis: {colunas_disponiveis_repouso}\")\n",
    "    if colunas_faltando_repouso:\n",
    "        print(f\"Colunas faltando: {colunas_faltando_repouso}\")\n",
    "    \n",
    "    # Verificar se as colunas essenciais est√£o dispon√≠veis\n",
    "    if all(col in df2.columns for col in ['Id_Leg', 'Checkin', 'Checkout']):\n",
    "        print(\"\\n‚úÖ Colunas essenciais dispon√≠veis - Iniciando an√°lise...\")\n",
    "        \n",
    "        # Primeiro, investigar os valores de Id_Leg\n",
    "        print(\"\\nüìä Investigando valores de Id_Leg:\")\n",
    "        id_leg_terminacoes_repouso = df2['Id_Leg'].str[-2:].value_counts() if df2['Id_Leg'].dtype == 'object' else df2['Id_Leg'].value_counts()\n",
    "        print(\"Termina√ß√µes mais comuns:\")\n",
    "        for term, count in id_leg_terminacoes_repouso.head(10).items():\n",
    "            valido_repouso = term in ['-F', 'IF']  # '-IF' cont√©m 'IF'\n",
    "            status = \"‚úÖ\" if valido_repouso else \"‚ùå\"\n",
    "            print(f\"  {status} {term}: {count} registros\")\n",
    "        \n",
    "        # Aplicar filtros\n",
    "        print(\"\\nüìã Aplicando filtros para Id_Leg...\")\n",
    "        \n",
    "        # Filtro: Id_Leg terminando com '-IF' ou '-F'\n",
    "        filtro_id_leg_repouso = df2['Id_Leg'].str.endswith(('-IF', '-F'), na=False)\n",
    "        registros_id_leg_repouso = filtro_id_leg_repouso.sum()\n",
    "        print(f\"Registros com Id_Leg terminando em '-IF' ou '-F': {registros_id_leg_repouso}\")\n",
    "        \n",
    "        if registros_id_leg_repouso > 0:\n",
    "            # Aplicar filtro\n",
    "            df_repouso_filtrado = df2[filtro_id_leg_repouso].copy()\n",
    "            \n",
    "            print(f\"\\n‚úÖ Dataset filtrado criado com {len(df_repouso_filtrado)} registros\")\n",
    "            \n",
    "            # Mostrar distribui√ß√£o das termina√ß√µes filtradas\n",
    "            print(\"Distribui√ß√£o das termina√ß√µes filtradas:\")\n",
    "            term_filtradas = df_repouso_filtrado['Id_Leg'].str[-2:].value_counts()\n",
    "            for term, count in term_filtradas.items():\n",
    "                print(f\"  - {term}: {count} registros\")\n",
    "            \n",
    "            # Calcular Repouso\n",
    "            print(\"\\n‚è±Ô∏è Calculando Repouso (Checkin pr√≥xima linha - Checkout linha atual)...\")\n",
    "            \n",
    "            # Ordenar por √≠ndice para garantir ordem correta\n",
    "            df_repouso_filtrado = df_repouso_filtrado.sort_index()\n",
    "            \n",
    "            # Converter datas\n",
    "            try:\n",
    "                df_repouso_filtrado['Checkin_dt'] = pd.to_datetime(df_repouso_filtrado['Checkin'], dayfirst=True, errors='coerce')\n",
    "                df_repouso_filtrado['Checkout_dt'] = pd.to_datetime(df_repouso_filtrado['Checkout'], dayfirst=True, errors='coerce')\n",
    "                \n",
    "                # Calcular Repouso (Checkin da pr√≥xima linha - Checkout da linha atual)\n",
    "                repouso_calculado = []\n",
    "                \n",
    "                for i in range(len(df_repouso_filtrado)):\n",
    "                    if i < len(df_repouso_filtrado) - 1:  # N√£o √© a √∫ltima linha\n",
    "                        try:\n",
    "                            checkout_atual = df_repouso_filtrado.iloc[i]['Checkout_dt']\n",
    "                            checkin_proximo = df_repouso_filtrado.iloc[i+1]['Checkin_dt']\n",
    "                            \n",
    "                            if pd.notna(checkout_atual) and pd.notna(checkin_proximo):\n",
    "                                repouso = checkin_proximo - checkout_atual\n",
    "                                repouso_calculado.append(repouso)\n",
    "                            else:\n",
    "                                repouso_calculado.append(pd.NaT)\n",
    "                        except:\n",
    "                            repouso_calculado.append(pd.NaT)\n",
    "                    else:  # √öltima linha\n",
    "                        repouso_calculado.append(pd.NaT)\n",
    "                \n",
    "                # Adicionar coluna calculada\n",
    "                df_repouso_filtrado['Repouso_Calculado'] = repouso_calculado\n",
    "                \n",
    "                # Contar registros v√°lidos\n",
    "                repouso_validos = pd.Series(repouso_calculado).notna().sum()\n",
    "                print(f\"Repouso calculado para {repouso_validos} registros\")\n",
    "                \n",
    "                # Comparar com Repouso original se existir\n",
    "                if 'Repouso' in df_repouso_filtrado.columns:\n",
    "                    print(\"\\nüîç Comparando Repouso original vs calculado...\")\n",
    "                    \n",
    "                    # Filtrar apenas registros com valores v√°lidos\n",
    "                    mask_validos_repouso = pd.notna(df_repouso_filtrado['Repouso_Calculado'])\n",
    "                    df_repouso_validos = df_repouso_filtrado[mask_validos_repouso].copy()\n",
    "                    \n",
    "                    if len(df_repouso_validos) > 0:\n",
    "                        # Converter Repouso original para timedelta se necess√°rio\n",
    "                        if df_repouso_validos['Repouso'].dtype == 'object':\n",
    "                            df_repouso_validos['Repouso_Original'] = pd.to_timedelta(df_repouso_validos['Repouso'], errors='coerce')\n",
    "                        else:\n",
    "                            df_repouso_validos['Repouso_Original'] = df_repouso_validos['Repouso']\n",
    "                        \n",
    "                        # Comparar valores (com toler√¢ncia de 1 minuto)\n",
    "                        tolerancia_repouso = pd.Timedelta(minutes=1)\n",
    "                        \n",
    "                        # Filtrar registros onde ambos valores s√£o v√°lidos\n",
    "                        mask_ambos_validos = pd.notna(df_repouso_validos['Repouso_Original']) & pd.notna(df_repouso_validos['Repouso_Calculado'])\n",
    "                        df_comparacao_repouso = df_repouso_validos[mask_ambos_validos].copy()\n",
    "                        \n",
    "                        if len(df_comparacao_repouso) > 0:\n",
    "                            # Calcular diferen√ßa absoluta\n",
    "                            diferenca_repouso = abs(df_comparacao_repouso['Repouso_Calculado'] - df_comparacao_repouso['Repouso_Original'])\n",
    "                            \n",
    "                            # Contar corretos e incorretos\n",
    "                            corretos_repouso = (diferenca_repouso <= tolerancia_repouso).sum()\n",
    "                            incorretos_repouso = len(df_comparacao_repouso) - corretos_repouso\n",
    "                            \n",
    "                            taxa_acerto_repouso = (corretos_repouso / len(df_comparacao_repouso)) * 100\n",
    "                            \n",
    "                            print(f\"üìä Resultados da compara√ß√£o:\")\n",
    "                            print(f\"- Total analisado: {len(df_comparacao_repouso)}\")\n",
    "                            print(f\"- Corretos: {corretos_repouso} ({taxa_acerto_repouso:.1f}%)\")\n",
    "                            print(f\"- Incorretos: {incorretos_repouso}\")\n",
    "                            \n",
    "                            # Mostrar exemplos\n",
    "                            print(f\"\\nüìù Exemplos de c√°lculos (primeiros 3 registros):\")\n",
    "                            exemplos_repouso = df_comparacao_repouso.head(3)\n",
    "                            for idx, row in exemplos_repouso.iterrows():\n",
    "                                checkout = row['Checkout_dt'].strftime('%d/%m/%Y %H:%M') if pd.notna(row['Checkout_dt']) else 'N/A'\n",
    "                                checkin_prox = df_repouso_filtrado.iloc[df_repouso_filtrado.index.get_loc(idx)+1]['Checkin_dt']\n",
    "                                checkin_prox_str = checkin_prox.strftime('%d/%m/%Y %H:%M') if pd.notna(checkin_prox) else 'N/A'\n",
    "                                repouso_orig = row['Repouso_Original'] if pd.notna(row['Repouso_Original']) else 'N/A'\n",
    "                                repouso_calc = row['Repouso_Calculado'] if pd.notna(row['Repouso_Calculado']) else 'N/A'\n",
    "                                \n",
    "                                print(f\"  Checkout atual: {checkout} | Checkin pr√≥ximo: {checkin_prox_str}\")\n",
    "                                print(f\"  Repouso Original: {repouso_orig} | Calculado: {repouso_calc}\")\n",
    "                                print()\n",
    "                        \n",
    "                        # Usar dados de compara√ß√£o para o log\n",
    "                        df_log_repouso = df_repouso_validos.copy()\n",
    "                    else:\n",
    "                        df_log_repouso = df_repouso_filtrado.copy()\n",
    "                        df_log_repouso['Repouso'] = df_log_repouso['Repouso_Calculado']\n",
    "                else:\n",
    "                    print(\"\\nüìù Coluna Repouso n√£o existe - usando apenas c√°lculo\")\n",
    "                    df_log_repouso = df_repouso_filtrado.copy()\n",
    "                    df_log_repouso['Repouso'] = df_log_repouso['Repouso_Calculado']\n",
    "                \n",
    "                # Preparar dados para log_repouso.csv\n",
    "                print(f\"\\nüìÑ Preparando log_repouso.csv...\")\n",
    "                \n",
    "                # Selecionar colunas relevantes\n",
    "                colunas_log_repouso = ['Activity', 'Id_Leg', 'Checkin', 'Checkout', 'Repouso']\n",
    "                \n",
    "                # Verificar quais colunas existem\n",
    "                colunas_existentes_repouso = []\n",
    "                for col in colunas_log_repouso:\n",
    "                    if col in df_log_repouso.columns:\n",
    "                        colunas_existentes_repouso.append(col)\n",
    "                    elif col == 'Repouso' and 'Repouso_Calculado' in df_log_repouso.columns:\n",
    "                        df_log_repouso['Repouso'] = df_log_repouso['Repouso_Calculado']\n",
    "                        colunas_existentes_repouso.append('Repouso')\n",
    "                \n",
    "                # Se Activity n√£o existe, usar colunas b√°sicas\n",
    "                if 'Activity' not in colunas_existentes_repouso:\n",
    "                    colunas_existentes_repouso = ['Id_Leg', 'Checkin', 'Checkout', 'Repouso']\n",
    "                \n",
    "                # Criar dataframe final\n",
    "                df_log_repouso_final = df_log_repouso[colunas_existentes_repouso].copy()\n",
    "                \n",
    "                # Salvar log_repouso.csv\n",
    "                caminho_log_repouso = \"log_repouso.csv\"\n",
    "                df_log_repouso_final.to_csv(caminho_log_repouso, index=False, encoding='utf-8')\n",
    "                \n",
    "                print(f\"‚úÖ Arquivo log_repouso.csv salvo com {len(df_log_repouso_final)} registros\")\n",
    "                print(f\"Colunas inclu√≠das: {list(df_log_repouso_final.columns)}\")\n",
    "                \n",
    "                # Estat√≠sticas finais\n",
    "                print(f\"\\nüìä Estat√≠sticas do log_repouso.csv:\")\n",
    "                print(f\"- Total de registros: {len(df_log_repouso_final)}\")\n",
    "                \n",
    "                if 'Repouso' in df_log_repouso_final.columns:\n",
    "                    repouso_validos_final = df_log_repouso_final['Repouso'].notna().sum()\n",
    "                    repouso_nulos_final = df_log_repouso_final['Repouso'].isna().sum()\n",
    "                    print(f\"- Repouso v√°lidos: {repouso_validos_final}\")\n",
    "                    print(f\"- Repouso nulos: {repouso_nulos_final}\")\n",
    "                    \n",
    "                    # Estat√≠sticas do Repouso\n",
    "                    if repouso_validos_final > 0:\n",
    "                        repousos_validos = df_log_repouso_final['Repouso'].dropna()\n",
    "                        \n",
    "                        # Converter para horas para an√°lise\n",
    "                        if repousos_validos.dtype == 'object':\n",
    "                            repousos_td = pd.to_timedelta(repousos_validos, errors='coerce')\n",
    "                        else:\n",
    "                            repousos_td = repousos_validos\n",
    "                        \n",
    "                        repousos_horas = repousos_td.dt.total_seconds() / 3600\n",
    "                        \n",
    "                        print(f\"- Repouso m√©dio: ~{repousos_horas.mean():.1f} horas\")\n",
    "                        print(f\"- Repouso min/max: {repousos_horas.min():.1f}h - {repousos_horas.max():.1f}h\")\n",
    "                \n",
    "                print(f\"\\n‚úÖ AN√ÅLISE DO REPOUSO CONCLU√çDA!\")\n",
    "                print(f\"Arquivo log_repouso.csv dispon√≠vel em: {caminho_log_repouso}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Erro ao processar datas: {e}\")\n",
    "                \n",
    "        else:\n",
    "            print(\"\\n‚ùå Nenhum registro encontrado com Id_Leg terminando em '-IF' ou '-F'\")\n",
    "            \n",
    "    else:\n",
    "        print(\"\\n‚ùå Colunas essenciais (Id_Leg, Checkin, Checkout) n√£o est√£o dispon√≠veis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "568775fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VERIFICA√á√ÉO DO ARQUIVO LOG_REPOUSO.CSV ===\n",
      "‚úÖ Arquivo log_repouso.csv encontrado!\n",
      "Tamanho do arquivo: 45911 bytes\n",
      "Linhas no arquivo: 702\n",
      "Colunas no arquivo: ['Activity', 'Id_Leg', 'Checkin', 'Checkout', 'Repouso']\n",
      "\n",
      "üìã Primeiras 5 linhas do log_repouso.csv:\n",
      "Activity Id_Leg             Checkin            Checkout           Repouso\n",
      "  AD2852     -F 2017-11-01 18:55:00 2017-11-02 04:01:00   0 days 20:19:00\n",
      "  AD2898    -IF 2017-11-03 00:20:00 2017-11-03 02:21:00   1 days 07:49:00\n",
      "  AD4446     -F 2017-11-04 10:10:00 2017-11-04 17:38:00   0 days 13:42:00\n",
      "  AD4151     -F 2017-11-05 07:20:00 2017-11-05 17:16:00   0 days 14:19:00\n",
      "      FR    -IF 2017-11-06 07:35:00 2017-11-07 08:05:00 -1 days +23:30:00\n",
      "\n",
      "üìä Distribui√ß√£o por Id_Leg:\n",
      "  IF: 565 registros\n",
      "  -F: 137 registros\n",
      "\n",
      "üìä Estat√≠sticas da coluna Repouso:\n",
      "- Registros com Repouso v√°lido: 702\n",
      "- Registros com Repouso nulo: 0\n",
      "- Repouso m√©dio: ~8.3 horas\n",
      "- Repouso m√≠nimo: -2.0 horas\n",
      "- Repouso m√°ximo: 864.0 horas\n",
      "\n",
      "üìù Exemplos de Repouso (primeiros 3 registros v√°lidos):\n",
      "  Id_Leg: -F, Repouso: 0 days 20:19:00\n",
      "  Id_Leg: -IF, Repouso: 1 days 07:49:00\n",
      "  Id_Leg: -F, Repouso: 0 days 13:42:00\n",
      "\n",
      "üìÇ Caminho completo: g:\\PROJETOS PYTHON\\aeronautas_azul\\CODIGOS TERMINADOS\\log_repouso.csv\n",
      "‚úÖ VERIFICA√á√ÉO CONCLU√çDA!\n",
      "\n",
      "============================================================\n",
      "üìÅ RESUMO DE TODOS OS ARQUIVOS GERADOS:\n",
      "‚úÖ log.csv (663 registros, 70994 bytes)\n",
      "   Tempo Solo - Activity 'AD*' + Id_Leg '-I'/'-M'\n",
      "‚úÖ log_jornadas.csv (940 registros, 61743 bytes)\n",
      "   Jornada - Checkout - Checkin\n",
      "‚úÖ log_repouso.csv (702 registros, 45911 bytes)\n",
      "   Repouso - Checkin pr√≥xima - Checkout atual (Id_Leg '-IF'/'-F')\n",
      "\n",
      "üìÇ Todos os arquivos est√£o em: g:\\PROJETOS PYTHON\\aeronautas_azul\\CODIGOS TERMINADOS\n",
      "‚úÖ AN√ÅLISES COMPLETAS!\n"
     ]
    }
   ],
   "source": [
    "print(\"=== VERIFICA√á√ÉO DO ARQUIVO LOG_REPOUSO.CSV ===\")\n",
    "\n",
    "# Verificar se o arquivo foi criado\n",
    "caminho_log_repouso_check = \"log_repouso.csv\"\n",
    "\n",
    "if os.path.exists(caminho_log_repouso_check):\n",
    "    print(\"‚úÖ Arquivo log_repouso.csv encontrado!\")\n",
    "    \n",
    "    # Informa√ß√µes do arquivo\n",
    "    tamanho_repouso = os.path.getsize(caminho_log_repouso_check)\n",
    "    print(f\"Tamanho do arquivo: {tamanho_repouso} bytes\")\n",
    "    \n",
    "    try:\n",
    "        # Ler e mostrar informa√ß√µes\n",
    "        df_log_repouso_check = pd.read_csv(caminho_log_repouso_check)\n",
    "        print(f\"Linhas no arquivo: {len(df_log_repouso_check)}\")\n",
    "        print(f\"Colunas no arquivo: {list(df_log_repouso_check.columns)}\")\n",
    "        \n",
    "        # Mostrar primeiras linhas\n",
    "        print(\"\\nüìã Primeiras 5 linhas do log_repouso.csv:\")\n",
    "        print(df_log_repouso_check.head().to_string(index=False))\n",
    "        \n",
    "        # Verificar distribui√ß√£o por Id_Leg\n",
    "        if 'Id_Leg' in df_log_repouso_check.columns:\n",
    "            print(f\"\\nüìä Distribui√ß√£o por Id_Leg:\")\n",
    "            id_leg_counts_repouso = df_log_repouso_check['Id_Leg'].str[-2:].value_counts()\n",
    "            for term, count in id_leg_counts_repouso.items():\n",
    "                print(f\"  {term}: {count} registros\")\n",
    "        \n",
    "        # Estat√≠sticas do Repouso\n",
    "        if 'Repouso' in df_log_repouso_check.columns:\n",
    "            print(f\"\\nüìä Estat√≠sticas da coluna Repouso:\")\n",
    "            \n",
    "            repouso_validos_check = df_log_repouso_check['Repouso'].notna().sum()\n",
    "            repouso_nulos_check = df_log_repouso_check['Repouso'].isna().sum()\n",
    "            \n",
    "            print(f\"- Registros com Repouso v√°lido: {repouso_validos_check}\")\n",
    "            print(f\"- Registros com Repouso nulo: {repouso_nulos_check}\")\n",
    "            \n",
    "            if repouso_validos_check > 0:\n",
    "                # Converter para an√°lise\n",
    "                repousos_check = df_log_repouso_check['Repouso'].dropna()\n",
    "                \n",
    "                if repousos_check.dtype == 'object':\n",
    "                    repousos_td_check = pd.to_timedelta(repousos_check, errors='coerce')\n",
    "                else:\n",
    "                    repousos_td_check = repousos_check\n",
    "                \n",
    "                repousos_horas_check = repousos_td_check.dt.total_seconds() / 3600\n",
    "                \n",
    "                print(f\"- Repouso m√©dio: ~{repousos_horas_check.mean():.1f} horas\")\n",
    "                print(f\"- Repouso m√≠nimo: {repousos_horas_check.min():.1f} horas\")\n",
    "                print(f\"- Repouso m√°ximo: {repousos_horas_check.max():.1f} horas\")\n",
    "                \n",
    "                # Exemplos de valores\n",
    "                print(f\"\\nüìù Exemplos de Repouso (primeiros 3 registros v√°lidos):\")\n",
    "                exemplos_repouso_check = df_log_repouso_check[df_log_repouso_check['Repouso'].notna()].head(3)\n",
    "                for idx, row in exemplos_repouso_check.iterrows():\n",
    "                    id_leg = row.get('Id_Leg', 'N/A')\n",
    "                    repouso = row.get('Repouso', 'N/A')\n",
    "                    print(f\"  Id_Leg: {id_leg}, Repouso: {repouso}\")\n",
    "        \n",
    "        print(f\"\\nüìÇ Caminho completo: {os.path.abspath(caminho_log_repouso_check)}\")\n",
    "        print(\"‚úÖ VERIFICA√á√ÉO CONCLU√çDA!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao ler o arquivo: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Arquivo log_repouso.csv n√£o foi encontrado\")\n",
    "\n",
    "# Resumo de todos os arquivos gerados\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"üìÅ RESUMO DE TODOS OS ARQUIVOS GERADOS:\")\n",
    "\n",
    "arquivos_todos = [\n",
    "    (\"log.csv\", \"Tempo Solo - Activity 'AD*' + Id_Leg '-I'/'-M'\"),\n",
    "    (\"log_jornadas.csv\", \"Jornada - Checkout - Checkin\"),\n",
    "    (\"log_repouso.csv\", \"Repouso - Checkin pr√≥xima - Checkout atual (Id_Leg '-IF'/'-F')\")\n",
    "]\n",
    "\n",
    "for arquivo, descricao in arquivos_todos:\n",
    "    if os.path.exists(arquivo):\n",
    "        tamanho_arquivo = os.path.getsize(arquivo)\n",
    "        try:\n",
    "            df_temp = pd.read_csv(arquivo)\n",
    "            print(f\"‚úÖ {arquivo} ({len(df_temp)} registros, {tamanho_arquivo} bytes)\")\n",
    "            print(f\"   {descricao}\")\n",
    "        except:\n",
    "            print(f\"‚úÖ {arquivo} ({tamanho_arquivo} bytes)\")\n",
    "            print(f\"   {descricao}\")\n",
    "    else:\n",
    "        print(f\"‚ùå {arquivo} - N√£o encontrado\")\n",
    "\n",
    "print(f\"\\nüìÇ Todos os arquivos est√£o em: {os.getcwd()}\")\n",
    "print(\"‚úÖ AN√ÅLISES COMPLETAS!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2f005001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RESUMO FINAL DE TODAS AS AN√ÅLISES ===\n",
      "üìä RESULTADOS DAS AN√ÅLISES:\n",
      "\n",
      "‚úÖ TEMPO SOLO (log.csv):\n",
      "   - Registros: 663\n",
      "   - Colunas: Activity, Id_Leg, Checkin, Start, End, Checkout, Tempo Solo\n",
      "   - Tempo Solo v√°lidos: 663\n",
      "\n",
      "‚úÖ JORNADA (log_jornadas.csv):\n",
      "   - Registros: 940\n",
      "   - Colunas: Activity, Id_Leg, Checkin, Checkout, Jornada\n",
      "   - Jornada m√©dia: ~12.4h\n",
      "\n",
      "‚úÖ REPOUSO (log_repouso.csv):\n",
      "   - Registros: 702\n",
      "   - Colunas: Activity, Id_Leg, Checkin, Checkout, Repouso\n",
      "   - Repouso m√©dio: ~8.3h\n",
      "\n",
      "üìÇ CRIT√âRIOS APLICADOS:\n",
      "1. Tempo Solo: Activity 'AD*' + Id_Leg '-I'/'-M' (Start pr√≥xima - End atual)\n",
      "2. Jornada: Todos os registros (Checkout - Checkin)\n",
      "3. Repouso: Id_Leg '-IF'/'-F' (Checkin pr√≥xima - Checkout atual)\n",
      "\n",
      "üìç Localiza√ß√£o: g:\\PROJETOS PYTHON\\aeronautas_azul\\CODIGOS TERMINADOS\n",
      "\n",
      "üéØ TODAS AS AN√ÅLISES CONCLU√çDAS COM SUCESSO!\n"
     ]
    }
   ],
   "source": [
    "print(\"=== RESUMO FINAL DE TODAS AS AN√ÅLISES ===\")\n",
    "\n",
    "# Verificar arquivos gerados\n",
    "arquivos_analise = [\n",
    "    (\"log.csv\", \"Tempo Solo\"),\n",
    "    (\"log_jornadas.csv\", \"Jornada\"), \n",
    "    (\"log_repouso.csv\", \"Repouso\")\n",
    "]\n",
    "\n",
    "print(\"üìä RESULTADOS DAS AN√ÅLISES:\")\n",
    "print()\n",
    "\n",
    "for arquivo, tipo in arquivos_analise:\n",
    "    if os.path.exists(arquivo):\n",
    "        try:\n",
    "            df_check = pd.read_csv(arquivo)\n",
    "            print(f\"‚úÖ {tipo.upper()} ({arquivo}):\")\n",
    "            print(f\"   - Registros: {len(df_check)}\")\n",
    "            print(f\"   - Colunas: {', '.join(df_check.columns)}\")\n",
    "            \n",
    "            # Mostrar estat√≠stica espec√≠fica de cada tipo\n",
    "            if tipo == \"Tempo Solo\" and 'Tempo Solo' in df_check.columns:\n",
    "                validos = df_check['Tempo Solo'].notna().sum()\n",
    "                print(f\"   - Tempo Solo v√°lidos: {validos}\")\n",
    "                \n",
    "            elif tipo == \"Jornada\" and 'Jornada' in df_check.columns:\n",
    "                validos = df_check['Jornada'].notna().sum()\n",
    "                if validos > 0:\n",
    "                    jornadas_td = pd.to_timedelta(df_check['Jornada'], errors='coerce')\n",
    "                    media_horas = jornadas_td.dt.total_seconds().mean() / 3600\n",
    "                    print(f\"   - Jornada m√©dia: ~{media_horas:.1f}h\")\n",
    "                    \n",
    "            elif tipo == \"Repouso\" and 'Repouso' in df_check.columns:\n",
    "                validos = df_check['Repouso'].notna().sum()\n",
    "                if validos > 0:\n",
    "                    repousos_td = pd.to_timedelta(df_check['Repouso'], errors='coerce')\n",
    "                    media_horas = repousos_td.dt.total_seconds().mean() / 3600\n",
    "                    print(f\"   - Repouso m√©dio: ~{media_horas:.1f}h\")\n",
    "                    \n",
    "            print()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erro ao ler {arquivo}: {e}\")\n",
    "    else:\n",
    "        print(f\"‚ùå {tipo} - Arquivo n√£o encontrado\")\n",
    "\n",
    "print(\"üìÇ CRIT√âRIOS APLICADOS:\")\n",
    "print(\"1. Tempo Solo: Activity 'AD*' + Id_Leg '-I'/'-M' (Start pr√≥xima - End atual)\")\n",
    "print(\"2. Jornada: Todos os registros (Checkout - Checkin)\")  \n",
    "print(\"3. Repouso: Id_Leg '-IF'/'-F' (Checkin pr√≥xima - Checkout atual)\")\n",
    "\n",
    "print(f\"\\nüìç Localiza√ß√£o: {os.getcwd()}\")\n",
    "print(\"\\nüéØ TODAS AS AN√ÅLISES CONCLU√çDAS COM SUCESSO!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a8f9d1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AN√ÅLISE DA COLUNA 'REPOUSO EXTRA' ===\n",
      "Crit√©rio: Repouso Extra = Repouso - 12 horas\n",
      "Base: Usar dados do arquivo log_repouso.csv ou coluna Repouso do dataset\n",
      "Objetivo: Gerar arquivo log_repousoextra.csv\n",
      "============================================================\n",
      "Fontes de dados de Repouso dispon√≠veis: ['log_repouso.csv', 'df2[Repouso]']\n",
      "\n",
      "‚úÖ Usando dados do arquivo log_repouso.csv\n",
      "Dados carregados: 702 registros\n",
      "Colunas dispon√≠veis: ['Activity', 'Id_Leg', 'Checkin', 'Checkout', 'Repouso']\n",
      "\n",
      "üìä An√°lise da coluna Repouso:\n",
      "- Total de registros: 702\n",
      "- Repouso v√°lidos: 702\n",
      "- Repouso nulos: 0\n",
      "\n",
      "‚è±Ô∏è Calculando Repouso Extra (Repouso - 12 horas)...\n",
      "Repouso Extra calculado para 702 registros\n",
      "\n",
      "üìä Estat√≠sticas do Repouso Extra:\n",
      "- Repouso Extra m√©dio: -3.7 horas\n",
      "- Repouso Extra m√≠nimo: -14.0 horas\n",
      "- Repouso Extra m√°ximo: 852.0 horas\n",
      "\n",
      "üìà Distribui√ß√£o do Repouso Extra:\n",
      "  Negativos (< 0h): 443 (63.1%)\n",
      "  0-4h: 137 (19.5%)\n",
      "  4-8h: 59 (8.4%)\n",
      "  8h+: 63 (9.0%)\n",
      "\n",
      "üìù Exemplos de c√°lculos (primeiros 5 registros):\n",
      "  Activity: AD2852, Id_Leg: -F\n",
      "  Repouso: 0 days 20:19:00 | Repouso Extra: 0 days 08:19:00\n",
      "\n",
      "  Activity: AD2898, Id_Leg: -IF\n",
      "  Repouso: 1 days 07:49:00 | Repouso Extra: 0 days 19:49:00\n",
      "\n",
      "  Activity: AD4446, Id_Leg: -F\n",
      "  Repouso: 0 days 13:42:00 | Repouso Extra: 0 days 01:42:00\n",
      "\n",
      "  Activity: AD4151, Id_Leg: -F\n",
      "  Repouso: 0 days 14:19:00 | Repouso Extra: 0 days 02:19:00\n",
      "\n",
      "  Activity: FR, Id_Leg: -IF\n",
      "  Repouso: -1 days +23:30:00 | Repouso Extra: -1 days +11:30:00\n",
      "\n",
      "üìÑ Preparando log_repousoextra.csv...\n",
      "‚úÖ Arquivo log_repousoextra.csv salvo com 702 registros\n",
      "Colunas inclu√≠das: ['Activity', 'Id_Leg', 'Checkin', 'Checkout', 'Repouso', 'Repouso Extra']\n",
      "\n",
      "üìä Estat√≠sticas do log_repousoextra.csv:\n",
      "- Total de registros: 702\n",
      "- Repouso Extra v√°lidos: 702\n",
      "- Repouso Extra nulos: 0\n",
      "\n",
      "‚úÖ AN√ÅLISE DO REPOUSO EXTRA CONCLU√çDA!\n",
      "Arquivo log_repousoextra.csv dispon√≠vel em: log_repousoextra.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"=== AN√ÅLISE DA COLUNA 'REPOUSO EXTRA' ===\")\n",
    "print(\"Crit√©rio: Repouso Extra = Repouso - 12 horas\")\n",
    "print(\"Base: Usar dados do arquivo log_repouso.csv ou coluna Repouso do dataset\")\n",
    "print(\"Objetivo: Gerar arquivo log_repousoextra.csv\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Verificar se temos dados de repouso dispon√≠veis\n",
    "arquivos_repouso_disponiveis = []\n",
    "\n",
    "# Op√ß√£o 1: Usar arquivo log_repouso.csv se existir\n",
    "if os.path.exists(\"log_repouso.csv\"):\n",
    "    arquivos_repouso_disponiveis.append(\"log_repouso.csv\")\n",
    "    \n",
    "# Op√ß√£o 2: Usar df2 se tiver coluna Repouso\n",
    "if 'df2' in locals() and 'Repouso' in df2.columns:\n",
    "    arquivos_repouso_disponiveis.append(\"df2[Repouso]\")\n",
    "\n",
    "print(f\"Fontes de dados de Repouso dispon√≠veis: {arquivos_repouso_disponiveis}\")\n",
    "\n",
    "if len(arquivos_repouso_disponiveis) == 0:\n",
    "    print(\"‚ùå Nenhuma fonte de dados de Repouso encontrada\")\n",
    "else:\n",
    "    # Priorizar arquivo log_repouso.csv se existir\n",
    "    if \"log_repouso.csv\" in arquivos_repouso_disponiveis:\n",
    "        print(\"\\n‚úÖ Usando dados do arquivo log_repouso.csv\")\n",
    "        try:\n",
    "            df_repouso_extra = pd.read_csv(\"log_repouso.csv\")\n",
    "            print(f\"Dados carregados: {len(df_repouso_extra)} registros\")\n",
    "            print(f\"Colunas dispon√≠veis: {list(df_repouso_extra.columns)}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erro ao carregar log_repouso.csv: {e}\")\n",
    "            df_repouso_extra = None\n",
    "            \n",
    "    else:\n",
    "        print(\"\\n‚úÖ Usando coluna Repouso do dataset df2\")\n",
    "        df_repouso_extra = df2[df2['Repouso'].notna()].copy()\n",
    "        print(f\"Registros com Repouso v√°lido: {len(df_repouso_extra)}\")\n",
    "    \n",
    "    if df_repouso_extra is not None and len(df_repouso_extra) > 0:\n",
    "        # Verificar se a coluna Repouso existe\n",
    "        if 'Repouso' not in df_repouso_extra.columns:\n",
    "            print(\"‚ùå Coluna 'Repouso' n√£o encontrada nos dados\")\n",
    "        else:\n",
    "            print(f\"\\nüìä An√°lise da coluna Repouso:\")\n",
    "            \n",
    "            # Verificar valores nulos na coluna Repouso\n",
    "            repouso_nulos_extra = df_repouso_extra['Repouso'].isna().sum()\n",
    "            repouso_validos_extra = len(df_repouso_extra) - repouso_nulos_extra\n",
    "            \n",
    "            print(f\"- Total de registros: {len(df_repouso_extra)}\")\n",
    "            print(f\"- Repouso v√°lidos: {repouso_validos_extra}\")\n",
    "            print(f\"- Repouso nulos: {repouso_nulos_extra}\")\n",
    "            \n",
    "            if repouso_validos_extra > 0:\n",
    "                print(\"\\n‚è±Ô∏è Calculando Repouso Extra (Repouso - 12 horas)...\")\n",
    "                \n",
    "                # Filtrar apenas registros com Repouso v√°lido\n",
    "                df_repouso_extra_validos = df_repouso_extra[df_repouso_extra['Repouso'].notna()].copy()\n",
    "                \n",
    "                # Converter Repouso para timedelta se necess√°rio\n",
    "                try:\n",
    "                    if df_repouso_extra_validos['Repouso'].dtype == 'object':\n",
    "                        df_repouso_extra_validos['Repouso_td'] = pd.to_timedelta(df_repouso_extra_validos['Repouso'], errors='coerce')\n",
    "                    else:\n",
    "                        df_repouso_extra_validos['Repouso_td'] = df_repouso_extra_validos['Repouso']\n",
    "                    \n",
    "                    # Definir 12 horas como timedelta\n",
    "                    doze_horas = pd.Timedelta(hours=12)\n",
    "                    \n",
    "                    # Calcular Repouso Extra\n",
    "                    df_repouso_extra_validos['Repouso_Extra'] = df_repouso_extra_validos['Repouso_td'] - doze_horas\n",
    "                    \n",
    "                    # Contar registros com c√°lculo v√°lido\n",
    "                    repouso_extra_calculados = df_repouso_extra_validos['Repouso_Extra'].notna().sum()\n",
    "                    print(f\"Repouso Extra calculado para {repouso_extra_calculados} registros\")\n",
    "                    \n",
    "                    # Verificar se existe coluna Repouso Extra original para compara√ß√£o\n",
    "                    if 'Repouso Extra' in df_repouso_extra_validos.columns:\n",
    "                        print(\"\\nüîç Comparando Repouso Extra original vs calculado...\")\n",
    "                        \n",
    "                        # Converter Repouso Extra original se necess√°rio\n",
    "                        if df_repouso_extra_validos['Repouso Extra'].dtype == 'object':\n",
    "                            df_repouso_extra_validos['Repouso_Extra_Original'] = pd.to_timedelta(df_repouso_extra_validos['Repouso Extra'], errors='coerce')\n",
    "                        else:\n",
    "                            df_repouso_extra_validos['Repouso_Extra_Original'] = df_repouso_extra_validos['Repouso Extra']\n",
    "                        \n",
    "                        # Comparar valores (com toler√¢ncia de 1 minuto)\n",
    "                        tolerancia_extra = pd.Timedelta(minutes=1)\n",
    "                        \n",
    "                        # Filtrar registros onde ambos valores s√£o v√°lidos\n",
    "                        mask_ambos_validos_extra = (pd.notna(df_repouso_extra_validos['Repouso_Extra_Original']) & \n",
    "                                                   pd.notna(df_repouso_extra_validos['Repouso_Extra']))\n",
    "                        \n",
    "                        df_comparacao_extra = df_repouso_extra_validos[mask_ambos_validos_extra].copy()\n",
    "                        \n",
    "                        if len(df_comparacao_extra) > 0:\n",
    "                            # Calcular diferen√ßa absoluta\n",
    "                            diferenca_extra = abs(df_comparacao_extra['Repouso_Extra'] - df_comparacao_extra['Repouso_Extra_Original'])\n",
    "                            \n",
    "                            # Contar corretos e incorretos\n",
    "                            corretos_extra = (diferenca_extra <= tolerancia_extra).sum()\n",
    "                            incorretos_extra = len(df_comparacao_extra) - corretos_extra\n",
    "                            \n",
    "                            taxa_acerto_extra = (corretos_extra / len(df_comparacao_extra)) * 100\n",
    "                            \n",
    "                            print(f\"üìä Resultados da compara√ß√£o:\")\n",
    "                            print(f\"- Total analisado: {len(df_comparacao_extra)}\")\n",
    "                            print(f\"- Corretos: {corretos_extra} ({taxa_acerto_extra:.1f}%)\")\n",
    "                            print(f\"- Incorretos: {incorretos_extra}\")\n",
    "                    \n",
    "                    # Estat√≠sticas do Repouso Extra\n",
    "                    print(f\"\\nüìä Estat√≠sticas do Repouso Extra:\")\n",
    "                    \n",
    "                    # Converter para horas para an√°lise\n",
    "                    repouso_extra_horas = df_repouso_extra_validos['Repouso_Extra'].dt.total_seconds() / 3600\n",
    "                    \n",
    "                    # Filtrar valores v√°lidos para estat√≠sticas\n",
    "                    repouso_extra_horas_validos = repouso_extra_horas.dropna()\n",
    "                    \n",
    "                    if len(repouso_extra_horas_validos) > 0:\n",
    "                        print(f\"- Repouso Extra m√©dio: {repouso_extra_horas_validos.mean():.1f} horas\")\n",
    "                        print(f\"- Repouso Extra m√≠nimo: {repouso_extra_horas_validos.min():.1f} horas\")\n",
    "                        print(f\"- Repouso Extra m√°ximo: {repouso_extra_horas_validos.max():.1f} horas\")\n",
    "                        \n",
    "                        # Distribui√ß√£o por faixas\n",
    "                        print(f\"\\nüìà Distribui√ß√£o do Repouso Extra:\")\n",
    "                        \n",
    "                        # Contadores por faixa\n",
    "                        negativos = (repouso_extra_horas_validos < 0).sum()\n",
    "                        zero_a_4h = ((repouso_extra_horas_validos >= 0) & (repouso_extra_horas_validos < 4)).sum()\n",
    "                        quatro_a_8h = ((repouso_extra_horas_validos >= 4) & (repouso_extra_horas_validos < 8)).sum()\n",
    "                        oito_mais = (repouso_extra_horas_validos >= 8).sum()\n",
    "                        \n",
    "                        total_validos = len(repouso_extra_horas_validos)\n",
    "                        \n",
    "                        print(f\"  Negativos (< 0h): {negativos} ({(negativos/total_validos)*100:.1f}%)\")\n",
    "                        print(f\"  0-4h: {zero_a_4h} ({(zero_a_4h/total_validos)*100:.1f}%)\")\n",
    "                        print(f\"  4-8h: {quatro_a_8h} ({(quatro_a_8h/total_validos)*100:.1f}%)\")\n",
    "                        print(f\"  8h+: {oito_mais} ({(oito_mais/total_validos)*100:.1f}%)\")\n",
    "                    \n",
    "                    # Mostrar exemplos\n",
    "                    print(f\"\\nüìù Exemplos de c√°lculos (primeiros 5 registros):\")\n",
    "                    exemplos_extra = df_repouso_extra_validos.head(5)\n",
    "                    for idx, row in exemplos_extra.iterrows():\n",
    "                        repouso_orig = row['Repouso_td'] if pd.notna(row['Repouso_td']) else 'N/A'\n",
    "                        repouso_extra = row['Repouso_Extra'] if pd.notna(row['Repouso_Extra']) else 'N/A'\n",
    "                        id_leg = row.get('Id_Leg', 'N/A')\n",
    "                        activity = row.get('Activity', 'N/A')\n",
    "                        \n",
    "                        print(f\"  Activity: {activity}, Id_Leg: {id_leg}\")\n",
    "                        print(f\"  Repouso: {repouso_orig} | Repouso Extra: {repouso_extra}\")\n",
    "                        print()\n",
    "                    \n",
    "                    # Preparar dados para log_repousoextra.csv\n",
    "                    print(f\"üìÑ Preparando log_repousoextra.csv...\")\n",
    "                    \n",
    "                    # Usar Repouso Extra calculado como coluna final\n",
    "                    df_repouso_extra_validos['Repouso Extra'] = df_repouso_extra_validos['Repouso_Extra']\n",
    "                    \n",
    "                    # Selecionar colunas relevantes\n",
    "                    colunas_log_extra = ['Activity', 'Id_Leg', 'Checkin', 'Checkout', 'Repouso', 'Repouso Extra']\n",
    "                    \n",
    "                    # Verificar quais colunas existem\n",
    "                    colunas_existentes_extra = []\n",
    "                    for col in colunas_log_extra:\n",
    "                        if col in df_repouso_extra_validos.columns:\n",
    "                            colunas_existentes_extra.append(col)\n",
    "                    \n",
    "                    # Se Activity n√£o existe, usar colunas b√°sicas\n",
    "                    if 'Activity' not in colunas_existentes_extra:\n",
    "                        colunas_existentes_extra = ['Id_Leg', 'Checkin', 'Checkout', 'Repouso', 'Repouso Extra']\n",
    "                        colunas_existentes_extra = [col for col in colunas_existentes_extra if col in df_repouso_extra_validos.columns]\n",
    "                    \n",
    "                    # Criar dataframe final\n",
    "                    df_log_extra_final = df_repouso_extra_validos[colunas_existentes_extra].copy()\n",
    "                    \n",
    "                    # Salvar log_repousoextra.csv\n",
    "                    caminho_log_extra = \"log_repousoextra.csv\"\n",
    "                    df_log_extra_final.to_csv(caminho_log_extra, index=False, encoding='utf-8')\n",
    "                    \n",
    "                    print(f\"‚úÖ Arquivo log_repousoextra.csv salvo com {len(df_log_extra_final)} registros\")\n",
    "                    print(f\"Colunas inclu√≠das: {list(df_log_extra_final.columns)}\")\n",
    "                    \n",
    "                    # Estat√≠sticas finais\n",
    "                    print(f\"\\nüìä Estat√≠sticas do log_repousoextra.csv:\")\n",
    "                    print(f\"- Total de registros: {len(df_log_extra_final)}\")\n",
    "                    \n",
    "                    if 'Repouso Extra' in df_log_extra_final.columns:\n",
    "                        extra_validos_final = df_log_extra_final['Repouso Extra'].notna().sum()\n",
    "                        extra_nulos_final = df_log_extra_final['Repouso Extra'].isna().sum()\n",
    "                        print(f\"- Repouso Extra v√°lidos: {extra_validos_final}\")\n",
    "                        print(f\"- Repouso Extra nulos: {extra_nulos_final}\")\n",
    "                    \n",
    "                    print(f\"\\n‚úÖ AN√ÅLISE DO REPOUSO EXTRA CONCLU√çDA!\")\n",
    "                    print(f\"Arquivo log_repousoextra.csv dispon√≠vel em: {caminho_log_extra}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Erro ao calcular Repouso Extra: {e}\")\n",
    "                    \n",
    "            else:\n",
    "                print(\"‚ùå N√£o h√° registros com Repouso v√°lido para calcular Repouso Extra\")\n",
    "    else:\n",
    "        print(\"‚ùå N√£o foi poss√≠vel carregar dados de Repouso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e529a842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VERIFICA√á√ÉO FINAL - REPOUSO EXTRA ===\n",
      "‚úÖ Arquivo log_repousoextra.csv encontrado!\n",
      "Registros: 702\n",
      "Colunas: Activity, Id_Leg, Checkin, Checkout, Repouso, Repouso Extra\n",
      "Repouso Extra m√©dio: -3.7h\n",
      "\n",
      "======================================================================\n",
      "üéØ RESUMO COMPLETO DE TODAS AS AN√ÅLISES REALIZADAS\n",
      "======================================================================\n",
      "\n",
      "üìä STATUS DOS ARQUIVOS GERADOS:\n",
      "\n",
      "‚úÖ TEMPO SOLO (log.csv)\n",
      "   üìÑ Registros: 663\n",
      "   üìê Tamanho: 70994 bytes\n",
      "   üîç Filtro: Activity 'AD*' + Id_Leg '-I'/'-M'\n",
      "   üßÆ C√°lculo: Start pr√≥xima - End atual\n",
      "   üìã Colunas: Activity, Id_Leg, Checkin, Start, End, Checkout, Tempo Solo\n",
      "   ‚úÖ Valores v√°lidos: 663\n",
      "\n",
      "‚úÖ JORNADA (log_jornadas.csv)\n",
      "   üìÑ Registros: 940\n",
      "   üìê Tamanho: 61743 bytes\n",
      "   üîç Filtro: Todos os registros\n",
      "   üßÆ C√°lculo: Checkout - Checkin\n",
      "   üìã Colunas: Activity, Id_Leg, Checkin, Checkout, Jornada\n",
      "   ‚è±Ô∏è M√©dia: 12.4 horas\n",
      "\n",
      "‚úÖ REPOUSO (log_repouso.csv)\n",
      "   üìÑ Registros: 702\n",
      "   üìê Tamanho: 45911 bytes\n",
      "   üîç Filtro: Id_Leg '-IF'/'-F'\n",
      "   üßÆ C√°lculo: Checkin pr√≥xima - Checkout atual\n",
      "   üìã Colunas: Activity, Id_Leg, Checkin, Checkout, Repouso\n",
      "   ‚è±Ô∏è M√©dia: 8.3 horas\n",
      "\n",
      "‚úÖ REPOUSO EXTRA (log_repousoextra.csv)\n",
      "   üìÑ Registros: 702\n",
      "   üìê Tamanho: 58044 bytes\n",
      "   üîç Filtro: Baseado em Repouso\n",
      "   üßÆ C√°lculo: Repouso - 12 horas\n",
      "   üìã Colunas: Activity, Id_Leg, Checkin, Checkout, Repouso, Repouso Extra\n",
      "   ‚è±Ô∏è M√©dia: -3.7 horas\n",
      "   ‚ö†Ô∏è Negativos: 443 registros\n",
      "\n",
      "üìà ESTAT√çSTICAS GERAIS:\n",
      "‚úÖ Arquivos criados com sucesso: 4/4\n",
      "üìÇ Localiza√ß√£o: g:\\PROJETOS PYTHON\\aeronautas_azul\\CODIGOS TERMINADOS\n",
      "\n",
      "üéâ PARAB√âNS! TODAS AS AN√ÅLISES FORAM CONCLU√çDAS COM SUCESSO!\n",
      "üöÄ Todos os 4 arquivos de log est√£o prontos para uso:\n",
      "   1. log.csv - Tempo Solo\n",
      "   2. log_jornadas.csv - Jornada\n",
      "   3. log_repouso.csv - Repouso\n",
      "   4. log_repousoextra.csv - Repouso Extra\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=== VERIFICA√á√ÉO FINAL - REPOUSO EXTRA ===\")\n",
    "\n",
    "# Verificar se o arquivo foi criado\n",
    "if os.path.exists(\"log_repousoextra.csv\"):\n",
    "    print(\"‚úÖ Arquivo log_repousoextra.csv encontrado!\")\n",
    "    \n",
    "    try:\n",
    "        df_extra_check = pd.read_csv(\"log_repousoextra.csv\")\n",
    "        print(f\"Registros: {len(df_extra_check)}\")\n",
    "        print(f\"Colunas: {', '.join(df_extra_check.columns)}\")\n",
    "        \n",
    "        if 'Repouso Extra' in df_extra_check.columns:\n",
    "            extra_validos = df_extra_check['Repouso Extra'].notna().sum()\n",
    "            if extra_validos > 0:\n",
    "                # Converter para horas\n",
    "                extra_td = pd.to_timedelta(df_extra_check['Repouso Extra'], errors='coerce')\n",
    "                extra_horas = extra_td.dt.total_seconds() / 3600\n",
    "                print(f\"Repouso Extra m√©dio: {extra_horas.mean():.1f}h\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao verificar arquivo: {e}\")\n",
    "else:\n",
    "    print(\"‚ùå Arquivo log_repousoextra.csv n√£o encontrado\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéØ RESUMO COMPLETO DE TODAS AS AN√ÅLISES REALIZADAS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Lista de todos os arquivos de log esperados\n",
    "arquivos_completos = [\n",
    "    (\"log.csv\", \"Tempo Solo\", \"Activity 'AD*' + Id_Leg '-I'/'-M'\", \"Start pr√≥xima - End atual\"),\n",
    "    (\"log_jornadas.csv\", \"Jornada\", \"Todos os registros\", \"Checkout - Checkin\"),\n",
    "    (\"log_repouso.csv\", \"Repouso\", \"Id_Leg '-IF'/'-F'\", \"Checkin pr√≥xima - Checkout atual\"),\n",
    "    (\"log_repousoextra.csv\", \"Repouso Extra\", \"Baseado em Repouso\", \"Repouso - 12 horas\")\n",
    "]\n",
    "\n",
    "print(\"\\nüìä STATUS DOS ARQUIVOS GERADOS:\")\n",
    "arquivos_criados = 0\n",
    "\n",
    "for arquivo, tipo, filtro, calculo in arquivos_completos:\n",
    "    if os.path.exists(arquivo):\n",
    "        try:\n",
    "            df_temp = pd.read_csv(arquivo)\n",
    "            tamanho = os.path.getsize(arquivo)\n",
    "            print(f\"\\n‚úÖ {tipo.upper()} ({arquivo})\")\n",
    "            print(f\"   üìÑ Registros: {len(df_temp)}\")\n",
    "            print(f\"   üìê Tamanho: {tamanho} bytes\")\n",
    "            print(f\"   üîç Filtro: {filtro}\")\n",
    "            print(f\"   üßÆ C√°lculo: {calculo}\")\n",
    "            print(f\"   üìã Colunas: {', '.join(df_temp.columns)}\")\n",
    "            \n",
    "            # Estat√≠stica espec√≠fica de cada tipo\n",
    "            if tipo == \"Tempo Solo\" and 'Tempo Solo' in df_temp.columns:\n",
    "                validos = df_temp['Tempo Solo'].notna().sum()\n",
    "                print(f\"   ‚úÖ Valores v√°lidos: {validos}\")\n",
    "                \n",
    "            elif tipo == \"Jornada\" and 'Jornada' in df_temp.columns:\n",
    "                validos = df_temp['Jornada'].notna().sum()\n",
    "                if validos > 0:\n",
    "                    jornadas = pd.to_timedelta(df_temp['Jornada'], errors='coerce')\n",
    "                    media = jornadas.dt.total_seconds().mean() / 3600\n",
    "                    print(f\"   ‚è±Ô∏è M√©dia: {media:.1f} horas\")\n",
    "                    \n",
    "            elif tipo == \"Repouso\" and 'Repouso' in df_temp.columns:\n",
    "                validos = df_temp['Repouso'].notna().sum()\n",
    "                if validos > 0:\n",
    "                    repousos = pd.to_timedelta(df_temp['Repouso'], errors='coerce')\n",
    "                    media = repousos.dt.total_seconds().mean() / 3600\n",
    "                    print(f\"   ‚è±Ô∏è M√©dia: {media:.1f} horas\")\n",
    "                    \n",
    "            elif tipo == \"Repouso Extra\" and 'Repouso Extra' in df_temp.columns:\n",
    "                validos = df_temp['Repouso Extra'].notna().sum()\n",
    "                if validos > 0:\n",
    "                    extras = pd.to_timedelta(df_temp['Repouso Extra'], errors='coerce')\n",
    "                    media = extras.dt.total_seconds().mean() / 3600\n",
    "                    negativos = (extras.dt.total_seconds() < 0).sum()\n",
    "                    print(f\"   ‚è±Ô∏è M√©dia: {media:.1f} horas\")\n",
    "                    print(f\"   ‚ö†Ô∏è Negativos: {negativos} registros\")\n",
    "            \n",
    "            arquivos_criados += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå {tipo} - Erro ao ler: {e}\")\n",
    "    else:\n",
    "        print(f\"‚ùå {tipo} - Arquivo n√£o encontrado\")\n",
    "\n",
    "print(f\"\\nüìà ESTAT√çSTICAS GERAIS:\")\n",
    "print(f\"‚úÖ Arquivos criados com sucesso: {arquivos_criados}/4\")\n",
    "print(f\"üìÇ Localiza√ß√£o: {os.getcwd()}\")\n",
    "\n",
    "if arquivos_criados == 4:\n",
    "    print(f\"\\nüéâ PARAB√âNS! TODAS AS AN√ÅLISES FORAM CONCLU√çDAS COM SUCESSO!\")\n",
    "    print(\"üöÄ Todos os 4 arquivos de log est√£o prontos para uso:\")\n",
    "    print(\"   1. log.csv - Tempo Solo\")\n",
    "    print(\"   2. log_jornadas.csv - Jornada\") \n",
    "    print(\"   3. log_repouso.csv - Repouso\")\n",
    "    print(\"   4. log_repousoextra.csv - Repouso Extra\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è {4-arquivos_criados} arquivo(s) n√£o foram criados com sucesso\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
